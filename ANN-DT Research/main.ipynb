{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"yNSyFZvf0Leo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression, SGDRegressor, PassiveAggressiveRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, StackingRegressor, VotingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from xgboost import XGBRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","from models import ETFONN, FONN1, MLPWithDecisionTrees, TREENN1, TREENN2"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[-0.41978194,  0.28482986, -1.2879095 , -0.27259857, -0.14421743,\n","          0.41367189, -0.12001342,  0.1402136 , -0.98284286, -0.66660821,\n","          0.44105193, -1.0755623 ],\n","        [-0.41733926, -0.48772236, -0.59338101, -0.27259857, -0.74026221,\n","          0.19427445,  0.36716642,  0.55715988, -0.8678825 , -0.98732948,\n","          0.44105193, -0.49243937],\n","        [-0.41734159, -0.48772236, -0.59338101, -0.27259857, -0.74026221,\n","          1.28271368, -0.26581176,  0.55715988, -0.8678825 , -0.98732948,\n","          0.39642699, -1.2087274 ],\n","        [-0.41675042, -0.48772236, -1.30687771, -0.27259857, -0.83528384,\n","          1.01630251, -0.80988851,  1.07773662, -0.75292215, -1.10611514,\n","          0.41616284, -1.36151682],\n","        [-0.41248185, -0.48772236, -1.30687771, -0.27259857, -0.83528384,\n","          1.22857665, -0.51117971,  1.07773662, -0.75292215, -1.10611514,\n","          0.44105193, -1.02650148]]),\n"," (506, 12),\n"," array([24. , 21.6, 34.7, 33.4, 36.2]),\n"," (506,))"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Load the Boston dataset\n","data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None) # type: ignore\n","X = np.hstack([raw_df.values[::2, :-1], raw_df.values[1::2, :2]])\n","y = raw_df.values[1::2, 2]\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","X[:5], X.shape, y[:5], y.shape"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[ 1.32780421e+00, -4.87722365e-01,  1.01599907e+00,\n","         -2.72598567e-01,  5.12295652e-01, -1.39706929e+00,\n","          1.02148094e+00, -8.05438224e-01,  1.66124525e+00,\n","          1.53092646e+00, -7.88779407e-02,  1.71810120e+00],\n","        [-3.47506015e-01, -4.87722365e-01, -4.37258013e-01,\n","         -2.72598567e-01, -1.44217433e-01, -6.42000190e-01,\n","         -4.29390392e-01,  3.34449434e-01, -6.37961799e-01,\n","         -6.01276097e-01,  4.27017554e-01, -5.86355801e-01],\n","        [-4.16483921e-01,  1.01446252e+00, -7.40749452e-01,\n","         -2.72598567e-01, -1.00891427e+00, -3.61342430e-01,\n","         -1.61000138e+00,  1.35273767e+00, -9.82842857e-01,\n","         -6.19093946e-01,  6.11369155e-02, -6.76067022e-01],\n","        [ 3.99962749e-01, -4.87722365e-01,  1.01599907e+00,\n","         -2.72598567e-01,  5.12295652e-01, -2.58767006e-01,\n","          5.87641964e-01, -8.42944849e-01,  1.66124525e+00,\n","          1.53092646e+00, -3.88307172e+00,  1.49101967e+00],\n","        [-3.36053725e-01, -4.87722365e-01, -4.37258013e-01,\n","         -2.72598567e-01, -1.44217433e-01, -7.94438668e-01,\n","          3.28970429e-02,  6.92761271e-04, -6.37961799e-01,\n","         -6.01276097e-01,  3.75814000e-01, -1.92467469e-01]]),\n"," (404, 12),\n"," array([[-0.40983668, -0.48772236, -1.03402724, -0.27259857, -0.38609067,\n","          0.18715116,  0.55208139, -0.54607682, -0.52300145, -0.66660821,\n","          0.42570183, -0.50645674],\n","        [-0.41394931,  1.22906036, -0.68968118,  3.66839786, -0.93030547,\n","          0.67438443, -1.26861989,  0.13431903, -0.6379618 , -0.91605809,\n","          0.44105193, -1.27881429],\n","        [-0.40821211, -0.48772236,  2.42256516, -0.27259857,  0.469104  ,\n","         -0.42972605,  1.0748218 , -0.91600909, -0.6379618 ,  1.79819419,\n","          0.36660394,  0.75931252],\n","        [-0.40985297, -0.48772236, -0.04768006, -0.27259857, -1.22400869,\n","         -0.31290404, -2.16119024,  0.70937307, -0.6379618 , -0.61315466,\n","          0.37537543, -0.99986846],\n","        [ 0.17184212, -0.48772236,  1.01599907, -0.27259857,  1.36749033,\n","          0.01761678,  0.8258978 , -0.67827698,  1.66124525,  1.53092646,\n","          0.31156286,  0.64717349]]),\n"," (102, 12),\n"," array([12. , 19.9, 19.4, 13.4, 18.2]),\n"," (404,),\n"," array([23.6, 32.4, 13.6, 22.8, 16.1]),\n"," (102,))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train[:5], X_train.shape, X_test[:5], X_test.shape, y_train[:5], y_train.shape, y_test[:5], y_test.shape"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Function to train and evaluate a model\n","def train_evaluate_model(model, X_train, X_test, y_train, y_test):\n","    start_time = time.time()\n","    model.fit(X_train, y_train)\n","    predictions = model.predict(X_test)\n","    end_time = time.time()\n","\n","    r2 = r2_score(y_test, predictions)\n","    mae = mean_absolute_error(y_test, predictions)\n","    mse = mean_squared_error(y_test, predictions)\n","    comp_time = end_time - start_time\n","\n","    return r2, mae, mse, comp_time\n","\n","\n","# Initialize models\n","models = {\n","    \"Linear Regression\": LinearRegression(),\n","    \"Ridge Regression\": Ridge(),\n","    \"Lasso Regression\": Lasso(),\n","    \"ElasticNet Regression\": ElasticNet(),\n","    \"Bayesian Ridge Regression\": BayesianRidge(),\n","    \"ARD Regression\": ARDRegression(),\n","    \"SGD Regressor\": SGDRegressor(),\n","    \"Passive Aggressive Regressor\": PassiveAggressiveRegressor(),\n","    \"Support Vector Regression\": SVR(),\n","    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n","    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n","    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n","    \"XGBoost Regressor\": XGBRegressor(random_state=42),\n","    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=42),\n","    \"Bagging Regressor\": BaggingRegressor(random_state=42),\n","    \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=42),\n","    \"HistGradientBoosting Regressor\": HistGradientBoostingRegressor(random_state=42),\n","    \"Stacking Regressor\": StackingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42))\n","    ], final_estimator=Ridge()),\n","    \"Voting Regressor\": VotingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42)),\n","        ('gb', GradientBoostingRegressor(random_state=42))\n","    ])\n","}\n","\n","# Train and evaluate models\n","results = {}\n","for name, model in models.items():\n","    r2, mae, mse, comp_time = train_evaluate_model(model, X_train, X_test, y_train, y_test)\n","    results[name] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse, \"Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 617.1178201368134\n","Epoch 100, Loss: 9.967957900380481\n","Epoch 200, Loss: 9.187284068929955\n","Epoch 300, Loss: 7.673977664441285\n","Epoch 400, Loss: 7.466842564663707\n","Epoch 500, Loss: 8.46982082997658\n","Epoch 600, Loss: 8.807855460524326\n","Epoch 700, Loss: 8.40493319501086\n","Epoch 800, Loss: 8.323554639202664\n","Epoch 900, Loss: 8.454306634575506\n"]}],"source":["# Initialize and train ETFONN\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","num_trees_hidden = 10\n","epochs = 1000\n","learning_rate = 0.001\n","\n","etfonn_model = ETFONN(input_dim, hidden_dim, output_dim, num_trees_hidden)\n","etfonn_model.train(X_train, y_train, epochs, learning_rate)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 605.6274193983369\n","Epoch 100, Loss: 597.9259141380838\n","Epoch 200, Loss: 592.8148376477936\n","Epoch 300, Loss: 587.8356882573632\n","Epoch 400, Loss: 582.9015864919595\n","Epoch 500, Loss: 577.9997983346836\n","Epoch 600, Loss: 573.1263572741778\n","Epoch 700, Loss: 568.2795802977311\n","Epoch 800, Loss: 563.4586146953266\n","Epoch 900, Loss: 558.662975046886\n","Epoch 1000, Loss: 553.8923611987461\n"]}],"source":["# Initialize and train FONN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10  # Increased hidden layer size\n","output_dim = 1\n","num_trees_input = 10\n","epochs = 40000  # Increased number of epochs\n","learning_rate = 0.0001  # Decreased learning rate\n","\n","fonn1 = FONN1(input_dim, hidden_dim, output_dim, num_trees_input, X_train, y_train)\n","fonn1.train(X_train, y_train, epochs, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train FONN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","num_trees_hidden = 10\n","epochs = 1000\n","learning_rate = 0.001\n","\n","fonn2 = MLPWithDecisionTrees(input_dim, hidden_dim, output_dim, num_trees_hidden)\n","fonn2.train(X_train, y_train, epochs, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train TREENN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10  # Hidden layer size\n","output_dim = 1\n","epochs = 40000  # Number of epochs\n","learning_rate = 0.0001  # Learning rate\n","\n","# Initialize and train TREENN1\n","treenn1 = TREENN1(input_dim, hidden_dim, output_dim, X_train, y_train)\n","treenn1.train(X_train, y_train, epochs, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train TREENN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","epochs = 1000\n","learning_rate = 0.001\n","\n","treenn2 = TREENN2(input_dim, hidden_dim, output_dim)\n","treenn2.train(X_train, y_train, epochs, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the custom ETFONN model\n","start_time = time.time()\n","etfonn_predictions = etfonn_model.forward(X_test, y_test)\n","end_time = time.time()\n","etfonn_r2 = r2_score(y_test, etfonn_predictions)\n","etfonn_mae = mean_absolute_error(y_test, etfonn_predictions)\n","etfonn_mse = mean_squared_error(y_test, etfonn_predictions)\n","etfonn_time = end_time - start_time\n","\n","results[\"ETFONN\"] = {\"R² Score\": etfonn_r2, \"MAE\": etfonn_mae, \"MSE\": etfonn_mse, \"Time (s)\": etfonn_time}\n","\n","# Measure computational time and predict house prices using the decision trees in the hidden layer\n","start_time = time.time()\n","tree_based_predictions = etfonn_model.tree_predict(X_test)\n","end_time = time.time()\n","tree_based_r2 = r2_score(y_test, tree_based_predictions)\n","tree_based_mae = mean_absolute_error(y_test, tree_based_predictions)\n","tree_based_mse = mean_squared_error(y_test, tree_based_predictions)\n","tree_based_time = end_time - start_time\n","\n","results[\"Tree-based Predictions (ETFONN)\"] = {\"R² Score\": tree_based_r2, \"MAE\": tree_based_mae, \"MSE\": tree_based_mse, \"Time (s)\": tree_based_time}\n","\n","# Combine 10 decision trees and evaluate the ensemble model\n","trees = [DecisionTreeRegressor(max_depth=5, random_state=i) for i in range(10)]\n","\n","for tree in trees:\n","    tree.fit(X_train, y_train)\n","\n","ensemble_predictions = np.mean([tree.predict(X_test) for tree in trees], axis=0)\n","ensemble_r2 = r2_score(y_test, ensemble_predictions)\n","ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n","ensemble_mse = mean_squared_error(y_test, ensemble_predictions)\n","ensemble_time = sum([train_evaluate_model(tree, X_train, X_test, y_train, y_test)[3] for tree in trees])\n","\n","results[\"Ensemble of 10 Trees (ETFONN)\"] = {\"R² Score\": ensemble_r2, \"MAE\": ensemble_mae, \"MSE\": ensemble_mse, \"Time (s)\": ensemble_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the FONN1 model\n","start_time = time.time()\n","fonn1_predictions = fonn1.forward(X_test)\n","end_time = time.time()\n","fonn1_r2 = r2_score(y_test, fonn1_predictions)\n","fonn1_mae = mean_absolute_error(y_test, fonn1_predictions)\n","fonn1_mse = mean_squared_error(y_test, fonn1_predictions)\n","fonn1_time = end_time - start_time\n","\n","results[\"FONN1\"] = {\"R² Score\": fonn1_r2, \"MAE\": fonn1_mae, \"MSE\": fonn1_mse, \"Time (s)\": fonn1_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the custom MLP model\n","start_time = time.time()\n","custom_predictions = fonn2.forward(X_test, y_test)\n","end_time = time.time()\n","custom_r2 = r2_score(y_test, custom_predictions)\n","custom_mae = mean_absolute_error(y_test, custom_predictions)\n","custom_mse = mean_squared_error(y_test, custom_predictions)\n","custom_time = end_time - start_time\n","\n","results[\"FONN2\"] = {\"R² Score\": custom_r2, \"MAE\": custom_mae, \"MSE\": custom_mse, \"Time (s)\": custom_time}\n","\n","# Measure computational time and predict house prices using the decision trees in the hidden layer\n","start_time = time.time()\n","tree_based_predictions = fonn2.tree_predict(X_test)\n","end_time = time.time()\n","tree_based_r2 = r2_score(y_test, tree_based_predictions)\n","tree_based_mae = mean_absolute_error(y_test, tree_based_predictions)\n","tree_based_mse = mean_squared_error(y_test, tree_based_predictions)\n","tree_based_time = end_time - start_time\n","\n","results[\"Tree-based Predictions (FONN2)\"] = {\"R² Score\": tree_based_r2, \"MAE\": tree_based_mae, \"MSE\": tree_based_mse, \"Time (s)\": tree_based_time}\n","\n","# Combine 10 decision trees and evaluate the ensemble model\n","trees = [DecisionTreeRegressor(max_depth=5, random_state=i) for i in range(10)]\n","\n","for tree in trees:\n","    tree.fit(X_train, y_train)\n","\n","ensemble_predictions = np.mean([tree.predict(X_test) for tree in trees], axis=0)\n","ensemble_r2 = r2_score(y_test, ensemble_predictions)\n","ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n","ensemble_mse = mean_squared_error(y_test, ensemble_predictions)\n","ensemble_time = sum([train_evaluate_model(tree, X_train, X_test, y_train, y_test)[3] for tree in trees])\n","\n","results[\"Ensemble of 10 Trees (FONN2)\"] = {\"R² Score\": ensemble_r2, \"MAE\": ensemble_mae, \"MSE\": ensemble_mse, \"Time (s)\": ensemble_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the TREENN1 model\n","start_time = time.time()\n","treenn1_predictions = treenn1.forward(X_test)\n","end_time = time.time()\n","treenn1_r2 = r2_score(y_test, treenn1_predictions)\n","treenn1_mae = mean_absolute_error(y_test, treenn1_predictions)\n","treenn1_mse = mean_squared_error(y_test, treenn1_predictions)\n","treenn1_time = end_time - start_time\n","\n","results[\"TREENN1\"] = {\"R² Score\": treenn1_r2, \"MAE\": treenn1_mae, \"MSE\": treenn1_mse, \"Time (s)\": treenn1_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the custom MLP model\n","start_time = time.time()\n","custom_predictions = treenn2.forward(X_test, y_test)\n","end_time = time.time()\n","custom_r2 = r2_score(y_test, custom_predictions)\n","custom_mae = mean_absolute_error(y_test, custom_predictions)\n","custom_mse = mean_squared_error(y_test, custom_predictions)\n","custom_time = end_time - start_time\n","\n","results[\"TREENN2\"] = {\"R² Score\": custom_r2, \"MAE\": custom_mae, \"MSE\": custom_mse, \"Time (s)\": custom_time}\n","\n","# Measure computational time and predict house prices using the decision tree in the hidden layer\n","start_time = time.time()\n","tree_based_predictions = treenn2.tree_hidden.predict(treenn2.a1)\n","end_time = time.time()\n","tree_based_r2 = r2_score(y_test, tree_based_predictions)\n","tree_based_mae = mean_absolute_error(y_test, tree_based_predictions)\n","tree_based_mse = mean_squared_error(y_test, tree_based_predictions)\n","tree_based_time = end_time - start_time\n","\n","results[\"Tree-based Predictions (TREENN2)\"] = {\"R² Score\": tree_based_r2, \"MAE\": tree_based_mae, \"MSE\": tree_based_mse, \"Time (s)\": tree_based_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert results to a DataFrame for better visualization\n","results_df = pd.DataFrame(results).T\n","print(results_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get and print tree importances\n","tree_importances = etfonn_model.get_tree_importances()"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
