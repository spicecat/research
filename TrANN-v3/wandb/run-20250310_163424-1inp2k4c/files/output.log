2025-03-10 16:34:25,986 - INFO - Loading dataset...
2025-03-10 16:34:26,673 - INFO - Input dimension: 12
2025-03-10 16:34:26,673 - INFO - Hidden dimension: 64
2025-03-10 16:34:26,673 - INFO - Output dimension: 1
2025-03-10 16:34:26,673 - INFO - Number of trees (for forest models): 20
2025-03-10 16:34:26,673 - INFO -
Evaluating Tree Models...
2025-03-10 16:34:26,673 - INFO -
Initializing TREENN1...
2025-03-10 16:34:26,673 - INFO - Model class: TREENN1
2025-03-10 16:34:26,676 - INFO - TREENN1 model initialized successfully!
2025-03-10 16:34:26,677 - INFO - TREENN1 architecture:
2025-03-10 16:34:26,677 - INFO - Input dimension: 12
2025-03-10 16:34:26,677 - INFO - Hidden dimension: 64
2025-03-10 16:34:26,677 - INFO - Output dimension: 1
2025-03-10 16:34:26,677 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:34:26,677 - INFO - Training TREENN1...
Epoch 0, Loss: 1.366264953219041
2025-03-10 16:34:26,788 - INFO - TREENN1 Epoch 0:
2025-03-10 16:34:26,788 - INFO - Train MSE: 1.0657, Test MSE: 1.1503
2025-03-10 16:34:26,789 - INFO - Train R²: -0.0657, Test R²: -0.3627
2025-03-10 16:34:26,789 - INFO - Train MAE: 0.7818, Test MAE: 0.8109
2025-03-10 16:34:26,789 - INFO - Overfit ratio (train R² / test R²): 0.1812
Epoch 0, Loss: 1.2286653932891658
Epoch 0, Loss: 1.0443648710388236
Epoch 0, Loss: 1.0491680594989983
Epoch 0, Loss: 0.9705111511102025
Epoch 0, Loss: 0.845001301132329
Epoch 0, Loss: 0.8767513782360841
Epoch 0, Loss: 0.7835598230980482
Epoch 0, Loss: 0.7531491139721019
Epoch 0, Loss: 0.7700424457803954
Epoch 0, Loss: 0.7353486381676136
Epoch 0, Loss: 0.6950046369709174
Epoch 0, Loss: 0.6496312562504567
Epoch 0, Loss: 0.6931002968493791
Epoch 0, Loss: 0.6410007777361139
Epoch 0, Loss: 0.6581762321392892
Epoch 0, Loss: 0.6297844832455093
Epoch 0, Loss: 0.6797186227224437
Epoch 0, Loss: 0.6184445781196056
Epoch 0, Loss: 0.6921819197768496
Epoch 0, Loss: 0.6522381970190606
Epoch 0, Loss: 0.575316379738379
Epoch 0, Loss: 0.5912499985856285
Epoch 0, Loss: 0.5824870406010619
Epoch 0, Loss: 0.561101820083289
Epoch 0, Loss: 0.5967701604744441
Epoch 0, Loss: 0.613771384951879
Epoch 0, Loss: 0.5054809682540296
Epoch 0, Loss: 0.5618391846359284
Epoch 0, Loss: 0.5778169132341193
Epoch 0, Loss: 0.5036377249756427
Epoch 0, Loss: 0.5164853770752641
Epoch 0, Loss: 0.5188686439985408
Epoch 0, Loss: 0.5186227117400948
Epoch 0, Loss: 0.5030601031688958
Epoch 0, Loss: 0.5101922763795702
Epoch 0, Loss: 0.48880453046698463
Epoch 0, Loss: 0.44265134113109855
Epoch 0, Loss: 0.5464949845336984
Epoch 0, Loss: 0.5512978112282237
Epoch 0, Loss: 0.5224631428723477
Epoch 0, Loss: 0.5288794968538836
Epoch 0, Loss: 0.502529151468996
Epoch 0, Loss: 0.524087739748801
Epoch 0, Loss: 0.5285620045595564
Epoch 0, Loss: 0.47923496509635516
Epoch 0, Loss: 0.47829904181980404
Epoch 0, Loss: 0.500411822834604
Epoch 0, Loss: 0.47053665107245574
Epoch 0, Loss: 0.5137414407158649
Epoch 0, Loss: 0.42113962680070394
Epoch 0, Loss: 0.5111174219792296
Epoch 0, Loss: 0.4975593352660841
Epoch 0, Loss: 0.4991602888215799
Epoch 0, Loss: 0.4315940538582207
Epoch 0, Loss: 0.4337591432557462
Epoch 0, Loss: 0.506945232143297
Epoch 0, Loss: 0.5037062813011559
Epoch 0, Loss: 0.44675942932842655
Epoch 0, Loss: 0.49951987456602054
Epoch 0, Loss: 0.47192160077912126
Epoch 0, Loss: 0.43367471887113607
Epoch 0, Loss: 0.5217302884645325
Epoch 0, Loss: 0.4678555979278308
Epoch 0, Loss: 0.4488754659168398
Epoch 0, Loss: 0.4553047915477153
Epoch 0, Loss: 0.4417616886592222
Epoch 0, Loss: 0.4756742143897193
Epoch 0, Loss: 0.47454367027897865
Epoch 0, Loss: 0.41105876584284157
Epoch 0, Loss: 0.46788176660122094
Epoch 0, Loss: 0.450686738079981
Epoch 0, Loss: 0.42118478151770145
Epoch 0, Loss: 0.4525779392771815
Epoch 0, Loss: 0.46560898850450977
Epoch 0, Loss: 0.42852940083679386
Epoch 0, Loss: 0.4268800604526127
Epoch 0, Loss: 0.43594874514046356
Epoch 0, Loss: 0.41187867056034677
Epoch 0, Loss: 0.4517173156310513
Epoch 0, Loss: 0.48798659218192314
Epoch 0, Loss: 0.4724247133429157
Epoch 0, Loss: 0.4276479274499087
Epoch 0, Loss: 0.4430997553317776
Epoch 0, Loss: 0.43343954560339365
Epoch 0, Loss: 0.4368714436004448
Epoch 0, Loss: 0.40575626736416276
Epoch 0, Loss: 0.515961957038929
Epoch 0, Loss: 0.4975293688811186
Epoch 0, Loss: 0.4446813377886148
Epoch 0, Loss: 0.40374913926831624
Epoch 0, Loss: 0.4781105776644512
Epoch 0, Loss: 0.4498223165629288
Epoch 0, Loss: 0.407535063583523
Epoch 0, Loss: 0.3873859644944409
Epoch 0, Loss: 0.4451055837553213
Epoch 0, Loss: 0.4252974125142085
Epoch 0, Loss: 0.38958811414159616
Epoch 0, Loss: 0.42132342184615995
Epoch 0, Loss: 0.4255566910692049
Epoch 0, Loss: 0.40593922415515754
2025-03-10 16:34:27,399 - INFO - TREENN1 Epoch 100:
2025-03-10 16:34:27,399 - INFO - Train MSE: 0.2631, Test MSE: 0.3381
2025-03-10 16:34:27,399 - INFO - Train R²: 0.7369, Test R²: 0.5995
2025-03-10 16:34:27,400 - INFO - Train MAE: 0.3654, Test MAE: 0.3957
2025-03-10 16:34:27,400 - INFO - Overfit ratio (train R² / test R²): 1.2293
Epoch 0, Loss: 0.43396948933495155
Epoch 0, Loss: 0.3980338700012378
Epoch 0, Loss: 0.4369694432682214
Epoch 0, Loss: 0.40986839533454883
Epoch 0, Loss: 0.36563157299135496
Epoch 0, Loss: 0.4281064106419371
Epoch 0, Loss: 0.4795653786896202
Epoch 0, Loss: 0.4607316356117792
Epoch 0, Loss: 0.40745286949710435
Epoch 0, Loss: 0.4001504106829525
Epoch 0, Loss: 0.44829309040899856
Epoch 0, Loss: 0.4261406339597663
Epoch 0, Loss: 0.36559100101743297
Epoch 0, Loss: 0.39230965990818767
Epoch 0, Loss: 0.4011092796835656
Epoch 0, Loss: 0.4108401903909383
Epoch 0, Loss: 0.39097101432252007
Epoch 0, Loss: 0.40381148326079186
Epoch 0, Loss: 0.36073906635479214
Epoch 0, Loss: 0.40177986491535056
Epoch 0, Loss: 0.42559206285279927
Epoch 0, Loss: 0.4411164237949074
Epoch 0, Loss: 0.3993865342257911
Epoch 0, Loss: 0.3890362984494468
Epoch 0, Loss: 0.38713941800060936
Epoch 0, Loss: 0.4173971158688716
Epoch 0, Loss: 0.44591529998379376
Epoch 0, Loss: 0.40055028373551466
Epoch 0, Loss: 0.4088857459053811
Epoch 0, Loss: 0.37705248222910537
Epoch 0, Loss: 0.41146907711965686
Epoch 0, Loss: 0.39995659234381026
Epoch 0, Loss: 0.39156613498033704
Epoch 0, Loss: 0.41104966768464163
Epoch 0, Loss: 0.37824469371226493
Epoch 0, Loss: 0.3859336164550458
Epoch 0, Loss: 0.36564599311175866
Epoch 0, Loss: 0.41822850178218307
Epoch 0, Loss: 0.3983013863989812
Epoch 0, Loss: 0.3857226278478912
Epoch 0, Loss: 0.3661517669981564
Epoch 0, Loss: 0.37848547253224746
Epoch 0, Loss: 0.3736308466512586
Epoch 0, Loss: 0.38844639543574805
Epoch 0, Loss: 0.40007619971036135
Epoch 0, Loss: 0.38187810749299445
Epoch 0, Loss: 0.40450378874263354
Epoch 0, Loss: 0.33500573804389183
Epoch 0, Loss: 0.41232829278264155
Epoch 0, Loss: 0.42893107777442435
Epoch 0, Loss: 0.3745498646324994
Epoch 0, Loss: 0.404814089507121
Epoch 0, Loss: 0.41782849079850987
Epoch 0, Loss: 0.4083104417649426
Epoch 0, Loss: 0.37452821560275773
Epoch 0, Loss: 0.38238568237659415
Epoch 0, Loss: 0.3782822079011449
Epoch 0, Loss: 0.3537919148201111
Epoch 0, Loss: 0.355449090134012
Epoch 0, Loss: 0.3785896496067683
Epoch 0, Loss: 0.40949450808033316
Epoch 0, Loss: 0.4526788250573575
Epoch 0, Loss: 0.42879634246990855
Epoch 0, Loss: 0.35700802496576206
Epoch 0, Loss: 0.4141155443244065
Epoch 0, Loss: 0.3537661223706045
Epoch 0, Loss: 0.39231323704522064
Epoch 0, Loss: 0.36602037441605995
Epoch 0, Loss: 0.42376682026472795
Epoch 0, Loss: 0.39431441146913365
Epoch 0, Loss: 0.3573254217958208
Epoch 0, Loss: 0.41936687217213164
Epoch 0, Loss: 0.4063950095424039
Epoch 0, Loss: 0.3981610273258192
Epoch 0, Loss: 0.4025832449648705
Epoch 0, Loss: 0.405190923632118
Epoch 0, Loss: 0.43076410059067666
Epoch 0, Loss: 0.4148437498520729
Epoch 0, Loss: 0.3457726847567254
Epoch 0, Loss: 0.4002305347572433
Epoch 0, Loss: 0.3320525621370747
Epoch 0, Loss: 0.3654153290244346
Epoch 0, Loss: 0.39959606953537513
Epoch 0, Loss: 0.42566925909059977
Epoch 0, Loss: 0.38901989872857273
Epoch 0, Loss: 0.36033825488706966
Epoch 0, Loss: 0.421919205084521
Epoch 0, Loss: 0.3615142445596878
Epoch 0, Loss: 0.40750141012157753
Epoch 0, Loss: 0.4043906081608432
Epoch 0, Loss: 0.40455011926404444
Epoch 0, Loss: 0.3561180546830881
Epoch 0, Loss: 0.39199466290281626
Epoch 0, Loss: 0.39791408808867657
Epoch 0, Loss: 0.37314307031066124
Epoch 0, Loss: 0.40010435439759157
Epoch 0, Loss: 0.39720455537460136
Epoch 0, Loss: 0.42336166695425276
Epoch 0, Loss: 0.38854057438760625
Epoch 0, Loss: 0.4035968866248465
2025-03-10 16:34:27,906 - INFO - TREENN1 Epoch 200:
2025-03-10 16:34:27,906 - INFO - Train MSE: 0.2337, Test MSE: 0.3200
2025-03-10 16:34:27,907 - INFO - Train R²: 0.7663, Test R²: 0.6209
2025-03-10 16:34:27,907 - INFO - Train MAE: 0.3445, Test MAE: 0.3820
2025-03-10 16:34:27,907 - INFO - Overfit ratio (train R² / test R²): 1.2341
Epoch 0, Loss: 0.38086980896566286
Epoch 0, Loss: 0.41772240242476044
Epoch 0, Loss: 0.39698113164788246
Epoch 0, Loss: 0.3789542191744827
Epoch 0, Loss: 0.3975072716121056
Epoch 0, Loss: 0.3648333063782648
Epoch 0, Loss: 0.4059500365703014
Epoch 0, Loss: 0.3274398425230508
Epoch 0, Loss: 0.3861933674371482
Epoch 0, Loss: 0.33147745933699196
Epoch 0, Loss: 0.4038321486096704
Epoch 0, Loss: 0.3905521473984335
Epoch 0, Loss: 0.39921062916835465
Epoch 0, Loss: 0.371776736650101
Epoch 0, Loss: 0.38474878083371716
Epoch 0, Loss: 0.378188389008267
Epoch 0, Loss: 0.34199176348153343
Epoch 0, Loss: 0.37296849317457403
Epoch 0, Loss: 0.366017641947582
Epoch 0, Loss: 0.37504457794745233
Epoch 0, Loss: 0.4332808481045288
Epoch 0, Loss: 0.4097212314917674
Epoch 0, Loss: 0.303394339178128
Epoch 0, Loss: 0.38482378810648393
Epoch 0, Loss: 0.39318364095253044
Epoch 0, Loss: 0.41797498594494237
Epoch 0, Loss: 0.378782778911836
Epoch 0, Loss: 0.40405003194918815
Epoch 0, Loss: 0.4031576690167659
Epoch 0, Loss: 0.3751315074723763
Epoch 0, Loss: 0.4159881490386496
Epoch 0, Loss: 0.3546304871664007
Epoch 0, Loss: 0.4181339392382165
Epoch 0, Loss: 0.39712096970825794
Epoch 0, Loss: 0.43353196283618967
Epoch 0, Loss: 0.3819579517785401
Epoch 0, Loss: 0.3349983307034998
Epoch 0, Loss: 0.39799146758804227
Epoch 0, Loss: 0.33745660458035137
Epoch 0, Loss: 0.4409563883277664
Epoch 0, Loss: 0.4169414949333332
Epoch 0, Loss: 0.3997704521111472
Epoch 0, Loss: 0.375836211263777
Epoch 0, Loss: 0.41749955963629787
Epoch 0, Loss: 0.3787423273748957
Epoch 0, Loss: 0.37246952618024753
Epoch 0, Loss: 0.38861532650644354
Epoch 0, Loss: 0.35498449819853756
Epoch 0, Loss: 0.4175704286536348
Epoch 0, Loss: 0.4166511872946586
Epoch 0, Loss: 0.3744619910814574
Epoch 0, Loss: 0.3786665205153872
Epoch 0, Loss: 0.34725694234374216
Epoch 0, Loss: 0.39073365982992697
Epoch 0, Loss: 0.3724624245428087
Epoch 0, Loss: 0.42909135631978657
Epoch 0, Loss: 0.37485944966254076
Epoch 0, Loss: 0.3226780380835548
Epoch 0, Loss: 0.3954874672679756
Epoch 0, Loss: 0.3831034776890271
Epoch 0, Loss: 0.3734677018870158
Epoch 0, Loss: 0.3592244029153311
Epoch 0, Loss: 0.412720832890977
Epoch 0, Loss: 0.36996808120789854
Epoch 0, Loss: 0.39056843633848126
Epoch 0, Loss: 0.39117880484123346
Epoch 0, Loss: 0.3492808923328462
Epoch 0, Loss: 0.39462778411542965
Epoch 0, Loss: 0.317750648734747
Epoch 0, Loss: 0.42410828494355424
Epoch 0, Loss: 0.34591757275841706
Epoch 0, Loss: 0.3735793515383339
Epoch 0, Loss: 0.3459368974846937
Epoch 0, Loss: 0.3465892960175089
Epoch 0, Loss: 0.3878471481062923
Epoch 0, Loss: 0.36970604370031873
Epoch 0, Loss: 0.3579360791405028
Epoch 0, Loss: 0.3897097941922009
Epoch 0, Loss: 0.3908214775505161
Epoch 0, Loss: 0.3599042361531414
Epoch 0, Loss: 0.33859586859430224
Epoch 0, Loss: 0.4077999876622365
Epoch 0, Loss: 0.3207853105634473
Epoch 0, Loss: 0.35908205358172895
Epoch 0, Loss: 0.41410514693570016
Epoch 0, Loss: 0.38448803306349255
Epoch 0, Loss: 0.4063494005758227
Epoch 0, Loss: 0.4074804796277866
Epoch 0, Loss: 0.3806996098681596
Epoch 0, Loss: 0.4007291911022453
Epoch 0, Loss: 0.3967543932723548
Epoch 0, Loss: 0.3576954016894682
Epoch 0, Loss: 0.36061030242421643
Epoch 0, Loss: 0.41515087681193646
Epoch 0, Loss: 0.3933883840514565
Epoch 0, Loss: 0.32886458494034804
Epoch 0, Loss: 0.4182060594941216
Epoch 0, Loss: 0.37385308747048196
Epoch 0, Loss: 0.3887427161022676
Epoch 0, Loss: 0.3603137192048533
2025-03-10 16:34:28,407 - INFO - TREENN1 Epoch 300:
2025-03-10 16:34:28,407 - INFO - Train MSE: 0.2249, Test MSE: 0.3176
2025-03-10 16:34:28,407 - INFO - Train R²: 0.7751, Test R²: 0.6238
2025-03-10 16:34:28,407 - INFO - Train MAE: 0.3395, Test MAE: 0.3829
2025-03-10 16:34:28,407 - INFO - Overfit ratio (train R² / test R²): 1.2426
Epoch 0, Loss: 0.3320272586941463
Epoch 0, Loss: 0.40275036012692444
Epoch 0, Loss: 0.3487179750022393
Epoch 0, Loss: 0.3315191014896659
Epoch 0, Loss: 0.3746702265148312
Epoch 0, Loss: 0.3619051525954763
Epoch 0, Loss: 0.3356794871941516
Epoch 0, Loss: 0.3502653801808999
Epoch 0, Loss: 0.3422168758888327
Epoch 0, Loss: 0.33031600361801305
Epoch 0, Loss: 0.38330051544347093
Epoch 0, Loss: 0.3497322016793702
Epoch 0, Loss: 0.358782088743888
Epoch 0, Loss: 0.35041551171143015
Epoch 0, Loss: 0.36647839101228635
Epoch 0, Loss: 0.40232813888923125
Epoch 0, Loss: 0.4262157915560666
Epoch 0, Loss: 0.3619833183847636
Epoch 0, Loss: 0.4049276452170094
Epoch 0, Loss: 0.39401290010615575
Epoch 0, Loss: 0.35783943277251756
Epoch 0, Loss: 0.37715092758610985
Epoch 0, Loss: 0.35421423832057214
Epoch 0, Loss: 0.3364222972786629
Epoch 0, Loss: 0.3761352788444896
Epoch 0, Loss: 0.37841914588930414
Epoch 0, Loss: 0.3453402188522324
Epoch 0, Loss: 0.363918481349769
Epoch 0, Loss: 0.35556857296188793
Epoch 0, Loss: 0.36061142749610514
Epoch 0, Loss: 0.39040112112453845
Epoch 0, Loss: 0.34807015694731136
Epoch 0, Loss: 0.3479003373189782
Epoch 0, Loss: 0.4094009858182604
Epoch 0, Loss: 0.34376964832342305
Epoch 0, Loss: 0.3388314395903117
Epoch 0, Loss: 0.3538107493108768
Epoch 0, Loss: 0.3737280070585631
Epoch 0, Loss: 0.3701060491614233
Epoch 0, Loss: 0.35731234116182237
Epoch 0, Loss: 0.38092402210801407
Epoch 0, Loss: 0.3730517228327825
Epoch 0, Loss: 0.359947292807944
Epoch 0, Loss: 0.33275465454914865
Epoch 0, Loss: 0.39313524484054846
Epoch 0, Loss: 0.33967793569930144
Epoch 0, Loss: 0.3775305390344435
Epoch 0, Loss: 0.34576422710837934
Epoch 0, Loss: 0.33217261726770986
Epoch 0, Loss: 0.37452214001092343
Epoch 0, Loss: 0.39943968070547203
Epoch 0, Loss: 0.3852317767303629
Epoch 0, Loss: 0.3539838633031184
Epoch 0, Loss: 0.36345740380398645
Epoch 0, Loss: 0.32737625353080985
Epoch 0, Loss: 0.4029526316910132
Epoch 0, Loss: 0.3887789367559897
Epoch 0, Loss: 0.3509733435185999
Epoch 0, Loss: 0.32926249034942917
Epoch 0, Loss: 0.343268572530008
Epoch 0, Loss: 0.3205001688445172
Epoch 0, Loss: 0.3745946104914282
Epoch 0, Loss: 0.34904214988696064
Epoch 0, Loss: 0.35733867550986154
Epoch 0, Loss: 0.3207617184344816
Epoch 0, Loss: 0.3545340669016678
Epoch 0, Loss: 0.331427683348565
Epoch 0, Loss: 0.3169418069395284
Epoch 0, Loss: 0.3429950032360294
Epoch 0, Loss: 0.32372551743366784
Epoch 0, Loss: 0.3172990767683815
Epoch 0, Loss: 0.38827395118284885
Epoch 0, Loss: 0.4113582398891423
Epoch 0, Loss: 0.331005204553293
Epoch 0, Loss: 0.3685203784280197
Epoch 0, Loss: 0.3846745944913828
Epoch 0, Loss: 0.3384275151883713
Epoch 0, Loss: 0.37838491266917135
Epoch 0, Loss: 0.37476089806581864
Epoch 0, Loss: 0.3693104190848655
Epoch 0, Loss: 0.3026116299188201
Epoch 0, Loss: 0.35055454284962495
Epoch 0, Loss: 0.3669243986014941
Epoch 0, Loss: 0.36170961162471194
Epoch 0, Loss: 0.3529633792543628
Epoch 0, Loss: 0.37843569162451435
Epoch 0, Loss: 0.3630623604662273
Epoch 0, Loss: 0.3477487076686672
Epoch 0, Loss: 0.3188674441887572
Epoch 0, Loss: 0.3489961888202831
Epoch 0, Loss: 0.3506544646679706
Epoch 0, Loss: 0.3508312718416041
Epoch 0, Loss: 0.3781481337382367
Epoch 0, Loss: 0.37183040652168314
Epoch 0, Loss: 0.3673676608461467
Epoch 0, Loss: 0.3977642189523131
Epoch 0, Loss: 0.39150073756697834
Epoch 0, Loss: 0.34688771204744473
Epoch 0, Loss: 0.3368267194810704
Epoch 0, Loss: 0.373618322285514
2025-03-10 16:34:28,895 - INFO - TREENN1 Epoch 400:
2025-03-10 16:34:28,895 - INFO - Train MSE: 0.2129, Test MSE: 0.3101
2025-03-10 16:34:28,896 - INFO - Train R²: 0.7871, Test R²: 0.6326
2025-03-10 16:34:28,896 - INFO - Train MAE: 0.3311, Test MAE: 0.3767
2025-03-10 16:34:28,896 - INFO - Overfit ratio (train R² / test R²): 1.2442
Epoch 0, Loss: 0.36884963733446946
Epoch 0, Loss: 0.35485581520507586
Epoch 0, Loss: 0.36340310393844555
Epoch 0, Loss: 0.3888425631769922
Epoch 0, Loss: 0.353382410405736
Epoch 0, Loss: 0.36058317522522293
Epoch 0, Loss: 0.369949261613364
Epoch 0, Loss: 0.37298420307549573
Epoch 0, Loss: 0.3981170593488294
Epoch 0, Loss: 0.35930217473975024
Epoch 0, Loss: 0.3700234889332977
Epoch 0, Loss: 0.3691608110703094
Epoch 0, Loss: 0.35953677559487923
Epoch 0, Loss: 0.4159576176239107
Epoch 0, Loss: 0.32504285127018673
Epoch 0, Loss: 0.40291554987975964
Epoch 0, Loss: 0.396435981180063
Epoch 0, Loss: 0.3904371192873703
Epoch 0, Loss: 0.33848323338985203
Epoch 0, Loss: 0.344727786571804
Epoch 0, Loss: 0.33289258558627954
Epoch 0, Loss: 0.385782586607875
Epoch 0, Loss: 0.3386582458151768
Epoch 0, Loss: 0.3574520706877919
Epoch 0, Loss: 0.33239773049280663
Epoch 0, Loss: 0.3477810474966527
Epoch 0, Loss: 0.41240056855784546
Epoch 0, Loss: 0.30336644175567035
Epoch 0, Loss: 0.3029228061014717
Epoch 0, Loss: 0.3492195441710061
Epoch 0, Loss: 0.37122233192582466
Epoch 0, Loss: 0.3989165516783417
Epoch 0, Loss: 0.3216478187420167
Epoch 0, Loss: 0.4066564785339156
Epoch 0, Loss: 0.36471156800594356
Epoch 0, Loss: 0.3359131337780208
Epoch 0, Loss: 0.3383915460919037
Epoch 0, Loss: 0.332452214131294
Epoch 0, Loss: 0.3344827467209089
Epoch 0, Loss: 0.34190514154662494
Epoch 0, Loss: 0.3805097620025316
Epoch 0, Loss: 0.3549876573080099
Epoch 0, Loss: 0.37964797500775826
Epoch 0, Loss: 0.32954066970745255
Epoch 0, Loss: 0.38030605517796967
Epoch 0, Loss: 0.3367101945121009
Epoch 0, Loss: 0.3655110627891853
Epoch 0, Loss: 0.3510599283151348
Epoch 0, Loss: 0.3841385144370211
Epoch 0, Loss: 0.3415257617153898
Epoch 0, Loss: 0.36458305825124443
Epoch 0, Loss: 0.4004015537721283
Epoch 0, Loss: 0.34156592562774835
Epoch 0, Loss: 0.32145195066064736
Epoch 0, Loss: 0.3610772081164692
Epoch 0, Loss: 0.3522950168480615
Epoch 0, Loss: 0.3632350487640411
Epoch 0, Loss: 0.3784747971827529
Epoch 0, Loss: 0.34828501197850265
Epoch 0, Loss: 0.34330063399556093
Epoch 0, Loss: 0.3721790419536782
Epoch 0, Loss: 0.3572334651021323
Epoch 0, Loss: 0.4089757514284527
Epoch 0, Loss: 0.39774167244499903
Epoch 0, Loss: 0.367735287879991
Epoch 0, Loss: 0.3359785131223992
Epoch 0, Loss: 0.31074404257184307
Epoch 0, Loss: 0.33999022627322334
Epoch 0, Loss: 0.34193559526733397
Epoch 0, Loss: 0.32823148457342743
Epoch 0, Loss: 0.3470292884221567
Epoch 0, Loss: 0.3768044952383408
Epoch 0, Loss: 0.33444509996732247
Epoch 0, Loss: 0.35670734806581644
Epoch 0, Loss: 0.38868461841256446
Epoch 0, Loss: 0.3644716707641577
Epoch 0, Loss: 0.34655128810547653
Epoch 0, Loss: 0.3853541210797846
Epoch 0, Loss: 0.38763058060013533
Epoch 0, Loss: 0.31550175124209784
Epoch 0, Loss: 0.3061581533231355
Epoch 0, Loss: 0.4451812531705631
Epoch 0, Loss: 0.3235866941555432
Epoch 0, Loss: 0.3880772156165898
Epoch 0, Loss: 0.3588623932486557
Epoch 0, Loss: 0.3202999715785222
Epoch 0, Loss: 0.3620099752602192
Epoch 0, Loss: 0.4435787685184433
Epoch 0, Loss: 0.3708645717778836
Epoch 0, Loss: 0.3345506014922465
Epoch 0, Loss: 0.3513965216629526
Epoch 0, Loss: 0.3117057010838911
Epoch 0, Loss: 0.3369253484846214
Epoch 0, Loss: 0.32610287263450827
Epoch 0, Loss: 0.37027168285130546
Epoch 0, Loss: 0.29925831196945724
Epoch 0, Loss: 0.32997104586669246
Epoch 0, Loss: 0.39563481625155
Epoch 0, Loss: 0.3315977477784912
Epoch 0, Loss: 0.36599430619258616
2025-03-10 16:34:29,436 - INFO - TREENN1 Epoch 500:
2025-03-10 16:34:29,436 - INFO - Train MSE: 0.2089, Test MSE: 0.3083
2025-03-10 16:34:29,436 - INFO - Train R²: 0.7911, Test R²: 0.6347
2025-03-10 16:34:29,436 - INFO - Train MAE: 0.3286, Test MAE: 0.3753
2025-03-10 16:34:29,436 - INFO - Overfit ratio (train R² / test R²): 1.2464
Epoch 0, Loss: 0.3373541936877754
Epoch 0, Loss: 0.3035272410323045
Epoch 0, Loss: 0.34674534964653564
Epoch 0, Loss: 0.3278165234519627
Epoch 0, Loss: 0.3270946251334001
Epoch 0, Loss: 0.3398560190968024
Epoch 0, Loss: 0.34523905689765005
Epoch 0, Loss: 0.32818553822520236
Epoch 0, Loss: 0.3361296901256558
Epoch 0, Loss: 0.40333591365806926
Epoch 0, Loss: 0.37943153754642317
Epoch 0, Loss: 0.30751298650743253
Epoch 0, Loss: 0.31627960298869356
Epoch 0, Loss: 0.38243099524731783
Epoch 0, Loss: 0.334609151321867
Epoch 0, Loss: 0.3944007821436448
Epoch 0, Loss: 0.38863202548028714
Epoch 0, Loss: 0.3615475140052521
Epoch 0, Loss: 0.3409030345111597
Epoch 0, Loss: 0.3549837647900276
Epoch 0, Loss: 0.34562784090214904
Epoch 0, Loss: 0.3615239236058517
Epoch 0, Loss: 0.3388758156450221
Epoch 0, Loss: 0.3320426115912336
Epoch 0, Loss: 0.3573985108141383
Epoch 0, Loss: 0.36231961304812477
Epoch 0, Loss: 0.32670200985730036
Epoch 0, Loss: 0.35415776496628965
Epoch 0, Loss: 0.3646450084576747
Epoch 0, Loss: 0.33088913756666005
Epoch 0, Loss: 0.3702200241073618
Epoch 0, Loss: 0.41860597945582534
Epoch 0, Loss: 0.3579098566136556
Epoch 0, Loss: 0.3703216959360864
Epoch 0, Loss: 0.34823652007544387
Epoch 0, Loss: 0.34086602792172227
Epoch 0, Loss: 0.3307328704927733
Epoch 0, Loss: 0.32720566009809215
Epoch 0, Loss: 0.3825369647693135
Epoch 0, Loss: 0.3424504227236221
Epoch 0, Loss: 0.3220928037336503
Epoch 0, Loss: 0.35912348185738857
Epoch 0, Loss: 0.3733016126408483
Epoch 0, Loss: 0.35691617969841066
Epoch 0, Loss: 0.3677327181408514
Epoch 0, Loss: 0.3272865473393232
Epoch 0, Loss: 0.3437357284133661
Epoch 0, Loss: 0.33912460885821993
Epoch 0, Loss: 0.34479501840491256
Epoch 0, Loss: 0.39480177476444145
Epoch 0, Loss: 0.3762726515121743
Epoch 0, Loss: 0.3312091037113368
Epoch 0, Loss: 0.34319831915272164
Epoch 0, Loss: 0.39878080566129465
Epoch 0, Loss: 0.39546771600438496
Epoch 0, Loss: 0.3864654461086727
Epoch 0, Loss: 0.30677835793219027
Epoch 0, Loss: 0.3435342877896235
Epoch 0, Loss: 0.3245895343692846
Epoch 0, Loss: 0.41162803377799323
Epoch 0, Loss: 0.3127880156698216
Epoch 0, Loss: 0.37094713914742944
Epoch 0, Loss: 0.33907343166710135
Epoch 0, Loss: 0.39000101985355073
Epoch 0, Loss: 0.34019334306035864
Epoch 0, Loss: 0.35517408515192
Epoch 0, Loss: 0.3372255896557411
Epoch 0, Loss: 0.3587509053116109
Epoch 0, Loss: 0.3782381901514806
Epoch 0, Loss: 0.35130493182832917
Epoch 0, Loss: 0.3966912915715917
Epoch 0, Loss: 0.34952340447795
Epoch 0, Loss: 0.39274854225371647
Epoch 0, Loss: 0.3286402915928941
Epoch 0, Loss: 0.36459896636595907
Epoch 0, Loss: 0.32735813959095306
Epoch 0, Loss: 0.3515299497952989
Epoch 0, Loss: 0.33876997315101076
Epoch 0, Loss: 0.34679674867670784
Epoch 0, Loss: 0.2935386456853588
Epoch 0, Loss: 0.3400032260075586
Epoch 0, Loss: 0.38448558550873535
Epoch 0, Loss: 0.35053311299990336
Epoch 0, Loss: 0.36388747080245076
Epoch 0, Loss: 0.3908751380796383
Epoch 0, Loss: 0.3423299380131589
Epoch 0, Loss: 0.3415861775359065
Epoch 0, Loss: 0.34458224483138034
Epoch 0, Loss: 0.3616805980441748
Epoch 0, Loss: 0.36767574960181
Epoch 0, Loss: 0.3570103749257404
Epoch 0, Loss: 0.3372932052504511
Epoch 0, Loss: 0.3080297457170153
Epoch 0, Loss: 0.3952636458341682
Epoch 0, Loss: 0.3589046018310286
Epoch 0, Loss: 0.31312530487564316
Epoch 0, Loss: 0.26386662961765794
Epoch 0, Loss: 0.3538571771001527
Epoch 0, Loss: 0.4061792444150451
Epoch 0, Loss: 0.3896094347259359
2025-03-10 16:34:29,961 - INFO - TREENN1 Epoch 600:
2025-03-10 16:34:29,961 - INFO - Train MSE: 0.2044, Test MSE: 0.3046
2025-03-10 16:34:29,961 - INFO - Train R²: 0.7956, Test R²: 0.6391
2025-03-10 16:34:29,962 - INFO - Train MAE: 0.3251, Test MAE: 0.3726
2025-03-10 16:34:29,962 - INFO - Overfit ratio (train R² / test R²): 1.2448
Epoch 0, Loss: 0.3306574256270518
Epoch 0, Loss: 0.3150077251241152
Epoch 0, Loss: 0.3704603213760531
Epoch 0, Loss: 0.37564780539614995
Epoch 0, Loss: 0.34914987070652265
Epoch 0, Loss: 0.3066145691405604
Epoch 0, Loss: 0.36982411940011384
Epoch 0, Loss: 0.3316710313179623
Epoch 0, Loss: 0.3336918874178552
Epoch 0, Loss: 0.36881617549927126
Epoch 0, Loss: 0.36403687155888514
Epoch 0, Loss: 0.3615938891081799
Epoch 0, Loss: 0.34956988157497465
Epoch 0, Loss: 0.31548165575851733
Epoch 0, Loss: 0.3306983760883845
Epoch 0, Loss: 0.3693193179031319
Epoch 0, Loss: 0.33035403340114594
Epoch 0, Loss: 0.32219922919273386
Epoch 0, Loss: 0.3532802003507333
Epoch 0, Loss: 0.3495800228761325
Epoch 0, Loss: 0.3192555820711385
Epoch 0, Loss: 0.4050285887609336
Epoch 0, Loss: 0.3272562639387216
Epoch 0, Loss: 0.35564251404689695
Epoch 0, Loss: 0.3906153304078864
Epoch 0, Loss: 0.3105965938954955
Epoch 0, Loss: 0.31847549493530236
Epoch 0, Loss: 0.34675657447032837
Epoch 0, Loss: 0.3132952645004312
Epoch 0, Loss: 0.3440940929306735
Epoch 0, Loss: 0.34285331581111056
Epoch 0, Loss: 0.3630005786622893
Epoch 0, Loss: 0.372630880748639
Epoch 0, Loss: 0.3835348383926366
Epoch 0, Loss: 0.3700606481893041
Epoch 0, Loss: 0.3733847690324587
Epoch 0, Loss: 0.3500117395115178
Epoch 0, Loss: 0.3723538205521658
Epoch 0, Loss: 0.34716199813293513
Epoch 0, Loss: 0.31922208606049546
Epoch 0, Loss: 0.3506171750534031
Epoch 0, Loss: 0.37544635626429507
Epoch 0, Loss: 0.3412787003122865
Epoch 0, Loss: 0.2965043723073052
Epoch 0, Loss: 0.3621787584624174
Epoch 0, Loss: 0.32065175462109957
Epoch 0, Loss: 0.3638639883555809
Epoch 0, Loss: 0.3627408179852446
Epoch 0, Loss: 0.3576882895775186
Epoch 0, Loss: 0.30948714898347357
Epoch 0, Loss: 0.32872231456561135
Epoch 0, Loss: 0.36143120427178116
Epoch 0, Loss: 0.3363937441671096
Epoch 0, Loss: 0.346285542771461
Epoch 0, Loss: 0.3435274816696813
Epoch 0, Loss: 0.31584322348340776
Epoch 0, Loss: 0.35200295623798733
Epoch 0, Loss: 0.3865109367712168
Epoch 0, Loss: 0.2919849246952385
Epoch 0, Loss: 0.3288702525261198
Epoch 0, Loss: 0.36540991954612684
Epoch 0, Loss: 0.3222267201823273
Epoch 0, Loss: 0.3537944381797087
Epoch 0, Loss: 0.29514573929949717
Epoch 0, Loss: 0.2914643866964306
Epoch 0, Loss: 0.3743332704746799
Epoch 0, Loss: 0.39143176119343565
Epoch 0, Loss: 0.3095841398271064
Epoch 0, Loss: 0.36423890452141083
Epoch 0, Loss: 0.3392295617164636
Epoch 0, Loss: 0.3268548437169309
Epoch 0, Loss: 0.37538422350286577
Epoch 0, Loss: 0.2958654189679586
Epoch 0, Loss: 0.39006573611966533
Epoch 0, Loss: 0.3376180074630711
Epoch 0, Loss: 0.3259688915486387
Epoch 0, Loss: 0.33089377625081
Epoch 0, Loss: 0.3194230254843814
Epoch 0, Loss: 0.3221826404958373
Epoch 0, Loss: 0.3984098323549179
Epoch 0, Loss: 0.33705179770706084
Epoch 0, Loss: 0.36888799858887783
Epoch 0, Loss: 0.3837068408633899
Epoch 0, Loss: 0.3369918293015333
Epoch 0, Loss: 0.31926498489130384
Epoch 0, Loss: 0.329483406305466
Epoch 0, Loss: 0.35524305526220823
Epoch 0, Loss: 0.3220522927643373
Epoch 0, Loss: 0.3572284498194823
Epoch 0, Loss: 0.3648075253541432
Epoch 0, Loss: 0.31610643666709676
Epoch 0, Loss: 0.37000146403341494
Epoch 0, Loss: 0.3284439998670442
Epoch 0, Loss: 0.30863385888105715
Epoch 0, Loss: 0.3390444509699359
Epoch 0, Loss: 0.36182219210122796
Epoch 0, Loss: 0.3524645654915294
Epoch 0, Loss: 0.36425712881504596
Epoch 0, Loss: 0.3502254774413834
Epoch 0, Loss: 0.32768154905061825
2025-03-10 16:34:30,470 - INFO - TREENN1 Epoch 700:
2025-03-10 16:34:30,470 - INFO - Train MSE: 0.1943, Test MSE: 0.2957
2025-03-10 16:34:30,470 - INFO - Train R²: 0.8057, Test R²: 0.6497
2025-03-10 16:34:30,470 - INFO - Train MAE: 0.3181, Test MAE: 0.3667
2025-03-10 16:34:30,471 - INFO - Overfit ratio (train R² / test R²): 1.2401
Epoch 0, Loss: 0.35475978902593325
Epoch 0, Loss: 0.35375381603809064
Epoch 0, Loss: 0.38635440582073405
Epoch 0, Loss: 0.34058734932411944
Epoch 0, Loss: 0.38405225577638585
Epoch 0, Loss: 0.40296329896682676
Epoch 0, Loss: 0.3872012112008854
Epoch 0, Loss: 0.36625499140534445
Epoch 0, Loss: 0.31538566439316024
Epoch 0, Loss: 0.36135486646981724
Epoch 0, Loss: 0.34241742166242806
Epoch 0, Loss: 0.3090112403987592
Epoch 0, Loss: 0.3555764172374156
Epoch 0, Loss: 0.3810883498922779
Epoch 0, Loss: 0.34192668671177384
Epoch 0, Loss: 0.3330553398143586
Epoch 0, Loss: 0.2983522907225032
Epoch 0, Loss: 0.2993902602354824
Epoch 0, Loss: 0.35768101120536944
Epoch 0, Loss: 0.30532901220733016
Epoch 0, Loss: 0.34902194568584566
Epoch 0, Loss: 0.32079363118104737
Epoch 0, Loss: 0.3797553457575315
Epoch 0, Loss: 0.3151680387151665
Epoch 0, Loss: 0.35376669482993917
Epoch 0, Loss: 0.3671956697334969
Epoch 0, Loss: 0.38526060281493896
Epoch 0, Loss: 0.3273739879008667
Epoch 0, Loss: 0.3619537435403476
Epoch 0, Loss: 0.3181543299259235
Epoch 0, Loss: 0.36340687417459516
Epoch 0, Loss: 0.3356119375460691
Epoch 0, Loss: 0.3689789966621283
Epoch 0, Loss: 0.34061178400557945
Epoch 0, Loss: 0.3676963433611801
Epoch 0, Loss: 0.3843543209222663
Epoch 0, Loss: 0.3136954253404161
Epoch 0, Loss: 0.36996292153088983
Epoch 0, Loss: 0.3863911035850664
Epoch 0, Loss: 0.29928194346094206
Epoch 0, Loss: 0.29861193263156294
Epoch 0, Loss: 0.35146583912372464
Epoch 0, Loss: 0.32846578878713784
Epoch 0, Loss: 0.36735033892046354
Epoch 0, Loss: 0.31939501373762685
Epoch 0, Loss: 0.3344646645124
Epoch 0, Loss: 0.33171950484583124
Epoch 0, Loss: 0.33970542826461914
Epoch 0, Loss: 0.38887330550144733
Epoch 0, Loss: 0.34852051266387785
Epoch 0, Loss: 0.3047570659349474
Epoch 0, Loss: 0.3772027830153367
Epoch 0, Loss: 0.3342457893049271
Epoch 0, Loss: 0.3412713612493787
Epoch 0, Loss: 0.3599188037952973
Epoch 0, Loss: 0.3475337016101671
Epoch 0, Loss: 0.31870280407573187
Epoch 0, Loss: 0.28427567106535157
Epoch 0, Loss: 0.4039472971475826
Epoch 0, Loss: 0.3239665768561432
Epoch 0, Loss: 0.29643330631732095
Epoch 0, Loss: 0.36551832983783855
Epoch 0, Loss: 0.3340162977109232
Epoch 0, Loss: 0.35646452530985323
Epoch 0, Loss: 0.2933776260130219
Epoch 0, Loss: 0.3147687240257964
Epoch 0, Loss: 0.30668404492507956
Epoch 0, Loss: 0.3648958382057627
Epoch 0, Loss: 0.3595368051107712
Epoch 0, Loss: 0.3320745911120719
Epoch 0, Loss: 0.3406417103771238
Epoch 0, Loss: 0.3804669648645945
Epoch 0, Loss: 0.4031921567632876
Epoch 0, Loss: 0.3221226107880158
Epoch 0, Loss: 0.3484899825923039
Epoch 0, Loss: 0.31925965036089266
Epoch 0, Loss: 0.3639828506868489
Epoch 0, Loss: 0.3490693860777877
Epoch 0, Loss: 0.2931962478444822
Epoch 0, Loss: 0.37277818681965763
Epoch 0, Loss: 0.3722446942264645
Epoch 0, Loss: 0.3358083920560643
Epoch 0, Loss: 0.32135382826188896
Epoch 0, Loss: 0.33210180504110764
Epoch 0, Loss: 0.36910590581034136
Epoch 0, Loss: 0.3723071091633128
Epoch 0, Loss: 0.3125572173475549
Epoch 0, Loss: 0.33244504914958484
Epoch 0, Loss: 0.2976792799949782
Epoch 0, Loss: 0.3436944736012807
Epoch 0, Loss: 0.3362676720688403
Epoch 0, Loss: 0.3391917686411846
Epoch 0, Loss: 0.306307461536768
Epoch 0, Loss: 0.3749305453932406
Epoch 0, Loss: 0.3586045319847974
Epoch 0, Loss: 0.35172877139738556
Epoch 0, Loss: 0.37208475051161544
Epoch 0, Loss: 0.3490238767440589
Epoch 0, Loss: 0.32437547787062226
Epoch 0, Loss: 0.359291527303857
2025-03-10 16:34:30,961 - INFO - TREENN1 Epoch 800:
2025-03-10 16:34:30,961 - INFO - Train MSE: 0.1926, Test MSE: 0.2949
2025-03-10 16:34:30,961 - INFO - Train R²: 0.8074, Test R²: 0.6507
2025-03-10 16:34:30,961 - INFO - Train MAE: 0.3177, Test MAE: 0.3673
2025-03-10 16:34:30,961 - INFO - Overfit ratio (train R² / test R²): 1.2408
Epoch 0, Loss: 0.3188044394356866
Epoch 0, Loss: 0.40579916722069603
Epoch 0, Loss: 0.30367676727782245
Epoch 0, Loss: 0.32875440174803183
Epoch 0, Loss: 0.3170218366002868
Epoch 0, Loss: 0.2745214899318354
Epoch 0, Loss: 0.3084233572616402
Epoch 0, Loss: 0.34710633306951333
Epoch 0, Loss: 0.3471176270483677
Epoch 0, Loss: 0.3031050922371377
Epoch 0, Loss: 0.3358036985262535
Epoch 0, Loss: 0.3577363520859572
Epoch 0, Loss: 0.3424819562723042
Epoch 0, Loss: 0.322130071925524
Epoch 0, Loss: 0.30840936684025344
Epoch 0, Loss: 0.31732367783807547
Epoch 0, Loss: 0.3398092183503105
Epoch 0, Loss: 0.37441033117714373
Epoch 0, Loss: 0.3499003413815157
Epoch 0, Loss: 0.3689660642576406
Epoch 0, Loss: 0.31691891256868543
Epoch 0, Loss: 0.3423762224703856
Epoch 0, Loss: 0.29023910668192915
Epoch 0, Loss: 0.3358196602294757
Epoch 0, Loss: 0.3497170359894984
Epoch 0, Loss: 0.32217934478411087
Epoch 0, Loss: 0.301016406541318
Epoch 0, Loss: 0.3291349971943084
Epoch 0, Loss: 0.29488748537238846
Epoch 0, Loss: 0.3279522010631879
Epoch 0, Loss: 0.32087287436040707
Epoch 0, Loss: 0.32155666124601473
Epoch 0, Loss: 0.36312343993370894
Epoch 0, Loss: 0.36579578921368777
Epoch 0, Loss: 0.3097160145443203
Epoch 0, Loss: 0.3213857772669011
Epoch 0, Loss: 0.346441771963376
Epoch 0, Loss: 0.33274847829327386
Epoch 0, Loss: 0.3182908848214149
Epoch 0, Loss: 0.3589779731782051
Epoch 0, Loss: 0.35253061858760687
Epoch 0, Loss: 0.3309825194204387
Epoch 0, Loss: 0.327006439248792
Epoch 0, Loss: 0.3426120668557058
Epoch 0, Loss: 0.34303708821510126
Epoch 0, Loss: 0.3469781963945044
Epoch 0, Loss: 0.35281584744733774
Epoch 0, Loss: 0.3152423399070314
Epoch 0, Loss: 0.3519385788053821
Epoch 0, Loss: 0.34116048760921613
Epoch 0, Loss: 0.3000735701366014
Epoch 0, Loss: 0.34360047878858657
Epoch 0, Loss: 0.32388438086449084
Epoch 0, Loss: 0.32593354553832266
Epoch 0, Loss: 0.35305454402680003
Epoch 0, Loss: 0.30173038540989716
Epoch 0, Loss: 0.3526773908798351
Epoch 0, Loss: 0.31997204615709673
Epoch 0, Loss: 0.3564282136396988
Epoch 0, Loss: 0.2921239273149991
Epoch 0, Loss: 0.36500281460359296
Epoch 0, Loss: 0.3611766330792823
Epoch 0, Loss: 0.38935074635421596
Epoch 0, Loss: 0.3471569244780037
Epoch 0, Loss: 0.29384087204632076
Epoch 0, Loss: 0.3418715048107161
Epoch 0, Loss: 0.33146895676923305
Epoch 0, Loss: 0.3579243978314266
Epoch 0, Loss: 0.347968784806659
Epoch 0, Loss: 0.37572646661145187
Epoch 0, Loss: 0.2992133032036562
Epoch 0, Loss: 0.331834846335376
Epoch 0, Loss: 0.3246011072955708
Epoch 0, Loss: 0.3278900534751094
Epoch 0, Loss: 0.328857658371105
Epoch 0, Loss: 0.2909180012610568
Epoch 0, Loss: 0.3197201620395979
Epoch 0, Loss: 0.31331708231413713
Epoch 0, Loss: 0.34836823568661535
Epoch 0, Loss: 0.2835128659579164
Epoch 0, Loss: 0.35919752496497315
Epoch 0, Loss: 0.3621884998113156
Epoch 0, Loss: 0.3419841771065683
Epoch 0, Loss: 0.31833145477232755
Epoch 0, Loss: 0.3648518682202808
Epoch 0, Loss: 0.35213337167932796
Epoch 0, Loss: 0.3411253186994916
Epoch 0, Loss: 0.318666806062589
Epoch 0, Loss: 0.34748076020658636
Epoch 0, Loss: 0.34803561006205797
Epoch 0, Loss: 0.35830584796055304
Epoch 0, Loss: 0.29948298899573345
Epoch 0, Loss: 0.3585608681242245
Epoch 0, Loss: 0.32626859509616885
Epoch 0, Loss: 0.3287935610896211
Epoch 0, Loss: 0.33570339670411586
Epoch 0, Loss: 0.3335054156572515
Epoch 0, Loss: 0.3337486001642532
Epoch 0, Loss: 0.3181095011004123
Epoch 0, Loss: 0.38214272233140284
2025-03-10 16:34:31,436 - INFO - TREENN1 Epoch 900:
2025-03-10 16:34:31,437 - INFO - Train MSE: 0.1896, Test MSE: 0.2934
2025-03-10 16:34:31,437 - INFO - Train R²: 0.8104, Test R²: 0.6524
2025-03-10 16:34:31,437 - INFO - Train MAE: 0.3156, Test MAE: 0.3650
2025-03-10 16:34:31,437 - INFO - Overfit ratio (train R² / test R²): 1.2422
Epoch 0, Loss: 0.3396439196085284
Epoch 0, Loss: 0.35315463392434004
Epoch 0, Loss: 0.3394620275261076
Epoch 0, Loss: 0.28682192088693526
Epoch 0, Loss: 0.3493269891967486
Epoch 0, Loss: 0.325154939177392
Epoch 0, Loss: 0.3309048523480053
Epoch 0, Loss: 0.308239589483668
Epoch 0, Loss: 0.3348109511943596
Epoch 0, Loss: 0.34042953820379523
Epoch 0, Loss: 0.35977148281778026
Epoch 0, Loss: 0.34534786760427494
Epoch 0, Loss: 0.2904221426738959
Epoch 0, Loss: 0.30991980430723226
Epoch 0, Loss: 0.2927016428878146
Epoch 0, Loss: 0.3453744800598546
Epoch 0, Loss: 0.3450778513878026
Epoch 0, Loss: 0.34460753059137744
Epoch 0, Loss: 0.3126960187805465
Epoch 0, Loss: 0.3299722012813354
Epoch 0, Loss: 0.32456864165276944
Epoch 0, Loss: 0.3288960256900469
Epoch 0, Loss: 0.34497604783155505
Epoch 0, Loss: 0.33860237241108526
Epoch 0, Loss: 0.3055501345488426
Epoch 0, Loss: 0.32392803425991973
Epoch 0, Loss: 0.3441525738011803
Epoch 0, Loss: 0.32342533124973627
Epoch 0, Loss: 0.30957679640446434
Epoch 0, Loss: 0.35428614460434993
Epoch 0, Loss: 0.29511260103270054
Epoch 0, Loss: 0.32414918346549126
Epoch 0, Loss: 0.2737612219834067
Epoch 0, Loss: 0.3239494098137298
Epoch 0, Loss: 0.34233058147176176
Epoch 0, Loss: 0.3085089222403644
Epoch 0, Loss: 0.28661212674464837
Epoch 0, Loss: 0.3302596188508401
Epoch 0, Loss: 0.34124476912620044
Epoch 0, Loss: 0.3193778312209984
Epoch 0, Loss: 0.2991244611409083
Epoch 0, Loss: 0.3347103607586275
Epoch 0, Loss: 0.3052173440595776
Epoch 0, Loss: 0.37286260181733094
Epoch 0, Loss: 0.2768509508593044
Epoch 0, Loss: 0.3417837444706367
Epoch 0, Loss: 0.3425405271490698
Epoch 0, Loss: 0.40762741524504803
Epoch 0, Loss: 0.29565101837659813
Epoch 0, Loss: 0.41234460710489906
Epoch 0, Loss: 0.292539626553681
Epoch 0, Loss: 0.3224206555783311
Epoch 0, Loss: 0.320810011632737
Epoch 0, Loss: 0.2849284197171402
Epoch 0, Loss: 0.2955650603802785
Epoch 0, Loss: 0.3207497108917384
Epoch 0, Loss: 0.31800110558484923
Epoch 0, Loss: 0.2978439705357768
Epoch 0, Loss: 0.3090400439893841
Epoch 0, Loss: 0.31190438474041876
Epoch 0, Loss: 0.3416492449347435
Epoch 0, Loss: 0.36729477335830163
Epoch 0, Loss: 0.3671680395338783
Epoch 0, Loss: 0.28638170827206044
Epoch 0, Loss: 0.3474396885165879
Epoch 0, Loss: 0.33790179479820637
Epoch 0, Loss: 0.3924537240524133
Epoch 0, Loss: 0.31147151292138653
Epoch 0, Loss: 0.31872026589566077
Epoch 0, Loss: 0.3934373109910268
Epoch 0, Loss: 0.36296809219326354
Epoch 0, Loss: 0.3268600219760245
Epoch 0, Loss: 0.30589801998013655
Epoch 0, Loss: 0.36581736734029036
Epoch 0, Loss: 0.34490646612265125
Epoch 0, Loss: 0.2732176297240335
Epoch 0, Loss: 0.32690059504313645
Epoch 0, Loss: 0.2843710840210756
Epoch 0, Loss: 0.3142732267853852
Epoch 0, Loss: 0.3376162650711059
Epoch 0, Loss: 0.33512665401632513
Epoch 0, Loss: 0.362568243131893
Epoch 0, Loss: 0.31861107364496116
Epoch 0, Loss: 0.3065054504900734
Epoch 0, Loss: 0.34101542553589637
Epoch 0, Loss: 0.32330044387609985
Epoch 0, Loss: 0.3652701946270287
Epoch 0, Loss: 0.3453830258151888
Epoch 0, Loss: 0.2984986246726019
Epoch 0, Loss: 0.3247667460115616
Epoch 0, Loss: 0.31120104141788213
Epoch 0, Loss: 0.3269882336459584
Epoch 0, Loss: 0.30207969313331334
Epoch 0, Loss: 0.29931399589925584
Epoch 0, Loss: 0.3474024104155583
Epoch 0, Loss: 0.30721145372790754
Epoch 0, Loss: 0.30006545897446407
Epoch 0, Loss: 0.3494569926033537
Epoch 0, Loss: 0.3296737860132672
2025-03-10 16:34:31,947 - INFO - TREENN1 Epoch 999:
2025-03-10 16:34:31,947 - INFO - Train MSE: 0.1855, Test MSE: 0.2884
2025-03-10 16:34:31,947 - INFO - Train R²: 0.8145, Test R²: 0.6584
2025-03-10 16:34:31,948 - INFO - Train MAE: 0.3126, Test MAE: 0.3611
2025-03-10 16:34:31,948 - INFO - Overfit ratio (train R² / test R²): 1.2370
2025-03-10 16:34:31,952 - INFO -
TREENN1 Final Metrics:
2025-03-10 16:34:31,952 - INFO - R² Score: 0.6584
2025-03-10 16:34:31,952 - INFO - MAE: 0.3611
2025-03-10 16:34:31,953 - INFO - MSE: 0.2884
2025-03-10 16:34:31,953 - INFO - Train R²: 0.8145
2025-03-10 16:34:31,953 - INFO - Overfit Ratio: 1.2370
2025-03-10 16:34:31,953 - INFO - TREENN1 evaluation successful!
2025-03-10 16:34:31,953 - INFO -
Initializing TREENN2...
2025-03-10 16:34:31,954 - INFO - Model class: TREENN2
2025-03-10 16:34:31,957 - INFO - TREENN2 model initialized successfully!
2025-03-10 16:34:31,957 - INFO - TREENN2 architecture:
2025-03-10 16:34:31,957 - INFO - Input dimension: 12
2025-03-10 16:34:31,957 - INFO - Hidden dimension: 64
2025-03-10 16:34:31,957 - INFO - Output dimension: 1
2025-03-10 16:34:31,958 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:34:31,958 - INFO - Training TREENN2...
Epoch 0, Loss: 1.5162673330119623
2025-03-10 16:34:31,969 - INFO - TREENN2 Epoch 0:
2025-03-10 16:34:31,969 - INFO - Train MSE: 1.2096, Test MSE: 1.1844
2025-03-10 16:34:31,969 - INFO - Train R²: -0.2096, Test R²: -0.4031
2025-03-10 16:34:31,969 - INFO - Train MAE: 0.8468, Test MAE: 0.7800
2025-03-10 16:34:31,970 - INFO - Overfit ratio (train R² / test R²): 0.5199
Epoch 0, Loss: 1.299243400106371
Epoch 0, Loss: 1.2326143836783054
Epoch 0, Loss: 1.1990458894826215
Epoch 0, Loss: 1.039884940232653
Epoch 0, Loss: 1.05629046619368
Epoch 0, Loss: 1.0149178195463266
Epoch 0, Loss: 0.8448171930629208
Epoch 0, Loss: 0.9423138782283875
Epoch 0, Loss: 0.8244022766700695
Epoch 0, Loss: 0.8132855750669454
Epoch 0, Loss: 0.7840212151295007
Epoch 0, Loss: 0.7773871764020998
Epoch 0, Loss: 0.7279960970015462
Epoch 0, Loss: 0.6855855615369617
Epoch 0, Loss: 0.6937784008048549
Epoch 0, Loss: 0.7107109382929229
Epoch 0, Loss: 0.7238086289639191
Epoch 0, Loss: 0.6681209227293425
Epoch 0, Loss: 0.6868159977759669
Epoch 0, Loss: 0.6566249429692484
Epoch 0, Loss: 0.596478914884367
Epoch 0, Loss: 0.6325322353381512
Epoch 0, Loss: 0.5997363435518115
Epoch 0, Loss: 0.6206185441796339
Epoch 0, Loss: 0.6633192948213587
Epoch 0, Loss: 0.5979005398319471
Epoch 0, Loss: 0.6506145479526345
Epoch 0, Loss: 0.5874573856466395
Epoch 0, Loss: 0.5515216531600666
Epoch 0, Loss: 0.5556165736174691
Epoch 0, Loss: 0.500147676982558
Epoch 0, Loss: 0.5535891998389529
Epoch 0, Loss: 0.49162871195758007
Epoch 0, Loss: 0.5812080858820412
Epoch 0, Loss: 0.5299295209695892
Epoch 0, Loss: 0.5424098078473943
Epoch 0, Loss: 0.5099798227993443
Epoch 0, Loss: 0.514325495851225
Epoch 0, Loss: 0.520366577822794
Epoch 0, Loss: 0.5430935507461502
Epoch 0, Loss: 0.549403684117057
Epoch 0, Loss: 0.4719008913177848
Epoch 0, Loss: 0.49533341365598793
Epoch 0, Loss: 0.4945723827358909
Epoch 0, Loss: 0.5064215934974665
Epoch 0, Loss: 0.5380571336480857
Epoch 0, Loss: 0.5355049290509595
Epoch 0, Loss: 0.44421479971453987
Epoch 0, Loss: 0.5474946972234798
Epoch 0, Loss: 0.5037456505090412
Epoch 0, Loss: 0.4940957730471383
Epoch 0, Loss: 0.5053235214205447
Epoch 0, Loss: 0.4507366473670523
Epoch 0, Loss: 0.4930778115855651
Epoch 0, Loss: 0.4385608695466685
Epoch 0, Loss: 0.43432168831069035
Epoch 0, Loss: 0.48609358485943654
Epoch 0, Loss: 0.48135475370477987
Epoch 0, Loss: 0.477937634134194
Epoch 0, Loss: 0.409314822752342
Epoch 0, Loss: 0.4690664548154647
Epoch 0, Loss: 0.4908864184177361
Epoch 0, Loss: 0.48014688988040766
Epoch 0, Loss: 0.4570376191361415
Epoch 0, Loss: 0.466701669764348
Epoch 0, Loss: 0.46381211337862516
Epoch 0, Loss: 0.4973414233614686
Epoch 0, Loss: 0.4673287041226981
Epoch 0, Loss: 0.44215845833160095
Epoch 0, Loss: 0.43716263208190165
Epoch 0, Loss: 0.44465777696848063
Epoch 0, Loss: 0.4810581904289767
Epoch 0, Loss: 0.48696519558015805
Epoch 0, Loss: 0.4240271579935067
Epoch 0, Loss: 0.4224505367466907
Epoch 0, Loss: 0.452059389672541
Epoch 0, Loss: 0.41461409251533815
Epoch 0, Loss: 0.40141455111571106
Epoch 0, Loss: 0.39034175303607793
Epoch 0, Loss: 0.4286175926637283
Epoch 0, Loss: 0.4348657703422518
Epoch 0, Loss: 0.44504674783955567
Epoch 0, Loss: 0.4182403417818858
Epoch 0, Loss: 0.44643963704121264
Epoch 0, Loss: 0.39422113947512505
Epoch 0, Loss: 0.46785300052709833
Epoch 0, Loss: 0.4903990684132899
Epoch 0, Loss: 0.49622322130406654
Epoch 0, Loss: 0.41811673094278806
Epoch 0, Loss: 0.4386952427855616
Epoch 0, Loss: 0.4756168437473388
Epoch 0, Loss: 0.4482958594230184
Epoch 0, Loss: 0.4272230332940587
Epoch 0, Loss: 0.4171147390608527
Epoch 0, Loss: 0.44644107908421443
Epoch 0, Loss: 0.42167521612104697
Epoch 0, Loss: 0.42976756669578803
Epoch 0, Loss: 0.4106419181306769
Epoch 0, Loss: 0.4711001323156842
Epoch 0, Loss: 0.4374233252466816
2025-03-10 16:34:32,547 - INFO - TREENN2 Epoch 100:
2025-03-10 16:34:32,547 - INFO - Train MSE: 0.2865, Test MSE: 0.3135
2025-03-10 16:34:32,547 - INFO - Train R²: 0.7135, Test R²: 0.6287
2025-03-10 16:34:32,548 - INFO - Train MAE: 0.3872, Test MAE: 0.3739
2025-03-10 16:34:32,548 - INFO - Overfit ratio (train R² / test R²): 1.1349
Epoch 0, Loss: 0.368932486410843
Epoch 0, Loss: 0.41934924971909293
Epoch 0, Loss: 0.45718078141704654
Epoch 0, Loss: 0.39537624094395424
Epoch 0, Loss: 0.40701178283977624
Epoch 0, Loss: 0.43207753115502784
Epoch 0, Loss: 0.41047628923916957
Epoch 0, Loss: 0.4662578350786236
Epoch 0, Loss: 0.4662705333449572
Epoch 0, Loss: 0.4486919547197561
Epoch 0, Loss: 0.4168959213951732
Epoch 0, Loss: 0.46202704214397594
Epoch 0, Loss: 0.4258249474256572
Epoch 0, Loss: 0.40430728709798525
Epoch 0, Loss: 0.420997088115595
Epoch 0, Loss: 0.41544193484259095
Epoch 0, Loss: 0.425616776098854
Epoch 0, Loss: 0.3882468282776297
Epoch 0, Loss: 0.4361013474077672
Epoch 0, Loss: 0.40226493883325304
Epoch 0, Loss: 0.3981636088318504
Epoch 0, Loss: 0.3550101598122682
Epoch 0, Loss: 0.4210643300195963
Epoch 0, Loss: 0.3873081336769468
Epoch 0, Loss: 0.4623195483368836
Epoch 0, Loss: 0.41521943525405225
Epoch 0, Loss: 0.3935371880074504
Epoch 0, Loss: 0.426516777066874
Epoch 0, Loss: 0.39890307995636404
Epoch 0, Loss: 0.4379200113749834
Epoch 0, Loss: 0.40604777875323533
Epoch 0, Loss: 0.42548528295279125
Epoch 0, Loss: 0.3773804900636825
Epoch 0, Loss: 0.3856056228400057
Epoch 0, Loss: 0.40753913142014636
Epoch 0, Loss: 0.39199784577080704
Epoch 0, Loss: 0.3827669282344427
Epoch 0, Loss: 0.3622645941826256
Epoch 0, Loss: 0.4225658337677905
Epoch 0, Loss: 0.3454248911969679
Epoch 0, Loss: 0.450985527403808
Epoch 0, Loss: 0.43597310843069753
Epoch 0, Loss: 0.41557894223761577
Epoch 0, Loss: 0.42157434945505823
Epoch 0, Loss: 0.4013745295800058
Epoch 0, Loss: 0.356304188264456
Epoch 0, Loss: 0.3965977705218402
Epoch 0, Loss: 0.40548656984990644
Epoch 0, Loss: 0.3949001906622145
Epoch 0, Loss: 0.40052417436474047
Epoch 0, Loss: 0.3517854630518237
Epoch 0, Loss: 0.35001498991086644
Epoch 0, Loss: 0.3826044326861695
Epoch 0, Loss: 0.3603198499499849
Epoch 0, Loss: 0.4353784348171592
Epoch 0, Loss: 0.38566551306510677
Epoch 0, Loss: 0.4227944527750983
Epoch 0, Loss: 0.38806551724832344
Epoch 0, Loss: 0.42333474952828376
Epoch 0, Loss: 0.3885319923511756
Epoch 0, Loss: 0.40345790681994154
Epoch 0, Loss: 0.3823450970968204
Epoch 0, Loss: 0.38426950105150026
Epoch 0, Loss: 0.4367215216091618
Epoch 0, Loss: 0.38885121012267965
Epoch 0, Loss: 0.36517343096868454
Epoch 0, Loss: 0.4430696370402717
Epoch 0, Loss: 0.3730771505837572
Epoch 0, Loss: 0.4412402217262088
Epoch 0, Loss: 0.41539623465042935
Epoch 0, Loss: 0.44968170405733393
Epoch 0, Loss: 0.36278952818490917
Epoch 0, Loss: 0.3953380508064887
Epoch 0, Loss: 0.4123586588639927
Epoch 0, Loss: 0.3700282534465733
Epoch 0, Loss: 0.3811766492043188
Epoch 0, Loss: 0.38386530591810153
Epoch 0, Loss: 0.38876562978730206
Epoch 0, Loss: 0.40288837847814746
Epoch 0, Loss: 0.423797273671327
Epoch 0, Loss: 0.37939720855244957
Epoch 0, Loss: 0.3644576299154604
Epoch 0, Loss: 0.38386256491486015
Epoch 0, Loss: 0.3923920184421316
Epoch 0, Loss: 0.3787319980040206
Epoch 0, Loss: 0.3626455598380821
Epoch 0, Loss: 0.43126873025936113
Epoch 0, Loss: 0.40268719451718255
Epoch 0, Loss: 0.38574514538167237
Epoch 0, Loss: 0.42893221828883443
Epoch 0, Loss: 0.35792697401694795
Epoch 0, Loss: 0.38359828515908007
Epoch 0, Loss: 0.40966255556718223
Epoch 0, Loss: 0.3922271082566603
Epoch 0, Loss: 0.42741943861626575
Epoch 0, Loss: 0.4165523487024067
Epoch 0, Loss: 0.3608468623136103
Epoch 0, Loss: 0.3224914437016226
Epoch 0, Loss: 0.3752437581877796
Epoch 0, Loss: 0.4287083698039627
2025-03-10 16:34:33,164 - INFO - TREENN2 Epoch 200:
2025-03-10 16:34:33,164 - INFO - Train MSE: 0.2385, Test MSE: 0.2587
2025-03-10 16:34:33,164 - INFO - Train R²: 0.7615, Test R²: 0.6936
2025-03-10 16:34:33,164 - INFO - Train MAE: 0.3487, Test MAE: 0.3364
2025-03-10 16:34:33,164 - INFO - Overfit ratio (train R² / test R²): 1.0980
Epoch 0, Loss: 0.3960954482986441
Epoch 0, Loss: 0.38180804365797927
Epoch 0, Loss: 0.4623003793525372
Epoch 0, Loss: 0.4067483256669755
Epoch 0, Loss: 0.34435916461460736
Epoch 0, Loss: 0.4097099291036589
Epoch 0, Loss: 0.41204423112636834
Epoch 0, Loss: 0.3420995196837613
Epoch 0, Loss: 0.40751197384395604
Epoch 0, Loss: 0.3894071707603857
Epoch 0, Loss: 0.403273777509127
Epoch 0, Loss: 0.40281492668565205
Epoch 0, Loss: 0.38734076896105046
Epoch 0, Loss: 0.3721360670526276
Epoch 0, Loss: 0.38727181523833065
Epoch 0, Loss: 0.3947001879271989
Epoch 0, Loss: 0.393560985592244
Epoch 0, Loss: 0.36739854556065965
Epoch 0, Loss: 0.40971419692016214
Epoch 0, Loss: 0.3971499750507888
Epoch 0, Loss: 0.45018856107696276
Epoch 0, Loss: 0.3782182899680178
Epoch 0, Loss: 0.39080985976375965
Epoch 0, Loss: 0.3493261696151913
Epoch 0, Loss: 0.4068867744841111
Epoch 0, Loss: 0.3619141568740501
Epoch 0, Loss: 0.35159780669216434
Epoch 0, Loss: 0.42683872168172565
Epoch 0, Loss: 0.3789111245340322
Epoch 0, Loss: 0.4076403309297544
Epoch 0, Loss: 0.3676455602480962
Epoch 0, Loss: 0.3912304127499022
Epoch 0, Loss: 0.3729245844673751
Epoch 0, Loss: 0.4310533108558
Epoch 0, Loss: 0.3225133391785196
Epoch 0, Loss: 0.4275876724747955
Epoch 0, Loss: 0.363938004844306
Epoch 0, Loss: 0.3995736314771918
Epoch 0, Loss: 0.40105090081984657
Epoch 0, Loss: 0.3565005891242716
Epoch 0, Loss: 0.3972191298748827
Epoch 0, Loss: 0.36001875265087285
Epoch 0, Loss: 0.36735343851767616
Epoch 0, Loss: 0.38172528202401784
Epoch 0, Loss: 0.40526816060828647
Epoch 0, Loss: 0.37746425249659243
Epoch 0, Loss: 0.3686425021141122
Epoch 0, Loss: 0.37010626091853155
Epoch 0, Loss: 0.38392285961900036
Epoch 0, Loss: 0.3988818791863058
Epoch 0, Loss: 0.344501385424462
Epoch 0, Loss: 0.3845065133908379
Epoch 0, Loss: 0.3718394209988192
Epoch 0, Loss: 0.32813373070122515
Epoch 0, Loss: 0.3124694485064516
Epoch 0, Loss: 0.3493546501074567
Epoch 0, Loss: 0.35381562048375986
Epoch 0, Loss: 0.3523448771244803
Epoch 0, Loss: 0.3998104695113116
Epoch 0, Loss: 0.3789335986836774
Epoch 0, Loss: 0.36658492372295387
Epoch 0, Loss: 0.3738094797579949
Epoch 0, Loss: 0.377738507478005
Epoch 0, Loss: 0.3663518204281283
Epoch 0, Loss: 0.3332592571387378
Epoch 0, Loss: 0.41775405805241606
Epoch 0, Loss: 0.34196720207269776
Epoch 0, Loss: 0.3818648422178833
Epoch 0, Loss: 0.38307398806547655
Epoch 0, Loss: 0.3451573320634135
Epoch 0, Loss: 0.4101892509473977
Epoch 0, Loss: 0.35266491908631403
Epoch 0, Loss: 0.36505336750866674
Epoch 0, Loss: 0.43343837112780625
Epoch 0, Loss: 0.37322545056808276
Epoch 0, Loss: 0.37066263612474154
Epoch 0, Loss: 0.42321966534433736
Epoch 0, Loss: 0.3268446834293817
Epoch 0, Loss: 0.31752653854834256
Epoch 0, Loss: 0.3810151236596424
Epoch 0, Loss: 0.3548276277603677
Epoch 0, Loss: 0.3816759679433067
Epoch 0, Loss: 0.3189672928087292
Epoch 0, Loss: 0.3561641396354815
Epoch 0, Loss: 0.3328113795072499
Epoch 0, Loss: 0.3559392462142925
Epoch 0, Loss: 0.3741934370862021
Epoch 0, Loss: 0.3063327136450476
Epoch 0, Loss: 0.3429062972584651
Epoch 0, Loss: 0.3636017634148242
Epoch 0, Loss: 0.38653347735343646
Epoch 0, Loss: 0.3930577083303453
Epoch 0, Loss: 0.3899721673741626
Epoch 0, Loss: 0.3344646611420861
Epoch 0, Loss: 0.36811546066785045
Epoch 0, Loss: 0.41781314811679626
Epoch 0, Loss: 0.37116879118110213
Epoch 0, Loss: 0.4056204562769269
Epoch 0, Loss: 0.3774257259939673
Epoch 0, Loss: 0.4499344563794959
2025-03-10 16:34:33,740 - INFO - TREENN2 Epoch 300:
2025-03-10 16:34:33,740 - INFO - Train MSE: 0.2132, Test MSE: 0.2355
2025-03-10 16:34:33,741 - INFO - Train R²: 0.7868, Test R²: 0.7210
2025-03-10 16:34:33,741 - INFO - Train MAE: 0.3293, Test MAE: 0.3201
2025-03-10 16:34:33,741 - INFO - Overfit ratio (train R² / test R²): 1.0913
Epoch 0, Loss: 0.3532457334857355
Epoch 0, Loss: 0.3138530886352654
Epoch 0, Loss: 0.4170459867691068
Epoch 0, Loss: 0.3517161140659045
Epoch 0, Loss: 0.3876423189557907
Epoch 0, Loss: 0.34092318053332393
Epoch 0, Loss: 0.44166987123241347
Epoch 0, Loss: 0.41723331787504125
Epoch 0, Loss: 0.37749867331327586
Epoch 0, Loss: 0.30685230945484887
Epoch 0, Loss: 0.3730382026154055
Epoch 0, Loss: 0.3446648474182647
Epoch 0, Loss: 0.34929514464702355
Epoch 0, Loss: 0.37947189413348625
Epoch 0, Loss: 0.3988992285424921
Epoch 0, Loss: 0.316829197987895
Epoch 0, Loss: 0.3247321724328393
Epoch 0, Loss: 0.3508764249641174
Epoch 0, Loss: 0.44416118347489003
Epoch 0, Loss: 0.337749434746789
Epoch 0, Loss: 0.35840592332437
Epoch 0, Loss: 0.3798945473116256
Epoch 0, Loss: 0.3666410959258033
Epoch 0, Loss: 0.391175071272624
Epoch 0, Loss: 0.3789345576115445
Epoch 0, Loss: 0.3776439389826786
Epoch 0, Loss: 0.4155177142242391
Epoch 0, Loss: 0.39457761431339305
Epoch 0, Loss: 0.3458052833077341
Epoch 0, Loss: 0.3967997616986052
Epoch 0, Loss: 0.39190140109447985
Epoch 0, Loss: 0.33647808886429664
Epoch 0, Loss: 0.31893026121888735
Epoch 0, Loss: 0.3715200587125087
Epoch 0, Loss: 0.3181826815946471
Epoch 0, Loss: 0.423345774344187
Epoch 0, Loss: 0.38842229443112597
Epoch 0, Loss: 0.32398121916102773
Epoch 0, Loss: 0.3042861872303563
Epoch 0, Loss: 0.401516069467783
Epoch 0, Loss: 0.389603083723052
Epoch 0, Loss: 0.3385412280631101
Epoch 0, Loss: 0.4184242999334923
Epoch 0, Loss: 0.3760246260255108
Epoch 0, Loss: 0.4167356868594526
Epoch 0, Loss: 0.34731170756716423
Epoch 0, Loss: 0.3160528247394013
Epoch 0, Loss: 0.3546681859986792
Epoch 0, Loss: 0.33350816734588357
Epoch 0, Loss: 0.34932357620961085
Epoch 0, Loss: 0.3402143262048854
Epoch 0, Loss: 0.36210735310557246
Epoch 0, Loss: 0.3666478867004971
Epoch 0, Loss: 0.3322249667433767
Epoch 0, Loss: 0.38479828205287203
Epoch 0, Loss: 0.4182715782313414
Epoch 0, Loss: 0.39482057366248946
Epoch 0, Loss: 0.36299131131006934
Epoch 0, Loss: 0.362257910688164
Epoch 0, Loss: 0.3543498079620328
Epoch 0, Loss: 0.40838479081621387
Epoch 0, Loss: 0.34042076436699054
Epoch 0, Loss: 0.36799766855796107
Epoch 0, Loss: 0.38853846082560306
Epoch 0, Loss: 0.3757174827449967
Epoch 0, Loss: 0.3949055839223519
Epoch 0, Loss: 0.3911963212881848
Epoch 0, Loss: 0.34243587057634495
Epoch 0, Loss: 0.4021432435806707
Epoch 0, Loss: 0.3962845387125835
Epoch 0, Loss: 0.3607057434784936
Epoch 0, Loss: 0.3512850246568925
Epoch 0, Loss: 0.35638181697411864
Epoch 0, Loss: 0.3734838317979801
Epoch 0, Loss: 0.33861273170280237
Epoch 0, Loss: 0.30999589147540935
Epoch 0, Loss: 0.39952208272920897
Epoch 0, Loss: 0.32598972064239945
Epoch 0, Loss: 0.34075173665164016
Epoch 0, Loss: 0.3513999024627983
Epoch 0, Loss: 0.39382266840819946
Epoch 0, Loss: 0.35314027512173507
Epoch 0, Loss: 0.3604678086306477
Epoch 0, Loss: 0.39708872296651015
Epoch 0, Loss: 0.3371052418565759
Epoch 0, Loss: 0.34960383432980224
Epoch 0, Loss: 0.3847316256275726
Epoch 0, Loss: 0.4130023697940547
Epoch 0, Loss: 0.3798545727900017
Epoch 0, Loss: 0.374681334289481
Epoch 0, Loss: 0.3436290222714081
Epoch 0, Loss: 0.39494887190800565
Epoch 0, Loss: 0.35680799079689923
Epoch 0, Loss: 0.3540573190023711
Epoch 0, Loss: 0.3561274945262567
Epoch 0, Loss: 0.3350761069070359
Epoch 0, Loss: 0.34115384226136103
Epoch 0, Loss: 0.3519383881938506
Epoch 0, Loss: 0.36377498948407333
Epoch 0, Loss: 0.3472566636347571
2025-03-10 16:34:34,323 - INFO - TREENN2 Epoch 400:
2025-03-10 16:34:34,324 - INFO - Train MSE: 0.1989, Test MSE: 0.2259
2025-03-10 16:34:34,324 - INFO - Train R²: 0.8011, Test R²: 0.7324
2025-03-10 16:34:34,324 - INFO - Train MAE: 0.3185, Test MAE: 0.3132
2025-03-10 16:34:34,324 - INFO - Overfit ratio (train R² / test R²): 1.0939
Epoch 0, Loss: 0.33903288067835063
Epoch 0, Loss: 0.358851923679841
Epoch 0, Loss: 0.363657127769019
Epoch 0, Loss: 0.34640457414938414
Epoch 0, Loss: 0.38807267765906406
Epoch 0, Loss: 0.37370278129806
Epoch 0, Loss: 0.3384019266942413
Epoch 0, Loss: 0.3700146290534322
Epoch 0, Loss: 0.3650010547381147
Epoch 0, Loss: 0.35079084363166424
Epoch 0, Loss: 0.41171150903014553
Epoch 0, Loss: 0.38780322017205104
Epoch 0, Loss: 0.36748420681487576
Epoch 0, Loss: 0.3588865991870555
Epoch 0, Loss: 0.3857672395265016
Epoch 0, Loss: 0.36358067630234736
Epoch 0, Loss: 0.33343197009839015
Epoch 0, Loss: 0.3730133850502658
Epoch 0, Loss: 0.36118221264950356
Epoch 0, Loss: 0.3724240856817816
Epoch 0, Loss: 0.35361261705205094
Epoch 0, Loss: 0.36525017501085516
Epoch 0, Loss: 0.384400891651757
Epoch 0, Loss: 0.3277654962302093
Epoch 0, Loss: 0.3083891557123879
Epoch 0, Loss: 0.36283257366940747
Epoch 0, Loss: 0.37519699200083734
Epoch 0, Loss: 0.33636579012409423
Epoch 0, Loss: 0.3384863745514547
Epoch 0, Loss: 0.3810999473070161
Epoch 0, Loss: 0.334280325241613
Epoch 0, Loss: 0.3779712614592234
Epoch 0, Loss: 0.4090898021204638
Epoch 0, Loss: 0.36095925170443194
Epoch 0, Loss: 0.36132681041555426
Epoch 0, Loss: 0.384880872461525
Epoch 0, Loss: 0.34833826801234785
Epoch 0, Loss: 0.3896892318885789
Epoch 0, Loss: 0.3452514380794269
Epoch 0, Loss: 0.35518992775375774
Epoch 0, Loss: 0.35442941717164206
Epoch 0, Loss: 0.34166234601231565
Epoch 0, Loss: 0.36118778004818275
Epoch 0, Loss: 0.34472459825082574
Epoch 0, Loss: 0.3109187252543063
Epoch 0, Loss: 0.36416815769308886
Epoch 0, Loss: 0.3670912688734723
Epoch 0, Loss: 0.3387596167367312
Epoch 0, Loss: 0.35005105087888105
Epoch 0, Loss: 0.3590414722834439
Epoch 0, Loss: 0.38701301698866236
Epoch 0, Loss: 0.32597083507883595
Epoch 0, Loss: 0.3715430172119335
Epoch 0, Loss: 0.30771456904926103
Epoch 0, Loss: 0.3435165703322413
Epoch 0, Loss: 0.3901637034006544
Epoch 0, Loss: 0.3860397606894873
Epoch 0, Loss: 0.32337367661059974
Epoch 0, Loss: 0.3666161597875141
Epoch 0, Loss: 0.3812339271072842
Epoch 0, Loss: 0.3557059452033193
Epoch 0, Loss: 0.4077995745060008
Epoch 0, Loss: 0.37393096010079907
Epoch 0, Loss: 0.35106190391957126
Epoch 0, Loss: 0.3668256701273222
Epoch 0, Loss: 0.32235061624755074
Epoch 0, Loss: 0.3576696113727838
Epoch 0, Loss: 0.35058265392638216
Epoch 0, Loss: 0.3316188050874249
Epoch 0, Loss: 0.34743311858340276
Epoch 0, Loss: 0.3590155966877228
Epoch 0, Loss: 0.3448179466228143
Epoch 0, Loss: 0.3290234866121671
Epoch 0, Loss: 0.35257207430813303
Epoch 0, Loss: 0.3838615090529761
Epoch 0, Loss: 0.36646294210495206
Epoch 0, Loss: 0.35685977166117583
Epoch 0, Loss: 0.3086309321455251
Epoch 0, Loss: 0.3457991101571986
Epoch 0, Loss: 0.3349718980835842
Epoch 0, Loss: 0.3393392965816315
Epoch 0, Loss: 0.3646090185758447
Epoch 0, Loss: 0.3326225975010795
Epoch 0, Loss: 0.3295509469675846
Epoch 0, Loss: 0.34345692150305923
Epoch 0, Loss: 0.35766239953755224
Epoch 0, Loss: 0.3627560781793865
Epoch 0, Loss: 0.34001252037210417
Epoch 0, Loss: 0.35666085935269837
Epoch 0, Loss: 0.36010881909875503
Epoch 0, Loss: 0.3870041974881239
Epoch 0, Loss: 0.3542938727488215
Epoch 0, Loss: 0.31793833314837966
Epoch 0, Loss: 0.37549081540092705
Epoch 0, Loss: 0.31377075514191244
Epoch 0, Loss: 0.32528031419547615
Epoch 0, Loss: 0.3485299568009039
Epoch 0, Loss: 0.3642701407150611
Epoch 0, Loss: 0.4008779960999268
Epoch 0, Loss: 0.39327681766788686
2025-03-10 16:34:34,906 - INFO - TREENN2 Epoch 500:
2025-03-10 16:34:34,906 - INFO - Train MSE: 0.1918, Test MSE: 0.2208
2025-03-10 16:34:34,906 - INFO - Train R²: 0.8082, Test R²: 0.7385
2025-03-10 16:34:34,906 - INFO - Train MAE: 0.3121, Test MAE: 0.3075
2025-03-10 16:34:34,906 - INFO - Overfit ratio (train R² / test R²): 1.0945
Epoch 0, Loss: 0.3715028413231863
Epoch 0, Loss: 0.33992754097629513
Epoch 0, Loss: 0.3850573649589529
Epoch 0, Loss: 0.3246709941770794
Epoch 0, Loss: 0.37227435906012035
Epoch 0, Loss: 0.3572515475398584
Epoch 0, Loss: 0.3439792109587268
Epoch 0, Loss: 0.3285150222318726
Epoch 0, Loss: 0.3543143694983442
Epoch 0, Loss: 0.36278763150833926
Epoch 0, Loss: 0.38679399308138124
Epoch 0, Loss: 0.3715326982792175
Epoch 0, Loss: 0.32481161355634364
Epoch 0, Loss: 0.4006251241734396
Epoch 0, Loss: 0.3237108767882395
Epoch 0, Loss: 0.38906734137342674
Epoch 0, Loss: 0.35355893153975143
Epoch 0, Loss: 0.292231765406862
Epoch 0, Loss: 0.3784342187551863
Epoch 0, Loss: 0.317498992436645
Epoch 0, Loss: 0.3234702499617482
Epoch 0, Loss: 0.39665286414250744
Epoch 0, Loss: 0.34219385145692083
Epoch 0, Loss: 0.353251267975692
Epoch 0, Loss: 0.33963883611113543
Epoch 0, Loss: 0.3767476306463129
Epoch 0, Loss: 0.4012451300184223
Epoch 0, Loss: 0.32468610271303244
Epoch 0, Loss: 0.3339057620805609
Epoch 0, Loss: 0.3332704938755066
Epoch 0, Loss: 0.33411401471365093
Epoch 0, Loss: 0.38982230318035643
Epoch 0, Loss: 0.3428182569821896
Epoch 0, Loss: 0.34822967853069897
Epoch 0, Loss: 0.3496065546157729
Epoch 0, Loss: 0.33420536804944695
Epoch 0, Loss: 0.3479101018934998
Epoch 0, Loss: 0.3309941342941905
Epoch 0, Loss: 0.40075175836213145
Epoch 0, Loss: 0.34683009471876325
Epoch 0, Loss: 0.37451744386616626
Epoch 0, Loss: 0.32948313962700676
Epoch 0, Loss: 0.35699382418865905
Epoch 0, Loss: 0.319207690462049
Epoch 0, Loss: 0.31189080717085677
Epoch 0, Loss: 0.3322469088178589
Epoch 0, Loss: 0.28979479056211266
Epoch 0, Loss: 0.36128368126295957
Epoch 0, Loss: 0.34966037454165233
Epoch 0, Loss: 0.337341778969595
Epoch 0, Loss: 0.33699338704106463
Epoch 0, Loss: 0.33470418510455235
Epoch 0, Loss: 0.30219951112163224
Epoch 0, Loss: 0.36349346028903246
Epoch 0, Loss: 0.3987632412573621
Epoch 0, Loss: 0.40641206710201
Epoch 0, Loss: 0.32525978128693456
Epoch 0, Loss: 0.3470303241893449
Epoch 0, Loss: 0.3182140437290139
Epoch 0, Loss: 0.29943939258245156
Epoch 0, Loss: 0.3322933286157521
Epoch 0, Loss: 0.33319775482369507
Epoch 0, Loss: 0.3709904173232522
Epoch 0, Loss: 0.3485989788112584
Epoch 0, Loss: 0.33971411084807673
Epoch 0, Loss: 0.3367171384639486
Epoch 0, Loss: 0.3671041728893853
Epoch 0, Loss: 0.3435326182680371
Epoch 0, Loss: 0.3275287117777421
Epoch 0, Loss: 0.3322994573375805
Epoch 0, Loss: 0.27200519786696253
Epoch 0, Loss: 0.40171311710323876
Epoch 0, Loss: 0.3155158291214562
Epoch 0, Loss: 0.32967924849471525
Epoch 0, Loss: 0.33941984377403267
Epoch 0, Loss: 0.34170606066338083
Epoch 0, Loss: 0.3103665594995403
Epoch 0, Loss: 0.3632620132626637
Epoch 0, Loss: 0.2904277831942268
Epoch 0, Loss: 0.3355720991350698
Epoch 0, Loss: 0.3782879112821484
Epoch 0, Loss: 0.3754111886253735
Epoch 0, Loss: 0.33261185198328463
Epoch 0, Loss: 0.3634369519189364
Epoch 0, Loss: 0.3777376417166002
Epoch 0, Loss: 0.3350555669195676
Epoch 0, Loss: 0.3640213195201057
Epoch 0, Loss: 0.32759931332933057
Epoch 0, Loss: 0.3477832307736485
Epoch 0, Loss: 0.3602479037330444
Epoch 0, Loss: 0.363435314703002
Epoch 0, Loss: 0.3395844256883952
Epoch 0, Loss: 0.36875945611487554
Epoch 0, Loss: 0.3967550390509425
Epoch 0, Loss: 0.3328060133852941
Epoch 0, Loss: 0.3619149987226617
Epoch 0, Loss: 0.31842911362599546
Epoch 0, Loss: 0.3671985284917951
Epoch 0, Loss: 0.3477824312438405
Epoch 0, Loss: 0.3844677139390109
2025-03-10 16:34:35,488 - INFO - TREENN2 Epoch 600:
2025-03-10 16:34:35,488 - INFO - Train MSE: 0.1858, Test MSE: 0.2163
2025-03-10 16:34:35,489 - INFO - Train R²: 0.8142, Test R²: 0.7438
2025-03-10 16:34:35,489 - INFO - Train MAE: 0.3077, Test MAE: 0.3044
2025-03-10 16:34:35,489 - INFO - Overfit ratio (train R² / test R²): 1.0947
Epoch 0, Loss: 0.3458569170177504
Epoch 0, Loss: 0.33565792119244914
Epoch 0, Loss: 0.33976308339839634
Epoch 0, Loss: 0.33545051368103385
Epoch 0, Loss: 0.30132628543637063
Epoch 0, Loss: 0.3277155678193705
Epoch 0, Loss: 0.3774295631150921
Epoch 0, Loss: 0.3116918625565932
Epoch 0, Loss: 0.3163181802213784
Epoch 0, Loss: 0.36618765838204864
Epoch 0, Loss: 0.3104523990361441
Epoch 0, Loss: 0.336692399403457
Epoch 0, Loss: 0.3636764819529571
Epoch 0, Loss: 0.3400082552532424
Epoch 0, Loss: 0.37709429635410613
Epoch 0, Loss: 0.3404078795458332
Epoch 0, Loss: 0.3384450304963755
Epoch 0, Loss: 0.334256680290108
Epoch 0, Loss: 0.3456146805534616
Epoch 0, Loss: 0.39262070686809675
Epoch 0, Loss: 0.3109940154231022
Epoch 0, Loss: 0.41078404650806355
Epoch 0, Loss: 0.32742655335427717
Epoch 0, Loss: 0.3474431162027395
Epoch 0, Loss: 0.3020701915051091
Epoch 0, Loss: 0.3097484607550337
Epoch 0, Loss: 0.3884742222864065
Epoch 0, Loss: 0.34703155997282314
Epoch 0, Loss: 0.43096016455746605
Epoch 0, Loss: 0.34937528778396826
Epoch 0, Loss: 0.33106106780215083
Epoch 0, Loss: 0.37613514205383647
Epoch 0, Loss: 0.3347660823524557
Epoch 0, Loss: 0.32984471106679114
Epoch 0, Loss: 0.35291904708974625
Epoch 0, Loss: 0.3739866789795692
Epoch 0, Loss: 0.3293939066979372
Epoch 0, Loss: 0.3686812592456302
Epoch 0, Loss: 0.34217677273613967
Epoch 0, Loss: 0.35895424623920913
Epoch 0, Loss: 0.3251297119543516
Epoch 0, Loss: 0.2937173328365433
Epoch 0, Loss: 0.3113131229818502
Epoch 0, Loss: 0.3441256460197404
Epoch 0, Loss: 0.35296496846656067
Epoch 0, Loss: 0.34456827647916416
Epoch 0, Loss: 0.33447433398784665
Epoch 0, Loss: 0.3698790691598889
Epoch 0, Loss: 0.3781273027144738
Epoch 0, Loss: 0.331101364537297
Epoch 0, Loss: 0.33083883304041367
Epoch 0, Loss: 0.36953461314621633
Epoch 0, Loss: 0.33165108371974783
Epoch 0, Loss: 0.4048558340047263
Epoch 0, Loss: 0.33481895935898554
Epoch 0, Loss: 0.35711894624256896
Epoch 0, Loss: 0.3067476074600592
Epoch 0, Loss: 0.3581381442949619
Epoch 0, Loss: 0.34709728972553133
Epoch 0, Loss: 0.374548609001269
Epoch 0, Loss: 0.32562162437242875
Epoch 0, Loss: 0.38681042938674176
Epoch 0, Loss: 0.33267520244238424
Epoch 0, Loss: 0.3327999002449023
Epoch 0, Loss: 0.37614504325948783
Epoch 0, Loss: 0.34428956297485747
Epoch 0, Loss: 0.32638702588235624
Epoch 0, Loss: 0.3132577986783861
Epoch 0, Loss: 0.34124403508728696
Epoch 0, Loss: 0.3807359307604278
Epoch 0, Loss: 0.24960733475889263
Epoch 0, Loss: 0.40033211141194674
Epoch 0, Loss: 0.34591994999651016
Epoch 0, Loss: 0.34251052326804804
Epoch 0, Loss: 0.37692351774421007
Epoch 0, Loss: 0.3667716091237866
Epoch 0, Loss: 0.3633696868415368
Epoch 0, Loss: 0.35131050895232213
Epoch 0, Loss: 0.3264885732421111
Epoch 0, Loss: 0.38559924458615336
Epoch 0, Loss: 0.3281915349283014
Epoch 0, Loss: 0.31588680909004135
Epoch 0, Loss: 0.3171085263472943
Epoch 0, Loss: 0.3452907383232163
Epoch 0, Loss: 0.2987627390457477
Epoch 0, Loss: 0.36961247662465185
Epoch 0, Loss: 0.4113467508005368
Epoch 0, Loss: 0.3579683042491973
Epoch 0, Loss: 0.35610673629478234
Epoch 0, Loss: 0.3671141908651625
Epoch 0, Loss: 0.3426524527818273
Epoch 0, Loss: 0.33971911018085754
Epoch 0, Loss: 0.41133068211993856
Epoch 0, Loss: 0.3295314359160415
Epoch 0, Loss: 0.3485696853069159
Epoch 0, Loss: 0.40854146711652073
Epoch 0, Loss: 0.3069677750914553
Epoch 0, Loss: 0.3861969127863799
Epoch 0, Loss: 0.3735503596683792
Epoch 0, Loss: 0.31876095173035046
2025-03-10 16:34:36,117 - INFO - TREENN2 Epoch 700:
2025-03-10 16:34:36,118 - INFO - Train MSE: 0.1806, Test MSE: 0.2142
2025-03-10 16:34:36,118 - INFO - Train R²: 0.8194, Test R²: 0.7462
2025-03-10 16:34:36,118 - INFO - Train MAE: 0.3037, Test MAE: 0.3036
2025-03-10 16:34:36,118 - INFO - Overfit ratio (train R² / test R²): 1.0981
Epoch 0, Loss: 0.3823772289499
Epoch 0, Loss: 0.33206257298534425
Epoch 0, Loss: 0.36712074348997537
Epoch 0, Loss: 0.37302473208880543
Epoch 0, Loss: 0.2984245008053096
Epoch 0, Loss: 0.3716500563313358
Epoch 0, Loss: 0.37508345319519726
Epoch 0, Loss: 0.3028235741211478
Epoch 0, Loss: 0.3184069921568372
Epoch 0, Loss: 0.385732546177089
Epoch 0, Loss: 0.4000511439644575
Epoch 0, Loss: 0.3276828452595152
Epoch 0, Loss: 0.29408833832721
Epoch 0, Loss: 0.3309480429151193
Epoch 0, Loss: 0.3175486720801615
Epoch 0, Loss: 0.3476028000106597
Epoch 0, Loss: 0.35731180651890704
Epoch 0, Loss: 0.3504279475479469
Epoch 0, Loss: 0.30408615353120466
Epoch 0, Loss: 0.39448032100550906
Epoch 0, Loss: 0.3267178422291129
Epoch 0, Loss: 0.38041132715907267
Epoch 0, Loss: 0.3453362928519871
Epoch 0, Loss: 0.26866092110273126
Epoch 0, Loss: 0.3628029683092646
Epoch 0, Loss: 0.3047519295028677
Epoch 0, Loss: 0.37863885230187183
Epoch 0, Loss: 0.3267709832206452
Epoch 0, Loss: 0.3247499712744645
Epoch 0, Loss: 0.2963915618278243
Epoch 0, Loss: 0.3215617371545413
Epoch 0, Loss: 0.33141841245110654
Epoch 0, Loss: 0.37466316749004
Epoch 0, Loss: 0.314965550351017
Epoch 0, Loss: 0.30026205358183267
Epoch 0, Loss: 0.3081222076609895
Epoch 0, Loss: 0.3272640189562063
Epoch 0, Loss: 0.36322952977619616
Epoch 0, Loss: 0.3244556003165473
Epoch 0, Loss: 0.36580792226648706
Epoch 0, Loss: 0.31045799131753066
Epoch 0, Loss: 0.3116390899982215
Epoch 0, Loss: 0.3635020868509574
Epoch 0, Loss: 0.35326958861745883
Epoch 0, Loss: 0.30689112116392736
Epoch 0, Loss: 0.3563113862114816
Epoch 0, Loss: 0.33131422241577996
Epoch 0, Loss: 0.3953966181189124
Epoch 0, Loss: 0.3823359432748766
Epoch 0, Loss: 0.3536002063217362
Epoch 0, Loss: 0.3354202524526796
Epoch 0, Loss: 0.32037362342192444
Epoch 0, Loss: 0.3052604871865993
Epoch 0, Loss: 0.3624044967984317
Epoch 0, Loss: 0.3204623700562063
Epoch 0, Loss: 0.33089104764107674
Epoch 0, Loss: 0.32028588451276097
Epoch 0, Loss: 0.3927012758466489
Epoch 0, Loss: 0.3653037545662014
Epoch 0, Loss: 0.34861713887542944
Epoch 0, Loss: 0.2677729959663454
Epoch 0, Loss: 0.3312707783329969
Epoch 0, Loss: 0.33825839451464246
Epoch 0, Loss: 0.29311435833071486
Epoch 0, Loss: 0.26990246343517543
Epoch 0, Loss: 0.33589262164800976
Epoch 0, Loss: 0.33817020292043415
Epoch 0, Loss: 0.3221616304345342
Epoch 0, Loss: 0.3464754808897166
Epoch 0, Loss: 0.3036843130762668
Epoch 0, Loss: 0.2752745717148545
Epoch 0, Loss: 0.37411956753952896
Epoch 0, Loss: 0.3836707962901077
Epoch 0, Loss: 0.3727822724910044
Epoch 0, Loss: 0.3386216625601582
Epoch 0, Loss: 0.32228321473612853
Epoch 0, Loss: 0.37730255658646666
Epoch 0, Loss: 0.364835259506763
Epoch 0, Loss: 0.32429550936635393
Epoch 0, Loss: 0.27348237056564967
Epoch 0, Loss: 0.34285239008317936
Epoch 0, Loss: 0.34354677274753903
Epoch 0, Loss: 0.3410599827954342
Epoch 0, Loss: 0.3301138156659447
Epoch 0, Loss: 0.29852367161979704
Epoch 0, Loss: 0.33293794522767717
Epoch 0, Loss: 0.31826415877224806
Epoch 0, Loss: 0.33065973567943513
Epoch 0, Loss: 0.32737674302481506
Epoch 0, Loss: 0.37648882625051905
Epoch 0, Loss: 0.3546514677687476
Epoch 0, Loss: 0.2950380970803045
Epoch 0, Loss: 0.315739399266086
Epoch 0, Loss: 0.3599131844016116
Epoch 0, Loss: 0.3524289417259348
Epoch 0, Loss: 0.33618729465629493
Epoch 0, Loss: 0.38376115327343907
Epoch 0, Loss: 0.3463023769666556
Epoch 0, Loss: 0.36406347535597716
Epoch 0, Loss: 0.3109225851173779
2025-03-10 16:34:36,721 - INFO - TREENN2 Epoch 800:
2025-03-10 16:34:36,721 - INFO - Train MSE: 0.1771, Test MSE: 0.2112
2025-03-10 16:34:36,721 - INFO - Train R²: 0.8229, Test R²: 0.7498
2025-03-10 16:34:36,721 - INFO - Train MAE: 0.3008, Test MAE: 0.3004
2025-03-10 16:34:36,722 - INFO - Overfit ratio (train R² / test R²): 1.0975
Epoch 0, Loss: 0.2751575569747354
Epoch 0, Loss: 0.3056342654907533
Epoch 0, Loss: 0.32330552387391615
Epoch 0, Loss: 0.3357247174565707
Epoch 0, Loss: 0.30456437969289035
Epoch 0, Loss: 0.3180452398685528
Epoch 0, Loss: 0.30450502862399115
Epoch 0, Loss: 0.3289952878272845
Epoch 0, Loss: 0.3732503777629633
Epoch 0, Loss: 0.3009631305113764
Epoch 0, Loss: 0.29664261153389
Epoch 0, Loss: 0.3159704310163896
Epoch 0, Loss: 0.3179297950783754
Epoch 0, Loss: 0.3637395658898113
Epoch 0, Loss: 0.32582358587349614
Epoch 0, Loss: 0.36799246352490095
Epoch 0, Loss: 0.30783119230486317
Epoch 0, Loss: 0.388182957020322
Epoch 0, Loss: 0.3609113302366188
Epoch 0, Loss: 0.32433338804323447
Epoch 0, Loss: 0.3259328232510494
Epoch 0, Loss: 0.36822780451861925
Epoch 0, Loss: 0.35105039834808277
Epoch 0, Loss: 0.33978056021868375
Epoch 0, Loss: 0.3239650714476554
Epoch 0, Loss: 0.32208817267233825
Epoch 0, Loss: 0.3608018437885716
Epoch 0, Loss: 0.3896516190703378
Epoch 0, Loss: 0.4004357233427967
Epoch 0, Loss: 0.33299329886431495
Epoch 0, Loss: 0.33120131432108374
Epoch 0, Loss: 0.32203136818836403
Epoch 0, Loss: 0.37309455676732844
Epoch 0, Loss: 0.2643751778956505
Epoch 0, Loss: 0.36067654644019737
Epoch 0, Loss: 0.32259938522624027
Epoch 0, Loss: 0.3515108452533104
Epoch 0, Loss: 0.3389563730424116
Epoch 0, Loss: 0.29920712961349444
Epoch 0, Loss: 0.32347912243768545
Epoch 0, Loss: 0.3427874727021061
Epoch 0, Loss: 0.373836694758905
Epoch 0, Loss: 0.37614300475480905
Epoch 0, Loss: 0.34410429610544296
Epoch 0, Loss: 0.35994962084145976
Epoch 0, Loss: 0.2962169294216171
Epoch 0, Loss: 0.29851930442065355
Epoch 0, Loss: 0.37244923357582665
Epoch 0, Loss: 0.3139110426148512
Epoch 0, Loss: 0.3380609412293067
Epoch 0, Loss: 0.33762184783288157
Epoch 0, Loss: 0.3136497161137407
Epoch 0, Loss: 0.2763667171803359
Epoch 0, Loss: 0.33625044179733493
Epoch 0, Loss: 0.3964297893012906
Epoch 0, Loss: 0.30299097726960883
Epoch 0, Loss: 0.30623768663875167
Epoch 0, Loss: 0.2798313887533519
Epoch 0, Loss: 0.3609879601224004
Epoch 0, Loss: 0.33410584805109145
Epoch 0, Loss: 0.3048983223066112
Epoch 0, Loss: 0.35309454436538645
Epoch 0, Loss: 0.2813458514342983
Epoch 0, Loss: 0.3641466603967727
Epoch 0, Loss: 0.3478451325849044
Epoch 0, Loss: 0.30695574657508223
Epoch 0, Loss: 0.3476935702425591
Epoch 0, Loss: 0.3428998232230647
Epoch 0, Loss: 0.3047884617304294
Epoch 0, Loss: 0.3439845700705449
Epoch 0, Loss: 0.3076301178903799
Epoch 0, Loss: 0.3501993260479684
Epoch 0, Loss: 0.34805778225852724
Epoch 0, Loss: 0.33939863737995907
Epoch 0, Loss: 0.32666925801451374
Epoch 0, Loss: 0.34782138135942253
Epoch 0, Loss: 0.3539287276717718
Epoch 0, Loss: 0.33998477396080273
Epoch 0, Loss: 0.2789499141338388
Epoch 0, Loss: 0.3300796491896675
Epoch 0, Loss: 0.3254504279327598
Epoch 0, Loss: 0.333292796006944
Epoch 0, Loss: 0.3372223798377249
Epoch 0, Loss: 0.328212274300172
Epoch 0, Loss: 0.3675366643163031
Epoch 0, Loss: 0.31969456422800446
Epoch 0, Loss: 0.3579857757154985
Epoch 0, Loss: 0.37621351257790897
Epoch 0, Loss: 0.3690856678042389
Epoch 0, Loss: 0.2857058872310825
Epoch 0, Loss: 0.3219753093079506
Epoch 0, Loss: 0.3492690277381975
Epoch 0, Loss: 0.3286215945969568
Epoch 0, Loss: 0.34408425437654167
Epoch 0, Loss: 0.2836942074255803
Epoch 0, Loss: 0.3100069985187348
Epoch 0, Loss: 0.33267858299026587
Epoch 0, Loss: 0.36030282873667563
Epoch 0, Loss: 0.2926424455628978
Epoch 0, Loss: 0.32610448338054293
2025-03-10 16:34:37,359 - INFO - TREENN2 Epoch 900:
2025-03-10 16:34:37,360 - INFO - Train MSE: 0.1724, Test MSE: 0.2077
2025-03-10 16:34:37,360 - INFO - Train R²: 0.8276, Test R²: 0.7540
2025-03-10 16:34:37,360 - INFO - Train MAE: 0.2967, Test MAE: 0.2974
2025-03-10 16:34:37,360 - INFO - Overfit ratio (train R² / test R²): 1.0977
Epoch 0, Loss: 0.3616343754175265
Epoch 0, Loss: 0.2760061674246472
Epoch 0, Loss: 0.33693522580348045
Epoch 0, Loss: 0.38085062226168426
Epoch 0, Loss: 0.34063703255086264
Epoch 0, Loss: 0.3268024473798072
Epoch 0, Loss: 0.32394117397373606
Epoch 0, Loss: 0.33702930162826067
Epoch 0, Loss: 0.33083398477306375
Epoch 0, Loss: 0.404618123996221
Epoch 0, Loss: 0.3010335934037983
Epoch 0, Loss: 0.3075149632160169
Epoch 0, Loss: 0.2749668370079789
Epoch 0, Loss: 0.30353551592343103
Epoch 0, Loss: 0.2895167190629879
Epoch 0, Loss: 0.3097715949929426
Epoch 0, Loss: 0.34757102447829896
Epoch 0, Loss: 0.35101657073916354
Epoch 0, Loss: 0.3386154567656263
Epoch 0, Loss: 0.34849517194170904
Epoch 0, Loss: 0.32440043842455035
Epoch 0, Loss: 0.29930420578076844
Epoch 0, Loss: 0.38523166298940487
Epoch 0, Loss: 0.3218591831924211
Epoch 0, Loss: 0.35973777511263505
Epoch 0, Loss: 0.36519693118768803
Epoch 0, Loss: 0.3062350434469143
Epoch 0, Loss: 0.348596896416936
Epoch 0, Loss: 0.26431814790176406
Epoch 0, Loss: 0.36723810314747213
Epoch 0, Loss: 0.31326131978439503
Epoch 0, Loss: 0.32288199786878413
Epoch 0, Loss: 0.3103554222631321
Epoch 0, Loss: 0.3454408779811783
Epoch 0, Loss: 0.32538702016552845
Epoch 0, Loss: 0.33976756505719097
Epoch 0, Loss: 0.36889566773831084
Epoch 0, Loss: 0.33301959161288713
Epoch 0, Loss: 0.37370430905151
Epoch 0, Loss: 0.34223316510333307
Epoch 0, Loss: 0.3571530839625741
Epoch 0, Loss: 0.31901668913236725
Epoch 0, Loss: 0.36780048928267317
Epoch 0, Loss: 0.36185900138479254
Epoch 0, Loss: 0.30223405313524426
Epoch 0, Loss: 0.28940731221088417
Epoch 0, Loss: 0.29570065425083514
Epoch 0, Loss: 0.3195459946925005
Epoch 0, Loss: 0.3004912556734124
Epoch 0, Loss: 0.3447790242336435
Epoch 0, Loss: 0.3467680927074023
Epoch 0, Loss: 0.3900655961354434
Epoch 0, Loss: 0.3408207402946939
Epoch 0, Loss: 0.3393106469376076
Epoch 0, Loss: 0.3247762188818607
Epoch 0, Loss: 0.2936093948833758
Epoch 0, Loss: 0.3456180792457349
Epoch 0, Loss: 0.3136453914930042
Epoch 0, Loss: 0.3403193362905556
Epoch 0, Loss: 0.3298019275451449
Epoch 0, Loss: 0.30582321721084904
Epoch 0, Loss: 0.32230148213654725
Epoch 0, Loss: 0.3214514861292791
Epoch 0, Loss: 0.34297277098768686
Epoch 0, Loss: 0.36861399372251485
Epoch 0, Loss: 0.3169765038061813
Epoch 0, Loss: 0.31932364142550007
Epoch 0, Loss: 0.38414371273741127
Epoch 0, Loss: 0.307880035111319
Epoch 0, Loss: 0.3205480691104792
Epoch 0, Loss: 0.3139219781136938
Epoch 0, Loss: 0.30175658705088504
Epoch 0, Loss: 0.30072496025225737
Epoch 0, Loss: 0.3248984415087485
Epoch 0, Loss: 0.3006950219526764
Epoch 0, Loss: 0.3822598820945454
Epoch 0, Loss: 0.2902743230347251
Epoch 0, Loss: 0.3555957656145523
Epoch 0, Loss: 0.3092363618519327
Epoch 0, Loss: 0.33281117347443023
Epoch 0, Loss: 0.33735317662592146
Epoch 0, Loss: 0.3309704524526472
Epoch 0, Loss: 0.36227082368575325
Epoch 0, Loss: 0.329828545125484
Epoch 0, Loss: 0.3403229340062478
Epoch 0, Loss: 0.29014307839332254
Epoch 0, Loss: 0.3291309390206268
Epoch 0, Loss: 0.3138161002472327
Epoch 0, Loss: 0.3411949421667312
Epoch 0, Loss: 0.34337406749433375
Epoch 0, Loss: 0.3467691651434798
Epoch 0, Loss: 0.34492373973502943
Epoch 0, Loss: 0.2960218183498048
Epoch 0, Loss: 0.36959651296605317
Epoch 0, Loss: 0.3374814844977294
Epoch 0, Loss: 0.27850225726973316
Epoch 0, Loss: 0.30569055457002026
Epoch 0, Loss: 0.3220792045023631
Epoch 0, Loss: 0.2975425196793427
2025-03-10 16:34:37,928 - INFO - TREENN2 Epoch 999:
2025-03-10 16:34:37,928 - INFO - Train MSE: 0.1714, Test MSE: 0.2089
2025-03-10 16:34:37,928 - INFO - Train R²: 0.8286, Test R²: 0.7526
2025-03-10 16:34:37,929 - INFO - Train MAE: 0.2964, Test MAE: 0.2975
2025-03-10 16:34:37,929 - INFO - Overfit ratio (train R² / test R²): 1.1010
2025-03-10 16:34:37,933 - INFO -
TREENN2 Final Metrics:
2025-03-10 16:34:37,933 - INFO - R² Score: 0.7526
2025-03-10 16:34:37,933 - INFO - MAE: 0.2975
2025-03-10 16:34:37,933 - INFO - MSE: 0.2089
2025-03-10 16:34:37,934 - INFO - Train R²: 0.8286
2025-03-10 16:34:37,934 - INFO - Overfit Ratio: 1.1010
2025-03-10 16:34:37,934 - INFO - TREENN2 evaluation successful!
2025-03-10 16:34:37,934 - INFO -
Initializing TREENN3...
2025-03-10 16:34:37,934 - INFO - Model class: TREENN3
2025-03-10 16:34:37,937 - INFO - TREENN3 model initialized successfully!
2025-03-10 16:34:37,937 - INFO - TREENN3 architecture:
2025-03-10 16:34:37,937 - INFO - Input dimension: 12
2025-03-10 16:34:37,937 - INFO - Hidden dimension: 64
2025-03-10 16:34:37,937 - INFO - Output dimension: 1
2025-03-10 16:34:37,937 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:34:37,938 - INFO - Training TREENN3...
Epoch 0, Loss: 3.204976475533395
2025-03-10 16:34:37,947 - INFO - TREENN3 Epoch 0:
2025-03-10 16:34:37,947 - INFO - Train MSE: 2.0967, Test MSE: 2.5244
2025-03-10 16:34:37,947 - INFO - Train R²: -1.0967, Test R²: -1.9905
2025-03-10 16:34:37,947 - INFO - Train MAE: 1.2514, Test MAE: 1.3460
2025-03-10 16:34:37,947 - INFO - Overfit ratio (train R² / test R²): 0.5510
Epoch 0, Loss: 2.658416380734414
Epoch 0, Loss: 2.13742947776467
Epoch 0, Loss: 2.4952775387263926
Epoch 0, Loss: 1.1983681129146646
Epoch 0, Loss: 1.4906685727782076
Epoch 0, Loss: 1.3151994139971406
Epoch 0, Loss: 1.2372641239980118
Epoch 0, Loss: 1.2348113080399052
Epoch 0, Loss: 1.0269117716473453
Epoch 0, Loss: 1.0105393269376155
Epoch 0, Loss: 0.9547319430340732
Epoch 0, Loss: 0.771982634506473
Epoch 0, Loss: 1.0264657382787281
Epoch 0, Loss: 0.9301144316737425
Epoch 0, Loss: 0.8279258132142547
Epoch 0, Loss: 0.6725081686065749
Epoch 0, Loss: 0.8187364819920749
Epoch 0, Loss: 0.6839642584389269
Epoch 0, Loss: 0.9630927697203302
Epoch 0, Loss: 0.9619578787447858
Epoch 0, Loss: 0.7006341505728801
Epoch 0, Loss: 0.7872283151116812
Epoch 0, Loss: 0.7670520059612803
Epoch 0, Loss: 0.8410355714067403
Epoch 0, Loss: 0.8449510889324641
Epoch 0, Loss: 0.6746381151210884
Epoch 0, Loss: 0.8223152350347757
Epoch 0, Loss: 0.7619577252101811
Epoch 0, Loss: 0.9820404991397337
Epoch 0, Loss: 0.6848877670809435
Epoch 0, Loss: 0.8185157649123118
Epoch 0, Loss: 0.7543402449692618
Epoch 0, Loss: 0.8440283298390777
Epoch 0, Loss: 0.7965321624729049
Epoch 0, Loss: 0.7478021613028443
Epoch 0, Loss: 0.7363241685638653
Epoch 0, Loss: 0.6805375215911205
Epoch 0, Loss: 0.7102671789690403
Epoch 0, Loss: 0.8272003962201349
Epoch 0, Loss: 0.79537686144771
Epoch 0, Loss: 0.8201969997865076
Epoch 0, Loss: 0.819080965967024
Epoch 0, Loss: 0.7796075065683467
Epoch 0, Loss: 0.652735347860279
Epoch 0, Loss: 0.7601032058479789
Epoch 0, Loss: 0.796151167096309
Epoch 0, Loss: 0.6921081181782929
Epoch 0, Loss: 0.9066528165537415
Epoch 0, Loss: 0.7656673968016021
Epoch 0, Loss: 0.8099284725717393
Epoch 0, Loss: 0.6952983556849799
Epoch 0, Loss: 0.739941978550104
Epoch 0, Loss: 0.6067641463435889
Epoch 0, Loss: 0.6402843746138578
Epoch 0, Loss: 0.7903797110819216
Epoch 0, Loss: 0.7321372934576439
Epoch 0, Loss: 0.8692187989362169
Epoch 0, Loss: 0.6668620256219354
Epoch 0, Loss: 0.7473130939219543
Epoch 0, Loss: 0.5681092564871089
Epoch 0, Loss: 0.5745136627476133
Epoch 0, Loss: 0.7299987914823138
Epoch 0, Loss: 0.5636740261890822
Epoch 0, Loss: 0.5930523597198406
Epoch 0, Loss: 0.7522371960100505
Epoch 0, Loss: 0.915743694786238
Epoch 0, Loss: 0.6899965305951969
Epoch 0, Loss: 0.8421829246257169
Epoch 0, Loss: 0.6838464165063378
Epoch 0, Loss: 0.7931584173806844
Epoch 0, Loss: 0.6327754097415417
Epoch 0, Loss: 0.7043107836259086
Epoch 0, Loss: 0.8571276542921541
Epoch 0, Loss: 0.8033655474459593
Epoch 0, Loss: 0.7655231821627442
Epoch 0, Loss: 0.7754989492415643
Epoch 0, Loss: 0.6929627299762822
Epoch 0, Loss: 0.6773169727526884
Epoch 0, Loss: 0.8839079245586562
Epoch 0, Loss: 0.8388886895848101
Epoch 0, Loss: 0.9448022373922758
Epoch 0, Loss: 0.6956607106217285
Epoch 0, Loss: 0.7890594150577767
Epoch 0, Loss: 0.9122775142655717
Epoch 0, Loss: 0.7191746429267855
Epoch 0, Loss: 0.845582940632233
Epoch 0, Loss: 0.8217746308282279
Epoch 0, Loss: 0.7648145954547427
Epoch 0, Loss: 0.8875944382962085
Epoch 0, Loss: 0.6662117391628493
Epoch 0, Loss: 0.8277268593024312
Epoch 0, Loss: 0.8061184308307698
Epoch 0, Loss: 0.6212624842848378
Epoch 0, Loss: 0.7065942685252814
Epoch 0, Loss: 0.593666897862056
Epoch 0, Loss: 0.7599863098120675
Epoch 0, Loss: 0.6999210021895298
Epoch 0, Loss: 0.8177231618817625
Epoch 0, Loss: 0.9078589125059963
Epoch 0, Loss: 0.7027339707712222
2025-03-10 16:34:38,439 - INFO - TREENN3 Epoch 100:
2025-03-10 16:34:38,439 - INFO - Train MSE: 0.1651, Test MSE: 0.2597
2025-03-10 16:34:38,440 - INFO - Train R²: 0.8349, Test R²: 0.6923
2025-03-10 16:34:38,440 - INFO - Train MAE: 0.3163, Test MAE: 0.3239
2025-03-10 16:34:38,440 - INFO - Overfit ratio (train R² / test R²): 1.2059
Epoch 0, Loss: 0.5003054810090141
Epoch 0, Loss: 0.867699194991768
Epoch 0, Loss: 0.7869907111004301
Epoch 0, Loss: 0.9106670575188764
Epoch 0, Loss: 0.7907285319534986
Epoch 0, Loss: 0.6148632629462284
Epoch 0, Loss: 0.7074849594113181
Epoch 0, Loss: 0.6860462002521299
Epoch 0, Loss: 0.714587984441974
Epoch 0, Loss: 0.7710317938829233
Epoch 0, Loss: 0.6157895712556645
Epoch 0, Loss: 0.6847385883695953
Epoch 0, Loss: 0.7103146174566574
Epoch 0, Loss: 0.6602453693507372
Epoch 0, Loss: 0.6833023099937413
Epoch 0, Loss: 0.5391902337006309
Epoch 0, Loss: 0.7175114037806102
Epoch 0, Loss: 0.6779975119118542
Epoch 0, Loss: 0.8805176638269054
Epoch 0, Loss: 0.8510524153721528
Epoch 0, Loss: 0.5697084768894672
Epoch 0, Loss: 0.7349293997946245
Epoch 0, Loss: 0.727800950253764
Epoch 0, Loss: 0.6637103031054057
Epoch 0, Loss: 0.6557108594413379
Epoch 0, Loss: 0.7269936856758822
Epoch 0, Loss: 0.7510804737507308
Epoch 0, Loss: 0.6547263088853587
Epoch 0, Loss: 0.6550253621799771
Epoch 0, Loss: 0.6247488776192134
Epoch 0, Loss: 0.6599322493643746
Epoch 0, Loss: 0.6907425131468959
Epoch 0, Loss: 0.5806450277453867
Epoch 0, Loss: 0.6577480396112371
Epoch 0, Loss: 0.9412609215116718
Epoch 0, Loss: 0.8595698564374861
Epoch 0, Loss: 0.7733358683035876
Epoch 0, Loss: 0.6723825078173511
Epoch 0, Loss: 0.6710113226211896
Epoch 0, Loss: 0.6009254158600003
Epoch 0, Loss: 0.7297652262159121
Epoch 0, Loss: 0.8601372140786839
Epoch 0, Loss: 0.6087301994323056
Epoch 0, Loss: 0.5545194236022791
Epoch 0, Loss: 0.6480360999108311
Epoch 0, Loss: 0.656872357746069
Epoch 0, Loss: 0.6871530659349527
Epoch 0, Loss: 0.6985892505529806
Epoch 0, Loss: 0.6233898849150858
Epoch 0, Loss: 0.6338383502870201
Epoch 0, Loss: 0.6289154696181428
Epoch 0, Loss: 0.5939292397928746
Epoch 0, Loss: 0.7073053414112165
Epoch 0, Loss: 0.613302158891442
Epoch 0, Loss: 0.614633672946268
Epoch 0, Loss: 0.7151291860337278
Epoch 0, Loss: 0.68115751226888
Epoch 0, Loss: 0.7047359139599313
Epoch 0, Loss: 0.8161770094922897
Epoch 0, Loss: 0.9604024463343948
Epoch 0, Loss: 0.572832274982097
Epoch 0, Loss: 0.6507238640144923
Epoch 0, Loss: 0.768927834214547
Epoch 0, Loss: 0.8438265988361024
Epoch 0, Loss: 0.6691632456748717
Epoch 0, Loss: 0.7050772989000481
Epoch 0, Loss: 0.6266442487474677
Epoch 0, Loss: 0.6509552879994321
Epoch 0, Loss: 0.7519197816985741
Epoch 0, Loss: 0.48952483105001976
Epoch 0, Loss: 0.6149402804248194
Epoch 0, Loss: 0.6296287436697927
Epoch 0, Loss: 0.6634804892001699
Epoch 0, Loss: 0.7023095431846328
Epoch 0, Loss: 0.6693368065521592
Epoch 0, Loss: 0.6906033686322747
Epoch 0, Loss: 0.7821306631596648
Epoch 0, Loss: 0.7374207636046434
Epoch 0, Loss: 0.6826653671245103
Epoch 0, Loss: 0.9051271137314376
Epoch 0, Loss: 0.6484267436300625
Epoch 0, Loss: 0.5590724668557581
Epoch 0, Loss: 0.7115947627374007
Epoch 0, Loss: 0.8074413367279356
Epoch 0, Loss: 0.7495683817071979
Epoch 0, Loss: 0.5207537909900188
Epoch 0, Loss: 0.7874835368461733
Epoch 0, Loss: 0.6181079866222389
Epoch 0, Loss: 0.9416313295999852
Epoch 0, Loss: 0.5715654571559077
Epoch 0, Loss: 0.5515730385272163
Epoch 0, Loss: 0.7175961103787096
Epoch 0, Loss: 0.6734198066908165
Epoch 0, Loss: 0.601985458794214
Epoch 0, Loss: 0.624312739069402
Epoch 0, Loss: 0.6982695279959324
Epoch 0, Loss: 0.8722315397721164
Epoch 0, Loss: 0.5369837382245626
Epoch 0, Loss: 0.6361119377305927
Epoch 0, Loss: 0.646039097992141
2025-03-10 16:34:38,924 - INFO - TREENN3 Epoch 200:
2025-03-10 16:34:38,924 - INFO - Train MSE: 0.1571, Test MSE: 0.2548
2025-03-10 16:34:38,924 - INFO - Train R²: 0.8429, Test R²: 0.6982
2025-03-10 16:34:38,924 - INFO - Train MAE: 0.3047, Test MAE: 0.3250
2025-03-10 16:34:38,924 - INFO - Overfit ratio (train R² / test R²): 1.2072
Epoch 0, Loss: 0.7202770171570888
Epoch 0, Loss: 0.7119748434196211
Epoch 0, Loss: 0.8498633267572496
Epoch 0, Loss: 0.6665264763315295
Epoch 0, Loss: 0.7782880312957352
Epoch 0, Loss: 0.7569877054282245
Epoch 0, Loss: 0.5395117408287665
Epoch 0, Loss: 0.6538097985753513
Epoch 0, Loss: 0.6085422482059366
Epoch 0, Loss: 0.6101440126425293
Epoch 0, Loss: 0.6709124529240523
Epoch 0, Loss: 0.8630020071791709
Epoch 0, Loss: 0.6901223942718839
Epoch 0, Loss: 0.7284743268251244
Epoch 0, Loss: 0.6560514083507727
Epoch 0, Loss: 0.7223567173653946
Epoch 0, Loss: 0.648622209051501
Epoch 0, Loss: 0.6850683291461246
Epoch 0, Loss: 0.8395351241554689
Epoch 0, Loss: 0.693174051601434
Epoch 0, Loss: 0.5948583908377377
Epoch 0, Loss: 0.7112090862886279
Epoch 0, Loss: 0.7746625630625499
Epoch 0, Loss: 0.839494982698537
Epoch 0, Loss: 0.5981356720122915
Epoch 0, Loss: 0.8279554380085243
Epoch 0, Loss: 0.6507216054455305
Epoch 0, Loss: 0.6221592207391431
Epoch 0, Loss: 0.5602343775597997
Epoch 0, Loss: 0.5506290555922239
Epoch 0, Loss: 0.7541332292099759
Epoch 0, Loss: 0.7330965792701134
Epoch 0, Loss: 0.6180112620341017
Epoch 0, Loss: 0.6026706573979166
Epoch 0, Loss: 0.6541787734965037
Epoch 0, Loss: 0.7153997321973234
Epoch 0, Loss: 0.4497659302790087
Epoch 0, Loss: 0.6898934515852939
Epoch 0, Loss: 0.7248515445023713
Epoch 0, Loss: 0.6640388754480956
Epoch 0, Loss: 0.7178043903877835
Epoch 0, Loss: 0.6706551855319971
Epoch 0, Loss: 0.6593370749175077
Epoch 0, Loss: 0.7570175053849764
Epoch 0, Loss: 0.8012810271896029
Epoch 0, Loss: 0.8627978419134068
Epoch 0, Loss: 0.8898916376136535
Epoch 0, Loss: 0.6061250948172707
Epoch 0, Loss: 0.8527083750293761
Epoch 0, Loss: 0.6355737948096266
Epoch 0, Loss: 0.6414003259232652
Epoch 0, Loss: 0.7070588636091882
Epoch 0, Loss: 0.7054253910907672
Epoch 0, Loss: 0.8016212134873099
Epoch 0, Loss: 0.6938815816100213
Epoch 0, Loss: 0.8368533135545104
Epoch 0, Loss: 0.7216293800242861
Epoch 0, Loss: 0.8154831297791283
Epoch 0, Loss: 0.7530155716781827
Epoch 0, Loss: 0.5910559894136876
Epoch 0, Loss: 0.762894364477496
Epoch 0, Loss: 0.7458228606457318
Epoch 0, Loss: 0.567484480322846
Epoch 0, Loss: 0.6778862740774956
Epoch 0, Loss: 0.5608845237375355
Epoch 0, Loss: 0.5745893020290931
Epoch 0, Loss: 0.6592689680186967
Epoch 0, Loss: 0.585798025891637
Epoch 0, Loss: 0.6790564590219967
Epoch 0, Loss: 0.5752790988325311
Epoch 0, Loss: 0.3920734936786938
Epoch 0, Loss: 0.6788093314594723
Epoch 0, Loss: 0.6838355596414285
Epoch 0, Loss: 0.7052657144262586
Epoch 0, Loss: 0.6448612118147462
Epoch 0, Loss: 0.6340211356520291
Epoch 0, Loss: 0.7092761688460908
Epoch 0, Loss: 0.6046532079517823
Epoch 0, Loss: 0.8368980990724756
Epoch 0, Loss: 0.630705865350507
Epoch 0, Loss: 0.5825595654293962
Epoch 0, Loss: 0.6254359509717944
Epoch 0, Loss: 0.6456006898665034
Epoch 0, Loss: 0.48391354390803004
Epoch 0, Loss: 0.6596347809697013
Epoch 0, Loss: 0.8391962404958061
Epoch 0, Loss: 0.846850441855943
Epoch 0, Loss: 0.7430191624759543
Epoch 0, Loss: 0.5481127501865637
Epoch 0, Loss: 0.7479186126114075
Epoch 0, Loss: 0.7244492663898178
Epoch 0, Loss: 0.8121250500608161
Epoch 0, Loss: 0.6743611023814521
Epoch 0, Loss: 0.6760326460836231
Epoch 0, Loss: 0.6243824914534438
Epoch 0, Loss: 0.79079722639977
Epoch 0, Loss: 0.5660962266081572
Epoch 0, Loss: 0.46600701020290414
Epoch 0, Loss: 0.6839627039593125
Epoch 0, Loss: 0.5461239009195208
2025-03-10 16:34:39,404 - INFO - TREENN3 Epoch 300:
2025-03-10 16:34:39,404 - INFO - Train MSE: 0.1547, Test MSE: 0.2479
2025-03-10 16:34:39,404 - INFO - Train R²: 0.8453, Test R²: 0.7063
2025-03-10 16:34:39,405 - INFO - Train MAE: 0.3022, Test MAE: 0.3194
2025-03-10 16:34:39,405 - INFO - Overfit ratio (train R² / test R²): 1.1968
Epoch 0, Loss: 0.8027812818034313
Epoch 0, Loss: 0.6853617529433996
Epoch 0, Loss: 0.643310319214981
Epoch 0, Loss: 0.7147763518627716
Epoch 0, Loss: 0.6664532948502626
Epoch 0, Loss: 0.7311590337807801
Epoch 0, Loss: 0.6116330677847808
Epoch 0, Loss: 0.660557515671797
Epoch 0, Loss: 0.6648177412069383
Epoch 0, Loss: 0.6172054702839367
Epoch 0, Loss: 0.7357147302157199
Epoch 0, Loss: 0.624537872861947
Epoch 0, Loss: 0.6016468661171084
Epoch 0, Loss: 0.7078452684725527
Epoch 0, Loss: 0.7190359095141268
Epoch 0, Loss: 0.793260495011778
Epoch 0, Loss: 0.8036624639606644
Epoch 0, Loss: 0.6748278867653594
Epoch 0, Loss: 0.7035674425315939
Epoch 0, Loss: 0.7818982070120626
Epoch 0, Loss: 0.5692674663000032
Epoch 0, Loss: 0.7696481606294747
Epoch 0, Loss: 0.5207742542385627
Epoch 0, Loss: 0.6510802279630464
Epoch 0, Loss: 0.5851190165515809
Epoch 0, Loss: 0.7276067550300291
Epoch 0, Loss: 0.4581684483270764
Epoch 0, Loss: 0.8441150316154238
Epoch 0, Loss: 0.6447714052263803
Epoch 0, Loss: 0.6224281769384931
Epoch 0, Loss: 0.7024212352551065
Epoch 0, Loss: 0.8770979871967788
Epoch 0, Loss: 0.6038880153311943
Epoch 0, Loss: 0.5916507867449395
Epoch 0, Loss: 0.6232851688098655
Epoch 0, Loss: 0.7071899044906614
Epoch 0, Loss: 0.7874349275088318
Epoch 0, Loss: 0.8165310966123347
Epoch 0, Loss: 0.6710642350891999
Epoch 0, Loss: 0.6696433174903813
Epoch 0, Loss: 0.6143052022910739
Epoch 0, Loss: 0.7497400159857743
Epoch 0, Loss: 0.5634463291054131
Epoch 0, Loss: 0.5025491352156487
Epoch 0, Loss: 0.6963551436098581
Epoch 0, Loss: 0.8464373031673962
Epoch 0, Loss: 0.7337596155449048
Epoch 0, Loss: 0.657406979699747
Epoch 0, Loss: 0.6986719593154337
Epoch 0, Loss: 0.6937858396057888
Epoch 0, Loss: 0.6375245799487165
Epoch 0, Loss: 0.6795517604375385
Epoch 0, Loss: 0.605208076312814
Epoch 0, Loss: 0.6231711082569927
Epoch 0, Loss: 0.7848890981309771
Epoch 0, Loss: 0.666531378851132
Epoch 0, Loss: 0.7668014286300489
Epoch 0, Loss: 0.6672063236693587
Epoch 0, Loss: 0.7869476864988796
Epoch 0, Loss: 0.695741552379521
Epoch 0, Loss: 0.5421753360267734
Epoch 0, Loss: 0.6383649281119494
Epoch 0, Loss: 0.5996904112930607
Epoch 0, Loss: 0.811167229387183
Epoch 0, Loss: 0.6957151548517028
Epoch 0, Loss: 0.7042838971048039
Epoch 0, Loss: 0.601171013876596
Epoch 0, Loss: 0.5722507549097111
Epoch 0, Loss: 0.6310663316424153
Epoch 0, Loss: 0.6319831639865381
Epoch 0, Loss: 0.68795617271318
Epoch 0, Loss: 0.6059676462086241
Epoch 0, Loss: 0.6998653543872841
Epoch 0, Loss: 0.7112625860180157
Epoch 0, Loss: 0.7952977500739832
Epoch 0, Loss: 0.6964916331716335
Epoch 0, Loss: 0.6586447619077924
Epoch 0, Loss: 0.610092376383285
Epoch 0, Loss: 0.6479860366877316
Epoch 0, Loss: 0.7512924074285948
Epoch 0, Loss: 0.5777287910796618
Epoch 0, Loss: 0.6021556838577747
Epoch 0, Loss: 0.7687032695482376
Epoch 0, Loss: 0.7402952304660159
Epoch 0, Loss: 0.8455115900629289
Epoch 0, Loss: 0.67480107217036
Epoch 0, Loss: 0.5615902177155441
Epoch 0, Loss: 0.8782279039349785
Epoch 0, Loss: 0.722272930904636
Epoch 0, Loss: 0.7781838360518099
Epoch 0, Loss: 0.6820761731386089
Epoch 0, Loss: 0.5466561382625058
Epoch 0, Loss: 0.5337839742624291
Epoch 0, Loss: 0.6749126518450975
Epoch 0, Loss: 0.6984051522022319
Epoch 0, Loss: 0.6330702689262215
Epoch 0, Loss: 0.6423849224992578
Epoch 0, Loss: 0.7552283011434456
Epoch 0, Loss: 0.8300565068669924
Epoch 0, Loss: 0.5906239500286632
2025-03-10 16:34:39,880 - INFO - TREENN3 Epoch 400:
2025-03-10 16:34:39,880 - INFO - Train MSE: 0.1554, Test MSE: 0.2512
2025-03-10 16:34:39,880 - INFO - Train R²: 0.8446, Test R²: 0.7025
2025-03-10 16:34:39,880 - INFO - Train MAE: 0.3042, Test MAE: 0.3246
2025-03-10 16:34:39,880 - INFO - Overfit ratio (train R² / test R²): 1.2023
Epoch 0, Loss: 0.8370992737255247
Epoch 0, Loss: 0.6934268905121928
Epoch 0, Loss: 0.7003731853805463
Epoch 0, Loss: 0.6551763222330247
Epoch 0, Loss: 0.6469972140224894
Epoch 0, Loss: 0.7042532541151549
Epoch 0, Loss: 0.5905420420502249
Epoch 0, Loss: 0.6888566386878232
Epoch 0, Loss: 0.8019027471812907
Epoch 0, Loss: 0.4950774146889062
Epoch 0, Loss: 0.6740343616246812
Epoch 0, Loss: 0.6095121663202216
Epoch 0, Loss: 0.7020709479957861
Epoch 0, Loss: 0.6112499190324928
Epoch 0, Loss: 0.6196426488352299
Epoch 0, Loss: 0.5552208296839465
Epoch 0, Loss: 0.7125007486003573
Epoch 0, Loss: 0.589186405594126
Epoch 0, Loss: 0.5602094592760739
Epoch 0, Loss: 0.7799510863657602
Epoch 0, Loss: 0.448502866806747
Epoch 0, Loss: 0.8097510475111624
Epoch 0, Loss: 0.6144725776071086
Epoch 0, Loss: 0.6708158189846327
Epoch 0, Loss: 0.6197562616602329
Epoch 0, Loss: 0.7207234820882267
Epoch 0, Loss: 0.6684249474758414
Epoch 0, Loss: 0.5304707837138187
Epoch 0, Loss: 0.7800125809272217
Epoch 0, Loss: 0.7019654820818139
Epoch 0, Loss: 0.6578515497032796
Epoch 0, Loss: 0.7649416980169825
Epoch 0, Loss: 0.6429307738863748
Epoch 0, Loss: 0.549759188373526
Epoch 0, Loss: 0.6048869930181539
Epoch 0, Loss: 0.7364622200717886
Epoch 0, Loss: 0.701103510144532
Epoch 0, Loss: 0.7266508932805503
Epoch 0, Loss: 0.6688668378411207
Epoch 0, Loss: 0.7188281965647507
Epoch 0, Loss: 0.5515318282597633
Epoch 0, Loss: 0.7823231322368173
Epoch 0, Loss: 0.8369961129647164
Epoch 0, Loss: 0.6771021740835736
Epoch 0, Loss: 0.6715225334695514
Epoch 0, Loss: 0.5733597791914392
Epoch 0, Loss: 0.5716352810731682
Epoch 0, Loss: 0.7778017203193504
Epoch 0, Loss: 0.7855083788298544
Epoch 0, Loss: 0.6399303772707409
Epoch 0, Loss: 0.7749478491568113
Epoch 0, Loss: 0.6144202102231707
Epoch 0, Loss: 0.7090266536150579
Epoch 0, Loss: 0.7012081385529836
Epoch 0, Loss: 0.7016057418162861
Epoch 0, Loss: 0.6227290409845545
Epoch 0, Loss: 0.771418719995578
Epoch 0, Loss: 0.7570164519030265
Epoch 0, Loss: 0.6163309621818809
Epoch 0, Loss: 0.8149079535190402
Epoch 0, Loss: 0.6577692430338029
Epoch 0, Loss: 0.6600338337572716
Epoch 0, Loss: 0.634245742312373
Epoch 0, Loss: 0.5290453442455686
Epoch 0, Loss: 0.5547204560617018
Epoch 0, Loss: 0.602093990288787
Epoch 0, Loss: 0.7950524539919187
Epoch 0, Loss: 0.786337429327686
Epoch 0, Loss: 0.6311866460764349
Epoch 0, Loss: 0.7096821238483271
Epoch 0, Loss: 0.6197913390142571
Epoch 0, Loss: 0.6163714277134819
Epoch 0, Loss: 0.6388275704469977
Epoch 0, Loss: 0.6719249254827776
Epoch 0, Loss: 0.5913627267574969
Epoch 0, Loss: 0.5261937769386893
Epoch 0, Loss: 0.6825352963780198
Epoch 0, Loss: 0.623572283988521
Epoch 0, Loss: 0.6308269609382849
Epoch 0, Loss: 0.674949288655444
Epoch 0, Loss: 0.6507271320048064
Epoch 0, Loss: 0.6807697430231778
Epoch 0, Loss: 0.8171384311082296
Epoch 0, Loss: 0.5949499673341043
Epoch 0, Loss: 0.6354446199823945
Epoch 0, Loss: 0.7306592803668701
Epoch 0, Loss: 0.570942965844646
Epoch 0, Loss: 0.8385216368702613
Epoch 0, Loss: 0.7698375053405045
Epoch 0, Loss: 0.548109454991983
Epoch 0, Loss: 0.6850082047343717
Epoch 0, Loss: 0.6844055954169641
Epoch 0, Loss: 0.829108143055185
Epoch 0, Loss: 0.7535811700285929
Epoch 0, Loss: 0.6927393485225815
Epoch 0, Loss: 0.768933132084497
Epoch 0, Loss: 0.4696861418385779
Epoch 0, Loss: 0.5453736438654793
Epoch 0, Loss: 0.7206134400508589
Epoch 0, Loss: 0.852899267695502
2025-03-10 16:34:40,360 - INFO - TREENN3 Epoch 500:
2025-03-10 16:34:40,360 - INFO - Train MSE: 0.1508, Test MSE: 0.2462
2025-03-10 16:34:40,360 - INFO - Train R²: 0.8492, Test R²: 0.7083
2025-03-10 16:34:40,360 - INFO - Train MAE: 0.2995, Test MAE: 0.3216
2025-03-10 16:34:40,361 - INFO - Overfit ratio (train R² / test R²): 1.1989
Epoch 0, Loss: 0.7862301731426878
Epoch 0, Loss: 0.7076185876213643
Epoch 0, Loss: 0.6146135953982932
Epoch 0, Loss: 0.5898292439663214
Epoch 0, Loss: 0.6535733607430884
Epoch 0, Loss: 0.6902143435073955
Epoch 0, Loss: 0.70420762419654
Epoch 0, Loss: 0.5488154267789688
Epoch 0, Loss: 0.5603714804289076
Epoch 0, Loss: 0.6479016569602325
Epoch 0, Loss: 0.7600619008092433
Epoch 0, Loss: 0.6677237762980172
Epoch 0, Loss: 0.7082641101527211
Epoch 0, Loss: 0.7191516904235116
Epoch 0, Loss: 0.6985801939210046
Epoch 0, Loss: 0.6233240504350862
Epoch 0, Loss: 0.8353829003295291
Epoch 0, Loss: 0.6199380382446728
Epoch 0, Loss: 0.654133314260884
Epoch 0, Loss: 0.603357399325155
Epoch 0, Loss: 0.6786108776271419
Epoch 0, Loss: 0.704684287883249
Epoch 0, Loss: 0.49650332434749256
Epoch 0, Loss: 0.568182699649672
Epoch 0, Loss: 0.7599092796739579
Epoch 0, Loss: 0.6031891632300753
Epoch 0, Loss: 0.6366866582394307
Epoch 0, Loss: 0.7086480720736776
Epoch 0, Loss: 0.7565122036155649
Epoch 0, Loss: 0.6557956782905148
Epoch 0, Loss: 0.6154848716079555
Epoch 0, Loss: 0.6317925261559171
Epoch 0, Loss: 0.6413713229243739
Epoch 0, Loss: 0.6331449358988577
Epoch 0, Loss: 0.6442570003210805
Epoch 0, Loss: 0.6078302785419293
Epoch 0, Loss: 0.5413907326227078
Epoch 0, Loss: 0.5866854738456204
Epoch 0, Loss: 0.5515352232257191
Epoch 0, Loss: 0.8229059331484604
Epoch 0, Loss: 0.8676757767265807
Epoch 0, Loss: 0.712456339374381
Epoch 0, Loss: 0.5035453731978154
Epoch 0, Loss: 0.6640091262706516
Epoch 0, Loss: 0.7511316926222905
Epoch 0, Loss: 0.7823621417204538
Epoch 0, Loss: 0.6241045561549292
Epoch 0, Loss: 0.5978782724156461
Epoch 0, Loss: 0.6943100541241379
Epoch 0, Loss: 0.5990809019117838
Epoch 0, Loss: 0.6496099457259589
Epoch 0, Loss: 0.5352070195166673
Epoch 0, Loss: 0.677510589603857
Epoch 0, Loss: 0.6812891149426444
Epoch 0, Loss: 0.6888729248330734
Epoch 0, Loss: 0.626936396037058
Epoch 0, Loss: 0.5525110327201044
Epoch 0, Loss: 0.7236112318752197
Epoch 0, Loss: 0.6595884956775393
Epoch 0, Loss: 0.6758946929157184
Epoch 0, Loss: 0.5938466240119827
Epoch 0, Loss: 0.7323767503748999
Epoch 0, Loss: 0.6620782527248019
Epoch 0, Loss: 0.591755146121899
Epoch 0, Loss: 0.6789486423488095
Epoch 0, Loss: 0.6173891673855688
Epoch 0, Loss: 0.8187928912707182
Epoch 0, Loss: 0.7228360323922404
Epoch 0, Loss: 0.593144126327349
Epoch 0, Loss: 0.5398588856796137
Epoch 0, Loss: 0.5914300194691858
Epoch 0, Loss: 0.671990790481425
Epoch 0, Loss: 0.5917275095829604
Epoch 0, Loss: 0.47304567915373796
Epoch 0, Loss: 0.6715436474250812
Epoch 0, Loss: 0.6294930926737019
Epoch 0, Loss: 0.6411181125265909
Epoch 0, Loss: 0.5378629298879908
Epoch 0, Loss: 0.7276486745801977
Epoch 0, Loss: 0.629721558306205
Epoch 0, Loss: 0.6070143467358334
Epoch 0, Loss: 0.675075837568178
Epoch 0, Loss: 0.7480534656833338
Epoch 0, Loss: 0.7019898887828131
Epoch 0, Loss: 0.6636395335125254
Epoch 0, Loss: 0.5496481246678756
Epoch 0, Loss: 0.7631910813816406
Epoch 0, Loss: 0.7313781854483572
Epoch 0, Loss: 0.688761077967223
Epoch 0, Loss: 0.777344393661657
Epoch 0, Loss: 0.7339415497954622
Epoch 0, Loss: 0.7168735811948937
Epoch 0, Loss: 0.5373873205679496
Epoch 0, Loss: 0.6616737812680202
Epoch 0, Loss: 0.6763061059346516
Epoch 0, Loss: 0.5577152777779789
Epoch 0, Loss: 0.6113454976709423
Epoch 0, Loss: 0.7469130206909802
Epoch 0, Loss: 0.6929359501299305
Epoch 0, Loss: 0.6045612982990751
2025-03-10 16:34:40,841 - INFO - TREENN3 Epoch 600:
2025-03-10 16:34:40,841 - INFO - Train MSE: 0.1460, Test MSE: 0.2405
2025-03-10 16:34:40,841 - INFO - Train R²: 0.8540, Test R²: 0.7150
2025-03-10 16:34:40,841 - INFO - Train MAE: 0.2945, Test MAE: 0.3151
2025-03-10 16:34:40,841 - INFO - Overfit ratio (train R² / test R²): 1.1943
Epoch 0, Loss: 0.5561555796823204
Epoch 0, Loss: 0.5798695866333591
Epoch 0, Loss: 0.8605590016219535
Epoch 0, Loss: 0.733602300387961
Epoch 0, Loss: 0.7527259537809591
Epoch 0, Loss: 0.7529702802295513
Epoch 0, Loss: 0.6378748563325375
Epoch 0, Loss: 0.6026194078123631
Epoch 0, Loss: 0.7996904241075055
Epoch 0, Loss: 0.6608147195863919
Epoch 0, Loss: 0.8206267668218815
Epoch 0, Loss: 0.6826165644848216
Epoch 0, Loss: 0.5737555042823085
Epoch 0, Loss: 0.7742796805772718
Epoch 0, Loss: 0.5052500829635803
Epoch 0, Loss: 0.5805700938480975
Epoch 0, Loss: 0.6672518987209313
Epoch 0, Loss: 0.6846191643849133
Epoch 0, Loss: 0.7714346905400523
Epoch 0, Loss: 0.5611924560856173
Epoch 0, Loss: 0.7291392230440533
Epoch 0, Loss: 0.6763060864564893
Epoch 0, Loss: 0.7420686726465008
Epoch 0, Loss: 0.7162515415585476
Epoch 0, Loss: 0.86170692780391
Epoch 0, Loss: 0.5866881378472925
Epoch 0, Loss: 0.5306029459796734
Epoch 0, Loss: 0.6856560227993012
Epoch 0, Loss: 0.720165310563788
Epoch 0, Loss: 0.6020623079568649
Epoch 0, Loss: 0.6969602434558076
Epoch 0, Loss: 0.8214202031647656
Epoch 0, Loss: 0.691854879482534
Epoch 0, Loss: 0.6702278158997897
Epoch 0, Loss: 0.5454644459711588
Epoch 0, Loss: 0.6095781552974293
Epoch 0, Loss: 0.6978790816852292
Epoch 0, Loss: 0.6399399123095802
Epoch 0, Loss: 0.650136872427248
Epoch 0, Loss: 0.6020151090867746
Epoch 0, Loss: 0.6968019945466838
Epoch 0, Loss: 0.5068731648611251
Epoch 0, Loss: 0.691176108718141
Epoch 0, Loss: 0.7275902817941714
Epoch 0, Loss: 0.7919948651246143
Epoch 0, Loss: 0.7004443369580374
Epoch 0, Loss: 0.7667425002828545
Epoch 0, Loss: 0.6260831495264895
Epoch 0, Loss: 0.7557144985482863
Epoch 0, Loss: 0.6895136353631519
Epoch 0, Loss: 0.596620453928151
Epoch 0, Loss: 0.6631533628819529
Epoch 0, Loss: 0.722101532214444
Epoch 0, Loss: 0.6297694733614244
Epoch 0, Loss: 0.5969597830226064
Epoch 0, Loss: 0.5783130295435585
Epoch 0, Loss: 0.6369244797198704
Epoch 0, Loss: 0.6445480275492971
Epoch 0, Loss: 0.7534230329714268
Epoch 0, Loss: 0.7210309519511898
Epoch 0, Loss: 0.7129160626301118
Epoch 0, Loss: 0.5957334060993822
Epoch 0, Loss: 0.6028863166655829
Epoch 0, Loss: 0.6337961318649137
Epoch 0, Loss: 0.7004465981662861
Epoch 0, Loss: 0.7620612727745395
Epoch 0, Loss: 0.6296038555689667
Epoch 0, Loss: 0.4928832750328001
Epoch 0, Loss: 0.6299973908361285
Epoch 0, Loss: 0.68083547956468
Epoch 0, Loss: 0.752302718221986
Epoch 0, Loss: 0.7611712291076306
Epoch 0, Loss: 0.7589548755066456
Epoch 0, Loss: 0.6142561300472087
Epoch 0, Loss: 0.598410914455096
Epoch 0, Loss: 0.5469277338215267
Epoch 0, Loss: 0.5848194852649072
Epoch 0, Loss: 0.6417823700955413
Epoch 0, Loss: 0.6012405543228174
Epoch 0, Loss: 0.6153552661714123
Epoch 0, Loss: 0.5539904292287368
Epoch 0, Loss: 0.6716878999255542
Epoch 0, Loss: 0.5702003612851888
Epoch 0, Loss: 0.5268794447738674
Epoch 0, Loss: 0.8067428587094984
Epoch 0, Loss: 0.6095859559963895
Epoch 0, Loss: 0.6406301146624738
Epoch 0, Loss: 0.6948460831670837
Epoch 0, Loss: 0.7378836492123049
Epoch 0, Loss: 0.7256626278525494
Epoch 0, Loss: 0.6899796586265926
Epoch 0, Loss: 0.6102574234493581
Epoch 0, Loss: 0.7683744687117133
Epoch 0, Loss: 0.7457092826724568
Epoch 0, Loss: 0.5061923183883271
Epoch 0, Loss: 0.5688996128390397
Epoch 0, Loss: 0.5138759768254282
Epoch 0, Loss: 0.5552910226823926
Epoch 0, Loss: 0.5276212656010952
Epoch 0, Loss: 0.7966571870398859
2025-03-10 16:34:41,370 - INFO - TREENN3 Epoch 700:
2025-03-10 16:34:41,370 - INFO - Train MSE: 0.1505, Test MSE: 0.2447
2025-03-10 16:34:41,370 - INFO - Train R²: 0.8495, Test R²: 0.7102
2025-03-10 16:34:41,370 - INFO - Train MAE: 0.3003, Test MAE: 0.3184
2025-03-10 16:34:41,371 - INFO - Overfit ratio (train R² / test R²): 1.1962
Epoch 0, Loss: 0.6561772848877779
Epoch 0, Loss: 0.6124569002421282
Epoch 0, Loss: 0.6896697332253798
Epoch 0, Loss: 0.5737492261258317
Epoch 0, Loss: 0.6048415738306349
Epoch 0, Loss: 0.627001091766817
Epoch 0, Loss: 0.6142359568676563
Epoch 0, Loss: 0.6165832808738171
Epoch 0, Loss: 0.5916295533998798
Epoch 0, Loss: 0.7279974649190057
Epoch 0, Loss: 0.8250194858153553
Epoch 0, Loss: 0.4712370302362617
Epoch 0, Loss: 0.7151553213730456
Epoch 0, Loss: 0.6262885076682824
Epoch 0, Loss: 0.46554768303396876
Epoch 0, Loss: 0.49366848393599705
Epoch 0, Loss: 0.5718656308457393
Epoch 0, Loss: 0.7242307271097574
Epoch 0, Loss: 0.523786118123272
Epoch 0, Loss: 0.6382055414315858
Epoch 0, Loss: 0.6207897599899517
Epoch 0, Loss: 0.5524146466111555
Epoch 0, Loss: 0.606413831793997
Epoch 0, Loss: 0.7851715321421343
Epoch 0, Loss: 0.8169165613536633
Epoch 0, Loss: 0.4742048070574766
Epoch 0, Loss: 0.6358151151886458
Epoch 0, Loss: 0.5063895082901864
Epoch 0, Loss: 0.6282188676873549
Epoch 0, Loss: 0.6330359748964015
Epoch 0, Loss: 0.6248760663800866
Epoch 0, Loss: 0.6005682983147659
Epoch 0, Loss: 0.7362124769811069
Epoch 0, Loss: 0.7162212791263157
Epoch 0, Loss: 0.6751423793170268
Epoch 0, Loss: 0.6721984565691089
Epoch 0, Loss: 0.8425155073162559
Epoch 0, Loss: 0.48983398315722215
Epoch 0, Loss: 0.6538530063002341
Epoch 0, Loss: 0.574030625127871
Epoch 0, Loss: 0.5834413105871252
Epoch 0, Loss: 0.6373859769962961
Epoch 0, Loss: 0.5815244822429432
Epoch 0, Loss: 0.4727533546530253
Epoch 0, Loss: 0.6473624423324769
Epoch 0, Loss: 0.8246452273188823
Epoch 0, Loss: 0.7766922239062903
Epoch 0, Loss: 0.7423440012167906
Epoch 0, Loss: 0.45903063866797655
Epoch 0, Loss: 0.8481385724166185
Epoch 0, Loss: 0.6075530982400119
Epoch 0, Loss: 0.4820418683159675
Epoch 0, Loss: 0.5111151158691265
Epoch 0, Loss: 0.6541778625107204
Epoch 0, Loss: 0.6329995144734513
Epoch 0, Loss: 0.6096704364103663
Epoch 0, Loss: 0.47994340537770097
Epoch 0, Loss: 0.6971036857815515
Epoch 0, Loss: 0.6420814650440786
Epoch 0, Loss: 0.6583670205469051
Epoch 0, Loss: 0.5305993966690122
Epoch 0, Loss: 0.5952610584554839
Epoch 0, Loss: 0.5182048406932602
Epoch 0, Loss: 0.6195604752900975
Epoch 0, Loss: 0.6491687322191438
Epoch 0, Loss: 0.6673151283290717
Epoch 0, Loss: 0.6193061902238465
Epoch 0, Loss: 0.7029953770646513
Epoch 0, Loss: 0.4958831808022511
Epoch 0, Loss: 0.5332716119851598
Epoch 0, Loss: 0.7818048811178078
Epoch 0, Loss: 0.6172999467140126
Epoch 0, Loss: 0.6946243295977492
Epoch 0, Loss: 0.7321043632749529
Epoch 0, Loss: 0.6980278721008965
Epoch 0, Loss: 0.7437509119471357
Epoch 0, Loss: 0.7490732493211131
Epoch 0, Loss: 0.5761152017999476
Epoch 0, Loss: 0.6874953917535624
Epoch 0, Loss: 0.5333963024751291
Epoch 0, Loss: 0.6956347740906377
Epoch 0, Loss: 0.5687139332219966
Epoch 0, Loss: 0.5716491963138601
Epoch 0, Loss: 0.6472040995204811
Epoch 0, Loss: 0.7203577730106853
Epoch 0, Loss: 0.6230853218107332
Epoch 0, Loss: 0.5948172637263562
Epoch 0, Loss: 0.7018827177855885
Epoch 0, Loss: 0.7616188960957193
Epoch 0, Loss: 0.5422390368049814
Epoch 0, Loss: 0.7178995021466397
Epoch 0, Loss: 0.6901214799580337
Epoch 0, Loss: 0.6658329069926024
Epoch 0, Loss: 0.5603595174483536
Epoch 0, Loss: 0.7609290730661362
Epoch 0, Loss: 0.6234283355889749
Epoch 0, Loss: 0.6392911698750962
Epoch 0, Loss: 0.6327234172216333
Epoch 0, Loss: 0.5715377023705653
Epoch 0, Loss: 0.5647196552102631
2025-03-10 16:34:41,852 - INFO - TREENN3 Epoch 800:
2025-03-10 16:34:41,852 - INFO - Train MSE: 0.1454, Test MSE: 0.2388
2025-03-10 16:34:41,852 - INFO - Train R²: 0.8546, Test R²: 0.7171
2025-03-10 16:34:41,852 - INFO - Train MAE: 0.2947, Test MAE: 0.3141
2025-03-10 16:34:41,852 - INFO - Overfit ratio (train R² / test R²): 1.1917
Epoch 0, Loss: 0.6259392633477361
Epoch 0, Loss: 0.717617071305615
Epoch 0, Loss: 0.7263356176957544
Epoch 0, Loss: 0.571461771966662
Epoch 0, Loss: 0.5316948840426831
Epoch 0, Loss: 0.44959037097867466
Epoch 0, Loss: 0.6558153462788734
Epoch 0, Loss: 0.7863612113239192
Epoch 0, Loss: 0.752861554706644
Epoch 0, Loss: 0.6864044332716936
Epoch 0, Loss: 0.5604372184703795
Epoch 0, Loss: 0.5819989002339185
Epoch 0, Loss: 0.6287461651682874
Epoch 0, Loss: 0.638274744591922
Epoch 0, Loss: 0.9369868198531248
Epoch 0, Loss: 0.45918733642315557
Epoch 0, Loss: 0.5586083946353123
Epoch 0, Loss: 0.6298493751834389
Epoch 0, Loss: 0.6930521829844243
Epoch 0, Loss: 0.6062153097962022
Epoch 0, Loss: 0.6416479228999435
Epoch 0, Loss: 0.7376574316454477
Epoch 0, Loss: 0.6140289669857846
Epoch 0, Loss: 0.650126946400838
Epoch 0, Loss: 0.7790837126217679
Epoch 0, Loss: 0.7844865353758725
Epoch 0, Loss: 0.5383747878133496
Epoch 0, Loss: 0.6194951063548022
Epoch 0, Loss: 0.6422445185973489
Epoch 0, Loss: 0.6685141100716087
Epoch 0, Loss: 0.6192548579968175
Epoch 0, Loss: 0.7485421323338347
Epoch 0, Loss: 0.47173593678667186
Epoch 0, Loss: 0.8402484310202325
Epoch 0, Loss: 0.728483928934778
Epoch 0, Loss: 0.6785884523963588
Epoch 0, Loss: 0.574336459760793
Epoch 0, Loss: 0.6507400804750325
Epoch 0, Loss: 0.7382370120464489
Epoch 0, Loss: 0.6963675776853974
Epoch 0, Loss: 0.6766597128473173
Epoch 0, Loss: 0.659868496356538
Epoch 0, Loss: 0.6032630944534598
Epoch 0, Loss: 0.5971246043197986
Epoch 0, Loss: 0.6369358453183543
Epoch 0, Loss: 0.7156041507433879
Epoch 0, Loss: 0.5941030613348413
Epoch 0, Loss: 0.47973668955648713
Epoch 0, Loss: 0.5996291727287248
Epoch 0, Loss: 0.5436678563158022
Epoch 0, Loss: 0.6137123401573593
Epoch 0, Loss: 0.533683488609507
Epoch 0, Loss: 0.6057193130904786
Epoch 0, Loss: 0.5020843936162858
Epoch 0, Loss: 0.5782539894666868
Epoch 0, Loss: 0.6839595796786667
Epoch 0, Loss: 0.5693516818776602
Epoch 0, Loss: 0.5692193760332127
Epoch 0, Loss: 0.6922003786357426
Epoch 0, Loss: 0.5772605546244248
Epoch 0, Loss: 0.5803636156168687
Epoch 0, Loss: 0.656484424090169
Epoch 0, Loss: 0.5855315646177804
Epoch 0, Loss: 0.5613173287397779
Epoch 0, Loss: 0.6834825790359649
Epoch 0, Loss: 0.6287363662852913
Epoch 0, Loss: 0.7191893928252504
Epoch 0, Loss: 0.5627676612402995
Epoch 0, Loss: 0.6786682734286967
Epoch 0, Loss: 0.6249588422288878
Epoch 0, Loss: 0.6683585721902454
Epoch 0, Loss: 0.5732345880060756
Epoch 0, Loss: 0.5679267914718101
Epoch 0, Loss: 0.6956390607082273
Epoch 0, Loss: 0.7931235027440655
Epoch 0, Loss: 0.5197319155987585
Epoch 0, Loss: 0.6401963214767304
Epoch 0, Loss: 0.59023795874007
Epoch 0, Loss: 0.7724378275008017
Epoch 0, Loss: 0.6970220511985518
Epoch 0, Loss: 0.5716076602489448
Epoch 0, Loss: 0.6104694409351504
Epoch 0, Loss: 0.7719679015342157
Epoch 0, Loss: 0.7274933735024398
Epoch 0, Loss: 0.680784135885628
Epoch 0, Loss: 0.6563517301856538
Epoch 0, Loss: 0.5985441581744778
Epoch 0, Loss: 0.6012587431735028
Epoch 0, Loss: 0.5815194678403907
Epoch 0, Loss: 0.6866231742559998
Epoch 0, Loss: 0.6348142619322571
Epoch 0, Loss: 0.48568189162280984
Epoch 0, Loss: 0.6049285415756431
Epoch 0, Loss: 0.6366652014273175
Epoch 0, Loss: 0.5836860528086427
Epoch 0, Loss: 0.6624839518499216
Epoch 0, Loss: 0.5032015384291852
Epoch 0, Loss: 0.7517573506981877
Epoch 0, Loss: 0.8006971854750125
Epoch 0, Loss: 0.49651045456245696
2025-03-10 16:34:42,361 - INFO - TREENN3 Epoch 900:
2025-03-10 16:34:42,361 - INFO - Train MSE: 0.1455, Test MSE: 0.2395
2025-03-10 16:34:42,361 - INFO - Train R²: 0.8545, Test R²: 0.7163
2025-03-10 16:34:42,361 - INFO - Train MAE: 0.2944, Test MAE: 0.3140
2025-03-10 16:34:42,361 - INFO - Overfit ratio (train R² / test R²): 1.1930
Epoch 0, Loss: 0.7635938885596608
Epoch 0, Loss: 0.7626873608118023
Epoch 0, Loss: 0.738760501014914
Epoch 0, Loss: 0.6987100425799805
Epoch 0, Loss: 0.5804770660797789
Epoch 0, Loss: 0.688739882705849
Epoch 0, Loss: 0.539542320917048
Epoch 0, Loss: 0.8710751912365903
Epoch 0, Loss: 0.8162671816754284
Epoch 0, Loss: 0.5643420220012058
Epoch 0, Loss: 0.5594642352941324
Epoch 0, Loss: 0.6622630358330625
Epoch 0, Loss: 0.6067973234753229
Epoch 0, Loss: 0.7146120054383839
Epoch 0, Loss: 0.6025672044192784
Epoch 0, Loss: 0.7678369449976024
Epoch 0, Loss: 0.5926243150297209
Epoch 0, Loss: 0.7128466643841774
Epoch 0, Loss: 0.46423206426742114
Epoch 0, Loss: 0.5636342439265734
Epoch 0, Loss: 0.6199886291482051
Epoch 0, Loss: 0.5775819465889539
Epoch 0, Loss: 0.7720224375337488
Epoch 0, Loss: 0.5802716093746281
Epoch 0, Loss: 0.5371561465267456
Epoch 0, Loss: 0.7459354849217904
Epoch 0, Loss: 0.6737641399418012
Epoch 0, Loss: 0.6218481305346604
Epoch 0, Loss: 0.5833845012970944
Epoch 0, Loss: 0.635823080230956
Epoch 0, Loss: 0.6101636293137651
Epoch 0, Loss: 0.5479032779840072
Epoch 0, Loss: 0.7747795981186447
Epoch 0, Loss: 0.6596583561535885
Epoch 0, Loss: 0.58130931969605
Epoch 0, Loss: 0.6037317713663779
Epoch 0, Loss: 0.6745056830888686
Epoch 0, Loss: 0.7782922808322432
Epoch 0, Loss: 0.6305322798511644
Epoch 0, Loss: 0.6147430404570658
Epoch 0, Loss: 0.6184805170036637
Epoch 0, Loss: 0.6121256016078461
Epoch 0, Loss: 0.6264696191122284
Epoch 0, Loss: 0.6589222380125811
Epoch 0, Loss: 0.5244370229801957
Epoch 0, Loss: 0.6526891271652554
Epoch 0, Loss: 0.6637729399506463
Epoch 0, Loss: 0.6098734009808473
Epoch 0, Loss: 0.5576268969442961
Epoch 0, Loss: 0.4436017835357441
Epoch 0, Loss: 0.6133265711980532
Epoch 0, Loss: 0.4662327091702987
Epoch 0, Loss: 0.7063847655014363
Epoch 0, Loss: 0.6302021521965719
Epoch 0, Loss: 0.7435701680344433
Epoch 0, Loss: 0.5850187821849723
Epoch 0, Loss: 0.7943769565362064
Epoch 0, Loss: 0.5147005236616592
Epoch 0, Loss: 0.7344936453928254
Epoch 0, Loss: 0.6981817004921741
Epoch 0, Loss: 0.6682496351023094
Epoch 0, Loss: 0.6210226842273043
Epoch 0, Loss: 0.6363310056071841
Epoch 0, Loss: 0.7412651413696426
Epoch 0, Loss: 0.5553434892167892
Epoch 0, Loss: 0.5903522571576512
Epoch 0, Loss: 0.8699811334584521
Epoch 0, Loss: 0.6573576785111043
Epoch 0, Loss: 0.5084837679001796
Epoch 0, Loss: 0.5935308999020877
Epoch 0, Loss: 0.6572399002071323
Epoch 0, Loss: 0.6618560288971252
Epoch 0, Loss: 0.5733700174517044
Epoch 0, Loss: 0.5908742041644135
Epoch 0, Loss: 0.6336663400541878
Epoch 0, Loss: 0.646284770749116
Epoch 0, Loss: 0.6049816943918533
Epoch 0, Loss: 0.57426210611689
Epoch 0, Loss: 0.6120864240007794
Epoch 0, Loss: 0.6730910591359291
Epoch 0, Loss: 0.6525472214457106
Epoch 0, Loss: 0.8140025736179468
Epoch 0, Loss: 0.6237477358546508
Epoch 0, Loss: 0.4941753337446723
Epoch 0, Loss: 0.7195425439652225
Epoch 0, Loss: 0.7126213249379204
Epoch 0, Loss: 0.6446657449835402
Epoch 0, Loss: 0.8356985031520827
Epoch 0, Loss: 0.6696655355666029
Epoch 0, Loss: 0.650367844167786
Epoch 0, Loss: 0.5623453066666925
Epoch 0, Loss: 0.7300274884979993
Epoch 0, Loss: 0.7582225596822885
Epoch 0, Loss: 0.5454815947704579
Epoch 0, Loss: 0.5132711475000358
Epoch 0, Loss: 0.6973381299640239
Epoch 0, Loss: 0.6618387839576984
Epoch 0, Loss: 0.6031032696829296
Epoch 0, Loss: 0.7097628813204312
2025-03-10 16:34:42,840 - INFO - TREENN3 Epoch 999:
2025-03-10 16:34:42,841 - INFO - Train MSE: 0.1509, Test MSE: 0.2440
2025-03-10 16:34:42,841 - INFO - Train R²: 0.8491, Test R²: 0.7109
2025-03-10 16:34:42,841 - INFO - Train MAE: 0.3005, Test MAE: 0.3180
2025-03-10 16:34:42,841 - INFO - Overfit ratio (train R² / test R²): 1.1943
2025-03-10 16:34:42,845 - INFO -
TREENN3 Final Metrics:
2025-03-10 16:34:42,845 - INFO - R² Score: 0.7109
2025-03-10 16:34:42,845 - INFO - MAE: 0.3180
2025-03-10 16:34:42,846 - INFO - MSE: 0.2440
2025-03-10 16:34:42,846 - INFO - Train R²: 0.8491
2025-03-10 16:34:42,846 - INFO - Overfit Ratio: 1.1943
2025-03-10 16:34:42,846 - INFO - TREENN3 evaluation successful!
2025-03-10 16:34:42,846 - INFO -
Evaluating Forest Models...
2025-03-10 16:34:42,846 - INFO -
Initializing FONN1...
2025-03-10 16:34:42,846 - INFO - Model class: FONN1
2025-03-10 16:34:42,907 - INFO - FONN1 model initialized successfully!
2025-03-10 16:34:42,908 - INFO - FONN1 architecture:
2025-03-10 16:34:42,908 - INFO - Input dimension: 12
2025-03-10 16:34:42,908 - INFO - Hidden dimension: 64
2025-03-10 16:34:42,908 - INFO - Output dimension: 1
2025-03-10 16:34:42,908 - INFO - Alpha (tree contribution): 0.5
2025-03-10 16:34:42,908 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:34:42,909 - INFO - Training FONN1...
Epoch 0, Loss: 1.7915741547788582
2025-03-10 16:34:42,919 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:42,933 - INFO - FONN1 Epoch 0:
2025-03-10 16:34:42,933 - INFO - Train MSE: 1.6333, Test MSE: 1.0451
2025-03-10 16:34:42,934 - INFO - Train R²: -0.6333, Test R²: -0.2381
2025-03-10 16:34:42,934 - INFO - Train MAE: 0.9121, Test MAE: 0.7336
2025-03-10 16:34:42,934 - INFO - Overfit ratio (train R² / test R²): 2.6604
Epoch 0, Loss: 1.6037619654587523
2025-03-10 16:34:42,944 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 1.314727668125307
2025-03-10 16:34:42,954 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 1.203540167911548
2025-03-10 16:34:42,964 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 1.1508190553883544
2025-03-10 16:34:42,974 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 1.0540961297734768
2025-03-10 16:34:42,984 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.9414051196135648
2025-03-10 16:34:42,994 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.8629390018255052
2025-03-10 16:34:43,004 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.8850472754423144
2025-03-10 16:34:43,014 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.8580352390794289
2025-03-10 16:34:43,024 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.7646519235817594
2025-03-10 16:34:43,034 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.821006567699735
2025-03-10 16:34:43,044 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.7424852109687817
2025-03-10 16:34:43,054 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.7156164844027129
2025-03-10 16:34:43,063 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6935329834839165
2025-03-10 16:34:43,073 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.7727733215415821
2025-03-10 16:34:43,084 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6778865971422904
2025-03-10 16:34:43,094 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6596140367068167
2025-03-10 16:34:43,104 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6229729492790839
2025-03-10 16:34:43,114 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.7038858709919148
2025-03-10 16:34:43,123 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5961325582851824
2025-03-10 16:34:43,133 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5976714327571524
2025-03-10 16:34:43,144 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5726354756578799
2025-03-10 16:34:43,154 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5742418219329414
2025-03-10 16:34:43,164 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5670550117604919
2025-03-10 16:34:43,173 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6023064062409538
2025-03-10 16:34:43,183 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5859950241036587
2025-03-10 16:34:43,193 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.6307047318066216
2025-03-10 16:34:43,203 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4808239018545872
2025-03-10 16:34:43,213 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5207101123632386
2025-03-10 16:34:43,222 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5137709317924046
2025-03-10 16:34:43,232 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5650921045872713
2025-03-10 16:34:43,242 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5614879442325029
2025-03-10 16:34:43,251 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5257775868359995
2025-03-10 16:34:43,261 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5131585922963454
2025-03-10 16:34:43,271 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5514798433348534
2025-03-10 16:34:43,281 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5268803911017825
2025-03-10 16:34:43,291 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.47556471262421585
2025-03-10 16:34:43,301 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5383388772805944
2025-03-10 16:34:43,311 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5383317720120218
2025-03-10 16:34:43,320 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.49694801384462134
2025-03-10 16:34:43,330 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5233298176395973
2025-03-10 16:34:43,340 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.49064832193259134
2025-03-10 16:34:43,350 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4989250420908524
2025-03-10 16:34:43,359 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46808010312235804
2025-03-10 16:34:43,369 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5320801577229679
2025-03-10 16:34:43,379 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5194796917619451
2025-03-10 16:34:43,389 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.48285083710199944
2025-03-10 16:34:43,399 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.45444370731658174
2025-03-10 16:34:43,409 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4904393648313722
2025-03-10 16:34:43,419 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4137443345054745
2025-03-10 16:34:43,429 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5273055509058321
2025-03-10 16:34:43,439 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5721736461250104
2025-03-10 16:34:43,449 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.436807343011
2025-03-10 16:34:43,458 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4587139454045971
2025-03-10 16:34:43,468 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5009390823157142
2025-03-10 16:34:43,478 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4364423469729038
2025-03-10 16:34:43,488 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4280961745662336
2025-03-10 16:34:43,498 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46834150395889307
2025-03-10 16:34:43,508 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4723060936691452
2025-03-10 16:34:43,518 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.426017461125787
2025-03-10 16:34:43,528 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4467577395246417
2025-03-10 16:34:43,538 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46826940577548065
2025-03-10 16:34:43,548 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40281063757874125
2025-03-10 16:34:43,558 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.5219569042966761
2025-03-10 16:34:43,567 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4661405790012035
2025-03-10 16:34:43,577 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4192071284975091
2025-03-10 16:34:43,587 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4631499042867726
2025-03-10 16:34:43,597 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4322844547481566
2025-03-10 16:34:43,607 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4576884721333369
2025-03-10 16:34:43,616 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.462113267102427
2025-03-10 16:34:43,626 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3962487242664775
2025-03-10 16:34:43,636 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4028734848835408
2025-03-10 16:34:43,646 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.44295880300358187
2025-03-10 16:34:43,656 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.42139395597207135
2025-03-10 16:34:43,666 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.42295543317353346
2025-03-10 16:34:43,676 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4714825162214642
2025-03-10 16:34:43,686 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41189514897949725
2025-03-10 16:34:43,696 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3981032051082297
2025-03-10 16:34:43,706 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41408899982584785
2025-03-10 16:34:43,716 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40547460274578734
2025-03-10 16:34:43,726 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.45379578125271175
2025-03-10 16:34:43,735 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.496946310983138
2025-03-10 16:34:43,745 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.43626282236871494
2025-03-10 16:34:43,755 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.44738645374125585
2025-03-10 16:34:43,765 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4571069800709598
2025-03-10 16:34:43,775 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40374718354768935
2025-03-10 16:34:43,785 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4079266800664982
2025-03-10 16:34:43,795 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.45427441172400973
2025-03-10 16:34:43,804 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46205334711079615
2025-03-10 16:34:43,815 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4478917960921397
2025-03-10 16:34:43,824 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4394393208276463
2025-03-10 16:34:43,834 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41897994712974873
2025-03-10 16:34:43,844 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4391893703975304
2025-03-10 16:34:43,854 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41850580499426093
2025-03-10 16:34:43,863 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3866220452173665
2025-03-10 16:34:43,873 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.382658127136324
2025-03-10 16:34:43,883 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46113902568011494
2025-03-10 16:34:43,893 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40019070645343013
2025-03-10 16:34:43,903 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4524243729120837
2025-03-10 16:34:43,913 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4312517210991913
2025-03-10 16:34:43,923 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:43,937 - INFO - FONN1 Epoch 100:
2025-03-10 16:34:43,937 - INFO - Train MSE: 0.2461, Test MSE: 0.2071
2025-03-10 16:34:43,937 - INFO - Train R²: 0.7539, Test R²: 0.7546
2025-03-10 16:34:43,937 - INFO - Train MAE: 0.3489, Test MAE: 0.3373
2025-03-10 16:34:43,937 - INFO - Overfit ratio (train R² / test R²): 0.9990
Epoch 0, Loss: 0.4216136229106132
2025-03-10 16:34:43,947 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4357317700701878
2025-03-10 16:34:43,957 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.44417957709778655
2025-03-10 16:34:43,967 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4698273634333845
2025-03-10 16:34:43,977 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4031234989382948
2025-03-10 16:34:43,987 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40859766952690035
2025-03-10 16:34:43,997 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4017963140702378
2025-03-10 16:34:44,007 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40801542778124295
2025-03-10 16:34:44,016 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3929361432674153
2025-03-10 16:34:44,026 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3702313965700034
2025-03-10 16:34:44,036 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3815580945098108
2025-03-10 16:34:44,046 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3939772334597685
2025-03-10 16:34:44,056 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.370453270050473
2025-03-10 16:34:44,066 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.46550214819940805
2025-03-10 16:34:44,075 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.42084483052768445
2025-03-10 16:34:44,087 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3832475943084476
2025-03-10 16:34:44,097 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38877241815936864
2025-03-10 16:34:44,106 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4002398915689004
2025-03-10 16:34:44,116 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4258162447492292
2025-03-10 16:34:44,125 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41293687736074913
2025-03-10 16:34:44,135 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38640209062730035
2025-03-10 16:34:44,144 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.44829265247304234
2025-03-10 16:34:44,154 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4477085840831487
2025-03-10 16:34:44,164 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40104083079259006
2025-03-10 16:34:44,173 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.408464419448805
2025-03-10 16:34:44,183 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.410227482631243
2025-03-10 16:34:44,193 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40021321829062695
2025-03-10 16:34:44,202 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37479172539235167
2025-03-10 16:34:44,212 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.39714219391163635
2025-03-10 16:34:44,222 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4072097707050969
2025-03-10 16:34:44,231 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3367995673640115
2025-03-10 16:34:44,241 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4136626372098354
2025-03-10 16:34:44,251 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3699379484787495
2025-03-10 16:34:44,261 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.418152489800927
2025-03-10 16:34:44,271 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3640791839884767
2025-03-10 16:34:44,281 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38976471935465967
2025-03-10 16:34:44,291 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35085563189734953
2025-03-10 16:34:44,301 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3537251250217301
2025-03-10 16:34:44,311 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3700411957204552
2025-03-10 16:34:44,320 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3422839790804221
2025-03-10 16:34:44,330 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3408000625947209
2025-03-10 16:34:44,340 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4055212579389494
2025-03-10 16:34:44,349 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.44855331107568863
2025-03-10 16:34:44,359 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4346969364401518
2025-03-10 16:34:44,369 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3488421823743432
2025-03-10 16:34:44,379 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4465719700411417
2025-03-10 16:34:44,389 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3651668085607853
2025-03-10 16:34:44,399 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37142474988044244
2025-03-10 16:34:44,409 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3496085420940181
2025-03-10 16:34:44,419 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40316228306530627
2025-03-10 16:34:44,429 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3639624841925172
2025-03-10 16:34:44,439 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3735210811208155
2025-03-10 16:34:44,448 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3199034682320761
2025-03-10 16:34:44,458 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.377535597779145
2025-03-10 16:34:44,468 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38909916791985216
2025-03-10 16:34:44,477 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.365897635739662
2025-03-10 16:34:44,487 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32058567809449434
2025-03-10 16:34:44,497 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3664890929810998
2025-03-10 16:34:44,507 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32861452251409257
2025-03-10 16:34:44,516 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40451299352707687
2025-03-10 16:34:44,526 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33795609048782493
2025-03-10 16:34:44,536 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3921560375606328
2025-03-10 16:34:44,546 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41737727248343337
2025-03-10 16:34:44,556 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.407487402474524
2025-03-10 16:34:44,566 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3543420182868588
2025-03-10 16:34:44,575 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4100469302633758
2025-03-10 16:34:44,585 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3332405967262361
2025-03-10 16:34:44,594 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.334326135717687
2025-03-10 16:34:44,604 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3997114466386972
2025-03-10 16:34:44,614 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4084415520660512
2025-03-10 16:34:44,624 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3321462137133556
2025-03-10 16:34:44,633 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3899572324605185
2025-03-10 16:34:44,643 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36637237758102176
2025-03-10 16:34:44,653 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4131941002451969
2025-03-10 16:34:44,662 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3620535561958973
2025-03-10 16:34:44,672 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.415804674262385
2025-03-10 16:34:44,682 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3404240644818634
2025-03-10 16:34:44,692 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37312582238411546
2025-03-10 16:34:44,701 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3640493498369371
2025-03-10 16:34:44,711 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3762655914607333
2025-03-10 16:34:44,720 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38881365075665464
2025-03-10 16:34:44,730 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3394612091748577
2025-03-10 16:34:44,742 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30287681639134983
2025-03-10 16:34:44,752 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3597716273180922
2025-03-10 16:34:44,762 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3604705451032002
2025-03-10 16:34:44,772 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3522129011136818
2025-03-10 16:34:44,782 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37984394361982265
2025-03-10 16:34:44,791 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34183532183641513
2025-03-10 16:34:44,801 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37515518840835843
2025-03-10 16:34:44,811 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38073924672839626
2025-03-10 16:34:44,820 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4075584105241655
2025-03-10 16:34:44,830 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38232933808492975
2025-03-10 16:34:44,840 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32511926699199234
2025-03-10 16:34:44,849 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34166879400526967
2025-03-10 16:34:44,859 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33179549728782887
2025-03-10 16:34:44,869 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3341010753479775
2025-03-10 16:34:44,878 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4391340165505839
2025-03-10 16:34:44,888 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35409707924778494
2025-03-10 16:34:44,898 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3816189306387133
2025-03-10 16:34:44,907 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3155850728528777
2025-03-10 16:34:44,917 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:44,931 - INFO - FONN1 Epoch 200:
2025-03-10 16:34:44,931 - INFO - Train MSE: 0.2183, Test MSE: 0.2046
2025-03-10 16:34:44,931 - INFO - Train R²: 0.7817, Test R²: 0.7576
2025-03-10 16:34:44,931 - INFO - Train MAE: 0.3342, Test MAE: 0.3292
2025-03-10 16:34:44,931 - INFO - Overfit ratio (train R² / test R²): 1.0318
Epoch 0, Loss: 0.38368269309023145
2025-03-10 16:34:44,941 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3935556151815121
2025-03-10 16:34:44,951 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3554257376346895
2025-03-10 16:34:44,960 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.367920001267237
2025-03-10 16:34:44,970 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.380831559817102
2025-03-10 16:34:44,980 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3481147363818109
2025-03-10 16:34:44,990 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3835365280981455
2025-03-10 16:34:45,001 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3796123416098118
2025-03-10 16:34:45,011 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33176132260689484
2025-03-10 16:34:45,020 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37620116735073994
2025-03-10 16:34:45,030 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37883240019689834
2025-03-10 16:34:45,040 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33324367847289843
2025-03-10 16:34:45,050 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34794354869032673
2025-03-10 16:34:45,059 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34650717294883854
2025-03-10 16:34:45,069 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33269402127661546
2025-03-10 16:34:45,079 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.404768675451538
2025-03-10 16:34:45,090 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34034301818069923
2025-03-10 16:34:45,100 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34133047860088395
2025-03-10 16:34:45,110 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3454571111150928
2025-03-10 16:34:45,119 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32431556637535336
2025-03-10 16:34:45,129 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34458514583671207
2025-03-10 16:34:45,138 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3623510445775695
2025-03-10 16:34:45,148 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41797121776643337
2025-03-10 16:34:45,157 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3402916043979553
2025-03-10 16:34:45,167 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3434653656621015
2025-03-10 16:34:45,177 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3492493686499316
2025-03-10 16:34:45,186 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34211174028527624
2025-03-10 16:34:45,196 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3450935766674414
2025-03-10 16:34:45,206 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3842244907144399
2025-03-10 16:34:45,215 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36467131617672777
2025-03-10 16:34:45,225 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3947714610361901
2025-03-10 16:34:45,234 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34384738011117666
2025-03-10 16:34:45,244 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3780061736932591
2025-03-10 16:34:45,254 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38574208198721566
2025-03-10 16:34:45,263 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37178857037945895
2025-03-10 16:34:45,273 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3447171599265547
2025-03-10 16:34:45,282 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3189317801829187
2025-03-10 16:34:45,292 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3556646016259686
2025-03-10 16:34:45,301 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35707795270285103
2025-03-10 16:34:45,311 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3292904114780841
2025-03-10 16:34:45,320 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3003551485277263
2025-03-10 16:34:45,330 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37528799163315824
2025-03-10 16:34:45,339 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34692083717938094
2025-03-10 16:34:45,349 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3720435634717634
2025-03-10 16:34:45,359 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36490945322109797
2025-03-10 16:34:45,368 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3611198754818698
2025-03-10 16:34:45,378 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35783258122481876
2025-03-10 16:34:45,387 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33876143152496346
2025-03-10 16:34:45,397 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3788058493017125
2025-03-10 16:34:45,406 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34108173085883053
2025-03-10 16:34:45,416 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3815879088661436
2025-03-10 16:34:45,425 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3790974371055119
2025-03-10 16:34:45,435 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3292956648229364
2025-03-10 16:34:45,445 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35647077005664457
2025-03-10 16:34:45,455 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3385604967554657
2025-03-10 16:34:45,464 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29112360519289826
2025-03-10 16:34:45,474 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31637831564910746
2025-03-10 16:34:45,483 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36276943576671267
2025-03-10 16:34:45,493 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3363635405256825
2025-03-10 16:34:45,503 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37355798909149895
2025-03-10 16:34:45,512 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34746100827842713
2025-03-10 16:34:45,522 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3618960255131693
2025-03-10 16:34:45,531 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.39452443240449075
2025-03-10 16:34:45,541 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3589377573929574
2025-03-10 16:34:45,551 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3214118947126242
2025-03-10 16:34:45,561 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36732613976153256
2025-03-10 16:34:45,570 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3583511038707756
2025-03-10 16:34:45,580 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3579041687718901
2025-03-10 16:34:45,590 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3755193305802772
2025-03-10 16:34:45,600 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3738994521218343
2025-03-10 16:34:45,609 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34561430131563875
2025-03-10 16:34:45,619 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3023147442695609
2025-03-10 16:34:45,628 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.393456284632873
2025-03-10 16:34:45,638 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36951305848023097
2025-03-10 16:34:45,648 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35726968732770653
2025-03-10 16:34:45,658 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.329914812985827
2025-03-10 16:34:45,668 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3451399601867432
2025-03-10 16:34:45,677 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32169813579995027
2025-03-10 16:34:45,687 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3564604796353886
2025-03-10 16:34:45,697 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34538720848720234
2025-03-10 16:34:45,707 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35415715183633717
2025-03-10 16:34:45,717 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3673397966810762
2025-03-10 16:34:45,727 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3607424069131474
2025-03-10 16:34:45,737 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31011548470795425
2025-03-10 16:34:45,747 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28639156177458663
2025-03-10 16:34:45,756 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32325181318801083
2025-03-10 16:34:45,766 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3146517880572291
2025-03-10 16:34:45,776 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3509391312920252
2025-03-10 16:34:45,786 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30760203304254846
2025-03-10 16:34:45,796 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3397026587947837
2025-03-10 16:34:45,806 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35335337940321326
2025-03-10 16:34:45,816 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31742554702293097
2025-03-10 16:34:45,826 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.43132575098244363
2025-03-10 16:34:45,835 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3599149180070539
2025-03-10 16:34:45,846 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3225833792706623
2025-03-10 16:34:45,855 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4013692829041035
2025-03-10 16:34:45,865 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3738848927427814
2025-03-10 16:34:45,875 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3593148362685179
2025-03-10 16:34:45,885 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3452083291755755
2025-03-10 16:34:45,895 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3234664726725196
2025-03-10 16:34:45,905 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:45,919 - INFO - FONN1 Epoch 300:
2025-03-10 16:34:45,919 - INFO - Train MSE: 0.1977, Test MSE: 0.1948
2025-03-10 16:34:45,919 - INFO - Train R²: 0.8023, Test R²: 0.7693
2025-03-10 16:34:45,919 - INFO - Train MAE: 0.3173, Test MAE: 0.3157
2025-03-10 16:34:45,919 - INFO - Overfit ratio (train R² / test R²): 1.0429
Epoch 0, Loss: 0.36271093108117947
2025-03-10 16:34:45,929 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3401975857120707
2025-03-10 16:34:45,939 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3487156919348927
2025-03-10 16:34:45,949 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32434364090192974
2025-03-10 16:34:45,959 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3845324177667775
2025-03-10 16:34:45,969 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3462966291253472
2025-03-10 16:34:45,979 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35663545229523286
2025-03-10 16:34:45,989 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33151981254487983
2025-03-10 16:34:45,998 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36859997270674577
2025-03-10 16:34:46,010 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3539294949928973
2025-03-10 16:34:46,019 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3511711577403594
2025-03-10 16:34:46,030 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35544298842089056
2025-03-10 16:34:46,041 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3351337404862323
2025-03-10 16:34:46,051 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.343577266868788
2025-03-10 16:34:46,062 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3109679046670384
2025-03-10 16:34:46,072 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30064808968752615
2025-03-10 16:34:46,082 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35111019889687584
2025-03-10 16:34:46,092 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3404249574518546
2025-03-10 16:34:46,102 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3546269428472431
2025-03-10 16:34:46,112 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27341224549824256
2025-03-10 16:34:46,122 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32514494532606786
2025-03-10 16:34:46,131 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3085078129542389
2025-03-10 16:34:46,141 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3492623993777494
2025-03-10 16:34:46,151 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36651986176945883
2025-03-10 16:34:46,161 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.41555608782580256
2025-03-10 16:34:46,171 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33016098023783597
2025-03-10 16:34:46,182 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3376460236128746
2025-03-10 16:34:46,192 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3012802630252061
2025-03-10 16:34:46,202 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4083095023765488
2025-03-10 16:34:46,212 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34806413573321066
2025-03-10 16:34:46,222 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3543050390037654
2025-03-10 16:34:46,233 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3623157895855529
2025-03-10 16:34:46,243 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31331387702773866
2025-03-10 16:34:46,254 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3365704627606279
2025-03-10 16:34:46,264 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3742912296469696
2025-03-10 16:34:46,274 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29451918693814133
2025-03-10 16:34:46,283 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.326956752022047
2025-03-10 16:34:46,293 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3699387643861742
2025-03-10 16:34:46,303 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3155792620567663
2025-03-10 16:34:46,312 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38042919898216726
2025-03-10 16:34:46,322 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30804839019239294
2025-03-10 16:34:46,332 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34517001974693423
2025-03-10 16:34:46,342 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30441551476937373
2025-03-10 16:34:46,352 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3284006052746181
2025-03-10 16:34:46,362 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34344146607950415
2025-03-10 16:34:46,371 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3265472884140169
2025-03-10 16:34:46,381 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2897667773807567
2025-03-10 16:34:46,391 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33336794478599596
2025-03-10 16:34:46,401 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3432760227948929
2025-03-10 16:34:46,411 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3508638373113316
2025-03-10 16:34:46,420 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3768628365842627
2025-03-10 16:34:46,430 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3381198641116153
2025-03-10 16:34:46,440 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3199612750714506
2025-03-10 16:34:46,449 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3408859890937481
2025-03-10 16:34:46,459 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3368201507769847
2025-03-10 16:34:46,469 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3208334816106633
2025-03-10 16:34:46,479 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3418737734387243
2025-03-10 16:34:46,488 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.43900782944511013
2025-03-10 16:34:46,498 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3288953256459674
2025-03-10 16:34:46,509 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.39176970025747054
2025-03-10 16:34:46,520 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3176570295908082
2025-03-10 16:34:46,531 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3155101469411453
2025-03-10 16:34:46,542 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33529726972426993
2025-03-10 16:34:46,553 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3089732639842207
2025-03-10 16:34:46,563 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3777265243894618
2025-03-10 16:34:46,574 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3175136091885635
2025-03-10 16:34:46,588 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32911761180276683
2025-03-10 16:34:46,599 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3636788240026232
2025-03-10 16:34:46,609 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3218810444975948
2025-03-10 16:34:46,621 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3302256029346327
2025-03-10 16:34:46,631 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34757146443669706
2025-03-10 16:34:46,640 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37707706230325344
2025-03-10 16:34:46,651 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3468577494890678
2025-03-10 16:34:46,661 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.332333672851686
2025-03-10 16:34:46,671 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33056750182816097
2025-03-10 16:34:46,682 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3171661486176847
2025-03-10 16:34:46,693 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2890721976777366
2025-03-10 16:34:46,703 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32275606279946734
2025-03-10 16:34:46,713 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33847841304623527
2025-03-10 16:34:46,723 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36075396776576324
2025-03-10 16:34:46,733 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3324050618620149
2025-03-10 16:34:46,742 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3160499025619815
2025-03-10 16:34:46,752 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36193386062318045
2025-03-10 16:34:46,762 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3140545714115035
2025-03-10 16:34:46,772 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3827883695241609
2025-03-10 16:34:46,782 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31870495215096367
2025-03-10 16:34:46,792 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3063788460615934
2025-03-10 16:34:46,802 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38370871848486743
2025-03-10 16:34:46,811 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3318031353979841
2025-03-10 16:34:46,821 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.294398247183591
2025-03-10 16:34:46,831 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3349824560786908
2025-03-10 16:34:46,841 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32931056863353647
2025-03-10 16:34:46,850 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27713265621915745
2025-03-10 16:34:46,860 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31694519819488143
2025-03-10 16:34:46,869 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3270787986308219
2025-03-10 16:34:46,879 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36070928277596087
2025-03-10 16:34:46,890 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3063425687782953
2025-03-10 16:34:46,900 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30200164473140984
2025-03-10 16:34:46,910 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33106055785870947
2025-03-10 16:34:46,920 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2774692854476244
2025-03-10 16:34:46,930 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:46,943 - INFO - FONN1 Epoch 400:
2025-03-10 16:34:46,944 - INFO - Train MSE: 0.1816, Test MSE: 0.1903
2025-03-10 16:34:46,944 - INFO - Train R²: 0.8184, Test R²: 0.7745
2025-03-10 16:34:46,944 - INFO - Train MAE: 0.3072, Test MAE: 0.3124
2025-03-10 16:34:46,944 - INFO - Overfit ratio (train R² / test R²): 1.0566
Epoch 0, Loss: 0.337100592104273
2025-03-10 16:34:46,954 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30161202436277235
2025-03-10 16:34:46,964 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3785951684766833
2025-03-10 16:34:46,975 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32121918299088376
2025-03-10 16:34:46,985 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37276594563817556
2025-03-10 16:34:46,995 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3204654111277758
2025-03-10 16:34:47,006 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3229700233562159
2025-03-10 16:34:47,015 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32253074574767127
2025-03-10 16:34:47,025 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2948837084823673
2025-03-10 16:34:47,035 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2962428864194217
2025-03-10 16:34:47,045 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.319759133684113
2025-03-10 16:34:47,055 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35105291498411517
2025-03-10 16:34:47,065 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33727133218459215
2025-03-10 16:34:47,075 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30222071509222026
2025-03-10 16:34:47,085 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2855450108004288
2025-03-10 16:34:47,095 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3423971028201609
2025-03-10 16:34:47,105 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28064250086170234
2025-03-10 16:34:47,115 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34974132962698185
2025-03-10 16:34:47,125 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35067885895090123
2025-03-10 16:34:47,135 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3274147617991087
2025-03-10 16:34:47,145 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3115377882336639
2025-03-10 16:34:47,154 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3369499770423751
2025-03-10 16:34:47,164 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33824664837623536
2025-03-10 16:34:47,174 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3030776322440457
2025-03-10 16:34:47,184 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3248582540148474
2025-03-10 16:34:47,194 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30302145772463207
2025-03-10 16:34:47,204 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31384789285052966
2025-03-10 16:34:47,214 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3028280877934523
2025-03-10 16:34:47,224 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33938559959753345
2025-03-10 16:34:47,233 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32333206645781265
2025-03-10 16:34:47,243 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37443579674697774
2025-03-10 16:34:47,253 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.338922571722946
2025-03-10 16:34:47,263 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33111799926241303
2025-03-10 16:34:47,272 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3326355592002706
2025-03-10 16:34:47,282 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3835784359815835
2025-03-10 16:34:47,292 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3155857995645737
2025-03-10 16:34:47,302 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2762831611821604
2025-03-10 16:34:47,311 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3866733528679368
2025-03-10 16:34:47,321 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33492932244800483
2025-03-10 16:34:47,331 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28604786080958344
2025-03-10 16:34:47,340 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3003749193833221
2025-03-10 16:34:47,350 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3399512058914082
2025-03-10 16:34:47,360 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38101991342632124
2025-03-10 16:34:47,369 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3406882152001331
2025-03-10 16:34:47,379 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33928261952178745
2025-03-10 16:34:47,389 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28449701532291843
2025-03-10 16:34:47,398 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3475483977765197
2025-03-10 16:34:47,408 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4034952318033946
2025-03-10 16:34:47,418 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3328478457704664
2025-03-10 16:34:47,428 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33040865955823284
2025-03-10 16:34:47,438 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3468656319833025
2025-03-10 16:34:47,447 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29258189965227704
2025-03-10 16:34:47,457 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3552590676894448
2025-03-10 16:34:47,466 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3409293096346494
2025-03-10 16:34:47,476 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3701869790425604
2025-03-10 16:34:47,486 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3300795671115616
2025-03-10 16:34:47,495 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3434621839347555
2025-03-10 16:34:47,505 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3365205259850292
2025-03-10 16:34:47,515 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3143183398525067
2025-03-10 16:34:47,525 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3356679505097944
2025-03-10 16:34:47,535 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33941400686885653
2025-03-10 16:34:47,544 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3069162230294271
2025-03-10 16:34:47,554 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34002247099439975
2025-03-10 16:34:47,564 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29306188229950586
2025-03-10 16:34:47,573 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3256139124096499
2025-03-10 16:34:47,583 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32621447239738866
2025-03-10 16:34:47,594 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31194110905995287
2025-03-10 16:34:47,604 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31187145207944733
2025-03-10 16:34:47,614 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3301200457608257
2025-03-10 16:34:47,624 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3305230434257142
2025-03-10 16:34:47,635 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3149999601588753
2025-03-10 16:34:47,645 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3218537571597643
2025-03-10 16:34:47,655 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35460719403810714
2025-03-10 16:34:47,664 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3082709871383385
2025-03-10 16:34:47,674 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34075700734293063
2025-03-10 16:34:47,684 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3352372635023912
2025-03-10 16:34:47,696 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3702873822054294
2025-03-10 16:34:47,706 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3483759940508664
2025-03-10 16:34:47,716 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33163019939185395
2025-03-10 16:34:47,726 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3474710647331097
2025-03-10 16:34:47,735 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3422729597712562
2025-03-10 16:34:47,745 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34585902273186003
2025-03-10 16:34:47,755 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3397343359699011
2025-03-10 16:34:47,765 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31618582677515694
2025-03-10 16:34:47,774 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3271400517395497
2025-03-10 16:34:47,784 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31095892645718526
2025-03-10 16:34:47,794 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29929762475022703
2025-03-10 16:34:47,804 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36280436987993836
2025-03-10 16:34:47,813 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29374207916968437
2025-03-10 16:34:47,823 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36234853548380475
2025-03-10 16:34:47,834 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37677643565985336
2025-03-10 16:34:47,847 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33832778392962215
2025-03-10 16:34:47,860 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2969323253818455
2025-03-10 16:34:47,872 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32604405617593096
2025-03-10 16:34:47,882 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33671596845973795
2025-03-10 16:34:47,892 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3424861810303935
2025-03-10 16:34:47,902 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29136356939407954
2025-03-10 16:34:47,913 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3002400052306263
2025-03-10 16:34:47,923 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3412191747448359
2025-03-10 16:34:47,933 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2890523104051784
2025-03-10 16:34:47,942 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:47,957 - INFO - FONN1 Epoch 500:
2025-03-10 16:34:47,957 - INFO - Train MSE: 0.1721, Test MSE: 0.1838
2025-03-10 16:34:47,957 - INFO - Train R²: 0.8279, Test R²: 0.7823
2025-03-10 16:34:47,957 - INFO - Train MAE: 0.2982, Test MAE: 0.3042
2025-03-10 16:34:47,957 - INFO - Overfit ratio (train R² / test R²): 1.0582
Epoch 0, Loss: 0.31941920374171123
2025-03-10 16:34:47,967 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3292380549111873
2025-03-10 16:34:47,977 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2917146200164476
2025-03-10 16:34:47,988 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3017575857064976
2025-03-10 16:34:47,998 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2927926051676605
2025-03-10 16:34:48,008 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2980998111388391
2025-03-10 16:34:48,019 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30387506836050526
2025-03-10 16:34:48,029 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3242605396860043
2025-03-10 16:34:48,039 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3467983743548648
2025-03-10 16:34:48,049 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31548009027242807
2025-03-10 16:34:48,059 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3546275328473376
2025-03-10 16:34:48,069 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.313222805098084
2025-03-10 16:34:48,081 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3371027019860598
2025-03-10 16:34:48,090 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.340466228311243
2025-03-10 16:34:48,100 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33668010822966443
2025-03-10 16:34:48,110 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2672804699562496
2025-03-10 16:34:48,120 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3435769931252326
2025-03-10 16:34:48,130 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3180618193132456
2025-03-10 16:34:48,140 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32642343403860513
2025-03-10 16:34:48,149 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32665636582785923
2025-03-10 16:34:48,159 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3357001489675485
2025-03-10 16:34:48,169 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35841982608631706
2025-03-10 16:34:48,179 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3440361391488946
2025-03-10 16:34:48,188 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3125432245454932
2025-03-10 16:34:48,198 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2867220295075894
2025-03-10 16:34:48,208 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3022044052302575
2025-03-10 16:34:48,217 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29522232367872636
2025-03-10 16:34:48,227 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32481999417773616
2025-03-10 16:34:48,237 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.289966025750009
2025-03-10 16:34:48,247 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3207593176924453
2025-03-10 16:34:48,257 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36088693598232296
2025-03-10 16:34:48,267 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3355323078090122
2025-03-10 16:34:48,277 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31230840919201197
2025-03-10 16:34:48,286 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3467858084367744
2025-03-10 16:34:48,296 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3146285249296609
2025-03-10 16:34:48,306 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3119780810210551
2025-03-10 16:34:48,316 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2839371600208035
2025-03-10 16:34:48,326 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33796697533721093
2025-03-10 16:34:48,335 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3143311247713001
2025-03-10 16:34:48,345 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2759122179312878
2025-03-10 16:34:48,355 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28599087920250793
2025-03-10 16:34:48,364 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3324347784105657
2025-03-10 16:34:48,374 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32828432109322936
2025-03-10 16:34:48,383 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3139018146802146
2025-03-10 16:34:48,393 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3106502109632792
2025-03-10 16:34:48,403 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30664322197742366
2025-03-10 16:34:48,412 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2982045700783111
2025-03-10 16:34:48,422 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3620326634975974
2025-03-10 16:34:48,432 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35643255348386216
2025-03-10 16:34:48,442 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.322548329512481
2025-03-10 16:34:48,452 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28465077209097733
2025-03-10 16:34:48,462 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36091820682800657
2025-03-10 16:34:48,473 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32511315006873254
2025-03-10 16:34:48,483 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3442565646442508
2025-03-10 16:34:48,493 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3182368356358097
2025-03-10 16:34:48,503 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32842264157507023
2025-03-10 16:34:48,514 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3471119390292598
2025-03-10 16:34:48,524 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3017563771051521
2025-03-10 16:34:48,534 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36529880497696743
2025-03-10 16:34:48,544 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34288591872649815
2025-03-10 16:34:48,555 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29601796371124434
2025-03-10 16:34:48,565 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3038937464335465
2025-03-10 16:34:48,576 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28584328792884617
2025-03-10 16:34:48,587 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32929554579764525
2025-03-10 16:34:48,598 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.4028732056041497
2025-03-10 16:34:48,608 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2882233476625758
2025-03-10 16:34:48,618 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3063300642695108
2025-03-10 16:34:48,628 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2487775909550187
2025-03-10 16:34:48,638 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3550792960260932
2025-03-10 16:34:48,648 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3433828619935999
2025-03-10 16:34:48,658 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3063430476481908
2025-03-10 16:34:48,669 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30577676439949336
2025-03-10 16:34:48,679 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31124226444350467
2025-03-10 16:34:48,689 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3027017639526006
2025-03-10 16:34:48,699 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.23979261638305763
2025-03-10 16:34:48,709 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38060930643673646
2025-03-10 16:34:48,719 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3413528034342905
2025-03-10 16:34:48,729 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2534548400804906
2025-03-10 16:34:48,740 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3257826747492431
2025-03-10 16:34:48,750 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3010933595404551
2025-03-10 16:34:48,760 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31202981075895675
2025-03-10 16:34:48,770 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34223035610349223
2025-03-10 16:34:48,780 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3161160575257328
2025-03-10 16:34:48,791 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3663234608513113
2025-03-10 16:34:48,801 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3067688743908052
2025-03-10 16:34:48,811 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33263775715257626
2025-03-10 16:34:48,821 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2870666458506486
2025-03-10 16:34:48,831 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32357541925868477
2025-03-10 16:34:48,841 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3213121578474053
2025-03-10 16:34:48,852 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3005107084396362
2025-03-10 16:34:48,862 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3526296616834443
2025-03-10 16:34:48,872 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3428704136687448
2025-03-10 16:34:48,882 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32057343318551235
2025-03-10 16:34:48,892 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2874291163981708
2025-03-10 16:34:48,903 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2931742259457274
2025-03-10 16:34:48,913 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30270821757873245
2025-03-10 16:34:48,923 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31323400041440197
2025-03-10 16:34:48,933 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35192259930087477
2025-03-10 16:34:48,944 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30113255987562354
2025-03-10 16:34:48,954 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3108987941659442
2025-03-10 16:34:48,964 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:48,977 - INFO - FONN1 Epoch 600:
2025-03-10 16:34:48,977 - INFO - Train MSE: 0.1622, Test MSE: 0.1788
2025-03-10 16:34:48,978 - INFO - Train R²: 0.8378, Test R²: 0.7882
2025-03-10 16:34:48,978 - INFO - Train MAE: 0.2903, Test MAE: 0.2997
2025-03-10 16:34:48,978 - INFO - Overfit ratio (train R² / test R²): 1.0629
Epoch 0, Loss: 0.3065210025256503
2025-03-10 16:34:48,989 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3506032209765077
2025-03-10 16:34:48,999 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35929940285045064
2025-03-10 16:34:49,009 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2768021214495093
2025-03-10 16:34:49,020 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30028770020201445
2025-03-10 16:34:49,029 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3233197120139629
2025-03-10 16:34:49,039 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30338271169542264
2025-03-10 16:34:49,049 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3766192482329785
2025-03-10 16:34:49,059 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2641354533389778
2025-03-10 16:34:49,068 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29645695997729804
2025-03-10 16:34:49,078 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.252242474760438
2025-03-10 16:34:49,088 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2958985740652804
2025-03-10 16:34:49,098 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3150840151727894
2025-03-10 16:34:49,108 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2828369647355834
2025-03-10 16:34:49,119 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3246023297745709
2025-03-10 16:34:49,129 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31210221828659035
2025-03-10 16:34:49,139 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3271839159253057
2025-03-10 16:34:49,149 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3005847934787694
2025-03-10 16:34:49,158 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27440230470930566
2025-03-10 16:34:49,168 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2510601217537587
2025-03-10 16:34:49,178 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2955421537092807
2025-03-10 16:34:49,188 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30058572081790186
2025-03-10 16:34:49,198 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25254796785790445
2025-03-10 16:34:49,208 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3024235019978429
2025-03-10 16:34:49,218 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3074672540766275
2025-03-10 16:34:49,228 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31724661297290146
2025-03-10 16:34:49,238 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2966142200155792
2025-03-10 16:34:49,247 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3332656959863288
2025-03-10 16:34:49,257 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28762194905196725
2025-03-10 16:34:49,267 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3000305470395596
2025-03-10 16:34:49,277 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2582723662685134
2025-03-10 16:34:49,286 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32260077539563475
2025-03-10 16:34:49,296 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.312598029799882
2025-03-10 16:34:49,306 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3102907701402681
2025-03-10 16:34:49,315 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3217001084945784
2025-03-10 16:34:49,325 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3757141210665814
2025-03-10 16:34:49,335 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3535916034682526
2025-03-10 16:34:49,345 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38038453448892223
2025-03-10 16:34:49,355 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27034634349399145
2025-03-10 16:34:49,364 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3407590020723304
2025-03-10 16:34:49,374 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3046338865720235
2025-03-10 16:34:49,384 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.269965274628935
2025-03-10 16:34:49,394 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3505510206630861
2025-03-10 16:34:49,404 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2938984741094478
2025-03-10 16:34:49,414 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32701049396001763
2025-03-10 16:34:49,424 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3199544823923548
2025-03-10 16:34:49,434 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2924346530444666
2025-03-10 16:34:49,443 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26491780962400957
2025-03-10 16:34:49,453 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32032385584851636
2025-03-10 16:34:49,463 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35924441816736785
2025-03-10 16:34:49,473 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2953692928712902
2025-03-10 16:34:49,483 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29900734123897205
2025-03-10 16:34:49,493 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2939656654796723
2025-03-10 16:34:49,503 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3144574294763195
2025-03-10 16:34:49,512 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3014547769344205
2025-03-10 16:34:49,522 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.281829798595187
2025-03-10 16:34:49,532 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30804085218118277
2025-03-10 16:34:49,542 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.39034794170635745
2025-03-10 16:34:49,551 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3220593533128374
2025-03-10 16:34:49,561 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2833378382243451
2025-03-10 16:34:49,571 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2990234960145834
2025-03-10 16:34:49,581 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34420292468482877
2025-03-10 16:34:49,591 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2987049601115821
2025-03-10 16:34:49,601 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2785354633389717
2025-03-10 16:34:49,611 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35060236960951496
2025-03-10 16:34:49,620 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3067483908855979
2025-03-10 16:34:49,630 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3046424837203854
2025-03-10 16:34:49,640 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3079793137054816
2025-03-10 16:34:49,650 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27152893472389933
2025-03-10 16:34:49,660 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2862972927989455
2025-03-10 16:34:49,670 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30470439135364613
2025-03-10 16:34:49,680 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2476774790957705
2025-03-10 16:34:49,690 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29104859253238374
2025-03-10 16:34:49,700 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31667722084829103
2025-03-10 16:34:49,710 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32719616654982236
2025-03-10 16:34:49,720 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2967010273616055
2025-03-10 16:34:49,730 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3147679421881486
2025-03-10 16:34:49,740 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2760264461654643
2025-03-10 16:34:49,750 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31164696142653897
2025-03-10 16:34:49,760 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3132342086600865
2025-03-10 16:34:49,770 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30865271081389184
2025-03-10 16:34:49,780 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3562686823198868
2025-03-10 16:34:49,790 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30130788768781847
2025-03-10 16:34:49,800 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3409520428203891
2025-03-10 16:34:49,811 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37795635020049767
2025-03-10 16:34:49,821 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3190506500169262
2025-03-10 16:34:49,831 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3348530761051974
2025-03-10 16:34:49,843 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.366508509500822
2025-03-10 16:34:49,858 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26712372591185385
2025-03-10 16:34:49,873 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2966911788668185
2025-03-10 16:34:49,886 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31058786246010084
2025-03-10 16:34:49,899 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.325638909892004
2025-03-10 16:34:49,908 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30395345629079085
2025-03-10 16:34:49,918 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3415225894664963
2025-03-10 16:34:49,928 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34876603976932985
2025-03-10 16:34:49,937 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34600521319900185
2025-03-10 16:34:49,947 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31143769150593653
2025-03-10 16:34:49,956 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3076204032636574
2025-03-10 16:34:49,966 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.318624420008886
2025-03-10 16:34:49,975 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2521772116843327
2025-03-10 16:34:49,985 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:49,998 - INFO - FONN1 Epoch 700:
2025-03-10 16:34:49,999 - INFO - Train MSE: 0.1564, Test MSE: 0.1781
2025-03-10 16:34:49,999 - INFO - Train R²: 0.8436, Test R²: 0.7890
2025-03-10 16:34:49,999 - INFO - Train MAE: 0.2873, Test MAE: 0.3013
2025-03-10 16:34:49,999 - INFO - Overfit ratio (train R² / test R²): 1.0691
Epoch 0, Loss: 0.3370352961941224
2025-03-10 16:34:50,009 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29104735365371165
2025-03-10 16:34:50,019 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.37093726870197014
2025-03-10 16:34:50,029 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3273536829260266
2025-03-10 16:34:50,038 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25718899623826513
2025-03-10 16:34:50,048 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3079327111176118
2025-03-10 16:34:50,058 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29456912904957544
2025-03-10 16:34:50,068 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26094556552145076
2025-03-10 16:34:50,077 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.40074600465140797
2025-03-10 16:34:50,087 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28239255769706073
2025-03-10 16:34:50,097 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30906737380954286
2025-03-10 16:34:50,107 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3366358602259936
2025-03-10 16:34:50,117 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3259658787833497
2025-03-10 16:34:50,126 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3070415799653505
2025-03-10 16:34:50,136 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29408411579037086
2025-03-10 16:34:50,146 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2720867211228069
2025-03-10 16:34:50,156 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30953355834940827
2025-03-10 16:34:50,165 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31209153709903636
2025-03-10 16:34:50,175 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2922555161417279
2025-03-10 16:34:50,185 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3203162705205201
2025-03-10 16:34:50,195 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2672028591996389
2025-03-10 16:34:50,204 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32514534764592423
2025-03-10 16:34:50,214 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3013489860747464
2025-03-10 16:34:50,224 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27079822968689715
2025-03-10 16:34:50,235 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29025816324001397
2025-03-10 16:34:50,245 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29025043947291945
2025-03-10 16:34:50,255 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28281118595135163
2025-03-10 16:34:50,265 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3216544260564288
2025-03-10 16:34:50,275 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25444332244028856
2025-03-10 16:34:50,284 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31354086573957574
2025-03-10 16:34:50,295 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.328463849522219
2025-03-10 16:34:50,308 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3122233269723201
2025-03-10 16:34:50,321 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31588910038442386
2025-03-10 16:34:50,334 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29445969011974193
2025-03-10 16:34:50,347 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3175702022026603
2025-03-10 16:34:50,360 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26776769865466754
2025-03-10 16:34:50,374 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2808077393741061
2025-03-10 16:34:50,387 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30629186375209766
2025-03-10 16:34:50,400 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34254294369098576
2025-03-10 16:34:50,413 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3551275405701999
2025-03-10 16:34:50,426 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2924771006231241
2025-03-10 16:34:50,439 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32399920030646945
2025-03-10 16:34:50,452 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29746037360728067
2025-03-10 16:34:50,465 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.294246105399645
2025-03-10 16:34:50,478 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34384324019439794
2025-03-10 16:34:50,491 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32737924379967165
2025-03-10 16:34:50,504 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3016656609927829
2025-03-10 16:34:50,517 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3402260982823666
2025-03-10 16:34:50,530 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35608755311704865
2025-03-10 16:34:50,543 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30346513080987403
2025-03-10 16:34:50,556 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30093213269048713
2025-03-10 16:34:50,569 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2896473099332928
2025-03-10 16:34:50,582 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32704972523609477
2025-03-10 16:34:50,595 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3066229178976986
2025-03-10 16:34:50,608 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.303947231075636
2025-03-10 16:34:50,621 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31322343734461383
2025-03-10 16:34:50,634 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31755857987445546
2025-03-10 16:34:50,647 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30337106637382
2025-03-10 16:34:50,660 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3100985189814745
2025-03-10 16:34:50,673 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30753714415643396
2025-03-10 16:34:50,686 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2706970982661945
2025-03-10 16:34:50,700 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2780538366150873
2025-03-10 16:34:50,713 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3222260517496538
2025-03-10 16:34:50,726 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3448674020827463
2025-03-10 16:34:50,739 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3180053149693025
2025-03-10 16:34:50,752 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31380089509590386
2025-03-10 16:34:50,765 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31782112764070103
2025-03-10 16:34:50,778 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3423721022052191
2025-03-10 16:34:50,791 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27759367967004733
2025-03-10 16:34:50,804 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3329030223974259
2025-03-10 16:34:50,817 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3006675028685559
2025-03-10 16:34:50,829 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2858777788238891
2025-03-10 16:34:50,839 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29074628686639203
2025-03-10 16:34:50,849 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.314107397660795
2025-03-10 16:34:50,858 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2960268567761909
2025-03-10 16:34:50,869 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3074212181158794
2025-03-10 16:34:50,878 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2778645742460033
2025-03-10 16:34:50,888 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2748282206107688
2025-03-10 16:34:50,898 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3048738884153615
2025-03-10 16:34:50,908 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3809225316311234
2025-03-10 16:34:50,918 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29911153474362195
2025-03-10 16:34:50,927 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27197059695626014
2025-03-10 16:34:50,937 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28109984394633253
2025-03-10 16:34:50,947 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2540421077536654
2025-03-10 16:34:50,957 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31694285068590855
2025-03-10 16:34:50,966 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27149574728349424
2025-03-10 16:34:50,976 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31198634143211385
2025-03-10 16:34:50,986 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30816128657896824
2025-03-10 16:34:50,996 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25838751255680037
2025-03-10 16:34:51,006 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29071046887282587
2025-03-10 16:34:51,016 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33784420795422654
2025-03-10 16:34:51,026 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3132778709617845
2025-03-10 16:34:51,035 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2728880582525442
2025-03-10 16:34:51,045 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3455695511722835
2025-03-10 16:34:51,055 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31763751172756216
2025-03-10 16:34:51,065 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3840442580450514
2025-03-10 16:34:51,074 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30563659716902314
2025-03-10 16:34:51,084 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2829970214765395
2025-03-10 16:34:51,094 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3330222905902891
2025-03-10 16:34:51,104 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3059063300684594
2025-03-10 16:34:51,114 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:51,128 - INFO - FONN1 Epoch 800:
2025-03-10 16:34:51,128 - INFO - Train MSE: 0.1514, Test MSE: 0.1747
2025-03-10 16:34:51,128 - INFO - Train R²: 0.8486, Test R²: 0.7931
2025-03-10 16:34:51,129 - INFO - Train MAE: 0.2839, Test MAE: 0.2978
2025-03-10 16:34:51,129 - INFO - Overfit ratio (train R² / test R²): 1.0700
Epoch 0, Loss: 0.31484770650879207
2025-03-10 16:34:51,139 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2744140922906888
2025-03-10 16:34:51,149 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3136014498316391
2025-03-10 16:34:51,159 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2784368582357638
2025-03-10 16:34:51,169 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31428163763955436
2025-03-10 16:34:51,179 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.297816264122117
2025-03-10 16:34:51,189 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3029050174940221
2025-03-10 16:34:51,199 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32249420809267487
2025-03-10 16:34:51,209 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36846558653998934
2025-03-10 16:34:51,219 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3140377813859226
2025-03-10 16:34:51,228 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2947366598462732
2025-03-10 16:34:51,238 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2639823452339633
2025-03-10 16:34:51,248 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3024413995407944
2025-03-10 16:34:51,257 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2770482225505828
2025-03-10 16:34:51,267 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2631424259468299
2025-03-10 16:34:51,277 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3099245170637254
2025-03-10 16:34:51,286 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31266959405181605
2025-03-10 16:34:51,296 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2723087147768565
2025-03-10 16:34:51,306 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3273808902808055
2025-03-10 16:34:51,316 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25797497511440726
2025-03-10 16:34:51,325 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2921836538792036
2025-03-10 16:34:51,335 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33233545220412586
2025-03-10 16:34:51,345 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2970778429684698
2025-03-10 16:34:51,354 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35114056845750813
2025-03-10 16:34:51,364 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29611874228552304
2025-03-10 16:34:51,374 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32161806627919365
2025-03-10 16:34:51,383 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32354216770361705
2025-03-10 16:34:51,393 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3185993435923189
2025-03-10 16:34:51,403 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3093679206104899
2025-03-10 16:34:51,413 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.24882161356030544
2025-03-10 16:34:51,422 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3073764425100383
2025-03-10 16:34:51,432 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27739166372068996
2025-03-10 16:34:51,442 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32776734491779613
2025-03-10 16:34:51,452 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30121502767822744
2025-03-10 16:34:51,461 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29619292562205707
2025-03-10 16:34:51,471 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30422413579333196
2025-03-10 16:34:51,481 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3135444141026556
2025-03-10 16:34:51,491 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2746791861677454
2025-03-10 16:34:51,500 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28379325028767577
2025-03-10 16:34:51,510 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3187598811979905
2025-03-10 16:34:51,519 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29469353933355624
2025-03-10 16:34:51,529 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2700926666977305
2025-03-10 16:34:51,539 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3130530309826581
2025-03-10 16:34:51,549 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3080138834980369
2025-03-10 16:34:51,558 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3053699861244716
2025-03-10 16:34:51,568 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3018082079001792
2025-03-10 16:34:51,577 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3439374456578947
2025-03-10 16:34:51,587 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.364522099996091
2025-03-10 16:34:51,599 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30743220247248776
2025-03-10 16:34:51,609 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31267016635905853
2025-03-10 16:34:51,619 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30973406905822115
2025-03-10 16:34:51,629 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27349693166826444
2025-03-10 16:34:51,638 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31323448706027507
2025-03-10 16:34:51,648 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3328379913439497
2025-03-10 16:34:51,657 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28592076772151703
2025-03-10 16:34:51,667 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28175080326977986
2025-03-10 16:34:51,676 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27856911289128006
2025-03-10 16:34:51,686 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.284288928680805
2025-03-10 16:34:51,695 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32454875471486583
2025-03-10 16:34:51,705 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29176180011564035
2025-03-10 16:34:51,714 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.23777759649105795
2025-03-10 16:34:51,724 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3099312626139191
2025-03-10 16:34:51,734 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2828722598043827
2025-03-10 16:34:51,744 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30029004043805624
2025-03-10 16:34:51,753 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2978599548508971
2025-03-10 16:34:51,763 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2623185266924483
2025-03-10 16:34:51,773 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3544948439506062
2025-03-10 16:34:51,782 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.35282113307910595
2025-03-10 16:34:51,792 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27577396073763544
2025-03-10 16:34:51,802 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3434560945182246
2025-03-10 16:34:51,811 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2827847355747568
2025-03-10 16:34:51,821 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3650361782174083
2025-03-10 16:34:51,831 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3058806775871932
2025-03-10 16:34:51,840 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3517222030148346
2025-03-10 16:34:51,850 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.38666237525030656
2025-03-10 16:34:51,860 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27602734607329227
2025-03-10 16:34:51,869 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28956541402992375
2025-03-10 16:34:51,879 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27635041665425547
2025-03-10 16:34:51,889 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27997146715083565
2025-03-10 16:34:51,900 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2864643587091345
2025-03-10 16:34:51,910 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30322808717577954
2025-03-10 16:34:51,921 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26348581574958885
2025-03-10 16:34:51,931 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2788717888771784
2025-03-10 16:34:51,944 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2971825897856953
2025-03-10 16:34:51,956 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28782820756720406
2025-03-10 16:34:51,967 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3299249214598308
2025-03-10 16:34:51,977 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32541672688690954
2025-03-10 16:34:51,987 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2637331900337392
2025-03-10 16:34:51,998 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33879283105020724
2025-03-10 16:34:52,009 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29840038028719285
2025-03-10 16:34:52,019 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2694631553226216
2025-03-10 16:34:52,029 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2936327966964632
2025-03-10 16:34:52,039 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2672842365619166
2025-03-10 16:34:52,049 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2772085229564647
2025-03-10 16:34:52,060 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2745593824069836
2025-03-10 16:34:52,070 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3465730711052592
2025-03-10 16:34:52,080 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32755579378678856
2025-03-10 16:34:52,090 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2862090357149476
2025-03-10 16:34:52,100 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28333165628717333
2025-03-10 16:34:52,110 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29247020624637904
2025-03-10 16:34:52,120 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:52,135 - INFO - FONN1 Epoch 900:
2025-03-10 16:34:52,135 - INFO - Train MSE: 0.1474, Test MSE: 0.1718
2025-03-10 16:34:52,135 - INFO - Train R²: 0.8526, Test R²: 0.7965
2025-03-10 16:34:52,135 - INFO - Train MAE: 0.2796, Test MAE: 0.2947
2025-03-10 16:34:52,135 - INFO - Overfit ratio (train R² / test R²): 1.0703
Epoch 0, Loss: 0.31476588951414786
2025-03-10 16:34:52,145 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2949279904847409
2025-03-10 16:34:52,155 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3244136021039463
2025-03-10 16:34:52,165 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.283532046913129
2025-03-10 16:34:52,174 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26520980509332537
2025-03-10 16:34:52,184 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32604388171947335
2025-03-10 16:34:52,194 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26941644495976047
2025-03-10 16:34:52,204 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.298865828564965
2025-03-10 16:34:52,213 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3638868625950759
2025-03-10 16:34:52,223 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26225898706096196
2025-03-10 16:34:52,233 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27574019791033694
2025-03-10 16:34:52,244 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33131648847399453
2025-03-10 16:34:52,257 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3516330343251757
2025-03-10 16:34:52,270 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.295471399136263
2025-03-10 16:34:52,283 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2645884724585878
2025-03-10 16:34:52,296 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.269967759204017
2025-03-10 16:34:52,309 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2849808013344447
2025-03-10 16:34:52,322 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3175151241050709
2025-03-10 16:34:52,335 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2889955028853158
2025-03-10 16:34:52,348 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28967204060303114
2025-03-10 16:34:52,361 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28873112809343654
2025-03-10 16:34:52,374 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3013897277263942
2025-03-10 16:34:52,387 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29498897805203167
2025-03-10 16:34:52,400 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28295989526889703
2025-03-10 16:34:52,413 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3426385198999889
2025-03-10 16:34:52,426 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3077319546418705
2025-03-10 16:34:52,439 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2632757533575704
2025-03-10 16:34:52,452 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32404576618893643
2025-03-10 16:34:52,466 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26173321295963725
2025-03-10 16:34:52,479 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28467421397405945
2025-03-10 16:34:52,492 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27465116709642584
2025-03-10 16:34:52,505 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3468312126917903
2025-03-10 16:34:52,518 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2982249731973729
2025-03-10 16:34:52,531 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3261148306323245
2025-03-10 16:34:52,544 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26348863242111475
2025-03-10 16:34:52,557 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30312675171560804
2025-03-10 16:34:52,570 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3186636755635678
2025-03-10 16:34:52,583 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28473647038010175
2025-03-10 16:34:52,596 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30178880296775257
2025-03-10 16:34:52,609 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3168788431812501
2025-03-10 16:34:52,622 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2810443357366007
2025-03-10 16:34:52,635 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2833453191084418
2025-03-10 16:34:52,648 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29701863278963964
2025-03-10 16:34:52,661 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2522013487297181
2025-03-10 16:34:52,674 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3119548285088611
2025-03-10 16:34:52,687 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2966693439812995
2025-03-10 16:34:52,701 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.28575170862883337
2025-03-10 16:34:52,714 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3100955690433306
2025-03-10 16:34:52,727 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2948778960839752
2025-03-10 16:34:52,740 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2906363072078788
2025-03-10 16:34:52,753 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.333832064127709
2025-03-10 16:34:52,766 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2546112471940673
2025-03-10 16:34:52,778 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.24713687414120963
2025-03-10 16:34:52,788 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3179782448771968
2025-03-10 16:34:52,798 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2962143740863621
2025-03-10 16:34:52,818 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31285484604419783
2025-03-10 16:34:52,830 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3638349220323523
2025-03-10 16:34:52,840 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.26596459112053183
2025-03-10 16:34:52,849 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2748090408145976
2025-03-10 16:34:52,859 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29470026997278187
2025-03-10 16:34:52,869 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2887356179779403
2025-03-10 16:34:52,879 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32595028732916786
2025-03-10 16:34:52,889 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3319127566534797
2025-03-10 16:34:52,898 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3178042306914353
2025-03-10 16:34:52,908 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2955648458623053
2025-03-10 16:34:52,918 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3133524249984321
2025-03-10 16:34:52,928 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.34191183229125927
2025-03-10 16:34:52,938 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3228381328238909
2025-03-10 16:34:52,948 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2613750562802864
2025-03-10 16:34:52,958 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3355508825628509
2025-03-10 16:34:52,968 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3521507006461588
2025-03-10 16:34:52,978 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2920635725184019
2025-03-10 16:34:52,987 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27789370223084203
2025-03-10 16:34:52,997 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3587117086712554
2025-03-10 16:34:53,007 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.326252587196741
2025-03-10 16:34:53,017 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3156186889158826
2025-03-10 16:34:53,027 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2582032981139341
2025-03-10 16:34:53,037 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29374504754898534
2025-03-10 16:34:53,047 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3285775580155252
2025-03-10 16:34:53,057 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.276665864331575
2025-03-10 16:34:53,066 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2595766568944716
2025-03-10 16:34:53,076 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.2825307838816118
2025-03-10 16:34:53,086 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.27624050953165225
2025-03-10 16:34:53,096 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3362073816301639
2025-03-10 16:34:53,105 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3294750954982967
2025-03-10 16:34:53,116 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.31398675796945763
2025-03-10 16:34:53,126 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33742574062441744
2025-03-10 16:34:53,136 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.29654014232988113
2025-03-10 16:34:53,145 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25937458403372765
2025-03-10 16:34:53,156 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3183977093286532
2025-03-10 16:34:53,165 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.33257728939929143
2025-03-10 16:34:53,175 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.36897020123071134
2025-03-10 16:34:53,185 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.24933776419810455
2025-03-10 16:34:53,194 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25404994836099626
2025-03-10 16:34:53,204 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.25120072212465827
2025-03-10 16:34:53,214 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.32819605653387846
2025-03-10 16:34:53,223 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3221430130706191
2025-03-10 16:34:53,233 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.3407593380597697
2025-03-10 16:34:53,243 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
Epoch 0, Loss: 0.30822481141403196
2025-03-10 16:34:53,252 - INFO - Skipping tree regularization for FONN1 - feature_importances_ is read-only
2025-03-10 16:34:53,266 - INFO - FONN1 Epoch 999:
2025-03-10 16:34:53,266 - INFO - Train MSE: 0.1404, Test MSE: 0.1669
2025-03-10 16:34:53,266 - INFO - Train R²: 0.8596, Test R²: 0.8023
2025-03-10 16:34:53,266 - INFO - Train MAE: 0.2742, Test MAE: 0.2916
2025-03-10 16:34:53,266 - INFO - Overfit ratio (train R² / test R²): 1.0715
2025-03-10 16:34:53,279 - INFO -
FONN1 Final Metrics:
2025-03-10 16:34:53,280 - INFO - R² Score: 0.8023
2025-03-10 16:34:53,280 - INFO - MAE: 0.2916
2025-03-10 16:34:53,280 - INFO - MSE: 0.1669
2025-03-10 16:34:53,280 - INFO - Train R²: 0.8596
2025-03-10 16:34:53,280 - INFO - Overfit Ratio: 1.0715
2025-03-10 16:34:53,280 - INFO - FONN1 evaluation successful!
2025-03-10 16:34:53,280 - INFO -
Initializing FONN2...
2025-03-10 16:34:53,281 - INFO - FONN2 uses trees in the hidden layer with standard learning rate: 0.01
2025-03-10 16:34:53,281 - INFO - Model class: FONN2
2025-03-10 16:34:53,326 - INFO - FONN2 initialized without alpha parameter
2025-03-10 16:34:53,326 - INFO - FONN2 model initialized successfully!
2025-03-10 16:34:53,327 - INFO - FONN2 architecture:
2025-03-10 16:34:53,327 - INFO - Input dimension: 12
2025-03-10 16:34:53,327 - INFO - Hidden dimension: 64
2025-03-10 16:34:53,327 - INFO - Output dimension: 1
2025-03-10 16:34:53,327 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:34:53,327 - INFO - Training FONN2...
Epoch 0, Loss: 1.94313687785416
2025-03-10 16:34:53,336 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:53,347 - INFO - FONN2 Epoch 0:
2025-03-10 16:34:53,347 - INFO - Train MSE: 1.3813, Test MSE: 1.0337
2025-03-10 16:34:53,347 - INFO - Train R²: -0.3813, Test R²: -0.2246
2025-03-10 16:34:53,347 - INFO - Train MAE: 0.9065, Test MAE: 0.7909
2025-03-10 16:34:53,347 - INFO - Overfit ratio (train R² / test R²): 1.6979
Epoch 0, Loss: 1.5755854854369813
2025-03-10 16:34:53,357 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.5432083068051077
2025-03-10 16:34:53,366 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.4287663264345156
2025-03-10 16:34:53,375 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.3079387883005573
2025-03-10 16:34:53,384 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.2604408038337753
2025-03-10 16:34:53,396 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.3608213010324381
2025-03-10 16:34:53,410 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.097814837219072
2025-03-10 16:34:53,423 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.0075684834804828
2025-03-10 16:34:53,437 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.1935550987521901
2025-03-10 16:34:53,451 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.0295015203388336
2025-03-10 16:34:53,464 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 1.0082265715727032
2025-03-10 16:34:53,473 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8802513093304005
2025-03-10 16:34:53,482 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.9962260548918526
2025-03-10 16:34:53,491 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8295458390586058
2025-03-10 16:34:53,500 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8769916517196903
2025-03-10 16:34:53,510 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.9366292393026743
2025-03-10 16:34:53,519 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.820214034333477
2025-03-10 16:34:53,528 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8279595859676749
2025-03-10 16:34:53,537 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8801226625454398
2025-03-10 16:34:53,546 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.7675211891383322
2025-03-10 16:34:53,555 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.8188801785289245
2025-03-10 16:34:53,567 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6628303535976767
2025-03-10 16:34:53,576 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.7191057115081277
2025-03-10 16:34:53,585 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.7307743205767764
2025-03-10 16:34:53,595 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6606076369094128
2025-03-10 16:34:53,604 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6447771153276005
2025-03-10 16:34:53,613 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.564741006630325
2025-03-10 16:34:53,622 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6468572891094887
2025-03-10 16:34:53,631 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6072314358818216
2025-03-10 16:34:53,640 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.618189185401568
2025-03-10 16:34:53,649 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6245743193526424
2025-03-10 16:34:53,659 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5841680151433991
2025-03-10 16:34:53,668 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6082863499172964
2025-03-10 16:34:53,677 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6502835124304751
2025-03-10 16:34:53,686 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6480817020591044
2025-03-10 16:34:53,695 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6218814679238082
2025-03-10 16:34:53,704 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5590341986544145
2025-03-10 16:34:53,714 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5752117393279623
2025-03-10 16:34:53,723 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5206206622209256
2025-03-10 16:34:53,732 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5802571419780724
2025-03-10 16:34:53,741 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5519114638880002
2025-03-10 16:34:53,750 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6313738330727522
2025-03-10 16:34:53,760 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5497654779233482
2025-03-10 16:34:53,769 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5147619567876287
2025-03-10 16:34:53,778 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.46961130055652317
2025-03-10 16:34:53,787 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5508738280557617
2025-03-10 16:34:53,797 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.6008983671092094
2025-03-10 16:34:53,806 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5485408890028094
2025-03-10 16:34:53,815 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.553515782834687
2025-03-10 16:34:53,824 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5384096763339439
2025-03-10 16:34:53,833 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4781290000913446
2025-03-10 16:34:53,843 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5656162815861007
2025-03-10 16:34:53,852 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5147990861355852
2025-03-10 16:34:53,862 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5492023544099585
2025-03-10 16:34:53,871 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5044802670022468
2025-03-10 16:34:53,881 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5083850054043244
2025-03-10 16:34:53,890 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5202798701244629
2025-03-10 16:34:53,900 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.49526026072445145
2025-03-10 16:34:53,909 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4979952190246042
2025-03-10 16:34:53,918 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4472832353098033
2025-03-10 16:34:53,927 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5612983286834475
2025-03-10 16:34:53,936 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4852809939553045
2025-03-10 16:34:53,946 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43479618677239523
2025-03-10 16:34:53,955 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4545322449047659
2025-03-10 16:34:53,964 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.48940984669820786
2025-03-10 16:34:53,973 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4902594939493149
2025-03-10 16:34:53,982 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.46177454076290936
2025-03-10 16:34:53,992 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38494809354448095
2025-03-10 16:34:54,001 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4738777740571431
2025-03-10 16:34:54,010 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4849482687876759
2025-03-10 16:34:54,020 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4661409255946991
2025-03-10 16:34:54,029 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43983320018262495
2025-03-10 16:34:54,039 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.44695102480711396
2025-03-10 16:34:54,048 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.47655526185830765
2025-03-10 16:34:54,057 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4487772028607334
2025-03-10 16:34:54,066 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.45665363656207036
2025-03-10 16:34:54,075 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43848748771203294
2025-03-10 16:34:54,084 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4344782435478214
2025-03-10 16:34:54,093 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4488337041158436
2025-03-10 16:34:54,103 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4193266207116844
2025-03-10 16:34:54,112 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.5070987080603612
2025-03-10 16:34:54,121 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.42425298993024957
2025-03-10 16:34:54,130 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.402693548242337
2025-03-10 16:34:54,140 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4326020652844263
2025-03-10 16:34:54,149 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40835522316124545
2025-03-10 16:34:54,158 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41589720704985017
2025-03-10 16:34:54,168 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.46769455346110284
2025-03-10 16:34:54,177 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40700276716526834
2025-03-10 16:34:54,186 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3573254923325369
2025-03-10 16:34:54,195 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36779852153291503
2025-03-10 16:34:54,205 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.481457052225259
2025-03-10 16:34:54,214 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4736074416732613
2025-03-10 16:34:54,223 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4358878002661183
2025-03-10 16:34:54,233 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41068238754760455
2025-03-10 16:34:54,242 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4132858616402941
2025-03-10 16:34:54,251 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4528994193523264
2025-03-10 16:34:54,260 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.45497705540404954
2025-03-10 16:34:54,270 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38260146905489134
2025-03-10 16:34:54,279 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.380069703379184
2025-03-10 16:34:54,288 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.46236574804536534
2025-03-10 16:34:54,298 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:54,308 - INFO - FONN2 Epoch 100:
2025-03-10 16:34:54,308 - INFO - Train MSE: 0.2215, Test MSE: 0.2341
2025-03-10 16:34:54,308 - INFO - Train R²: 0.7785, Test R²: 0.7227
2025-03-10 16:34:54,309 - INFO - Train MAE: 0.3359, Test MAE: 0.3084
2025-03-10 16:34:54,309 - INFO - Overfit ratio (train R² / test R²): 1.0773
Epoch 0, Loss: 0.3867304506915937
2025-03-10 16:34:54,318 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40613769112084513
2025-03-10 16:34:54,327 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4252431257614718
2025-03-10 16:34:54,336 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4109847568214481
2025-03-10 16:34:54,346 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43527689568451555
2025-03-10 16:34:54,355 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3173186335298461
2025-03-10 16:34:54,365 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39613976347391044
2025-03-10 16:34:54,374 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4129840490143268
2025-03-10 16:34:54,383 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4146513378451626
2025-03-10 16:34:54,393 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37226117611666953
2025-03-10 16:34:54,402 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4297931490826099
2025-03-10 16:34:54,411 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3857000646411544
2025-03-10 16:34:54,421 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43918848488333084
2025-03-10 16:34:54,430 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38368277487024965
2025-03-10 16:34:54,439 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4482215747285691
2025-03-10 16:34:54,448 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.48332833154876886
2025-03-10 16:34:54,457 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40966967365078066
2025-03-10 16:34:54,466 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37916172232072004
2025-03-10 16:34:54,476 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4212359448869892
2025-03-10 16:34:54,485 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3831964273701926
2025-03-10 16:34:54,494 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3700701444376494
2025-03-10 16:34:54,503 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38825669564380244
2025-03-10 16:34:54,513 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3904586964398264
2025-03-10 16:34:54,522 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.42934004076081267
2025-03-10 16:34:54,531 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3802563086530443
2025-03-10 16:34:54,540 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4521550575076784
2025-03-10 16:34:54,549 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.45200385612652627
2025-03-10 16:34:54,559 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3699824080268591
2025-03-10 16:34:54,567 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4408824864734495
2025-03-10 16:34:54,577 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.412406511695451
2025-03-10 16:34:54,586 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34269882172165694
2025-03-10 16:34:54,596 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38899457271761806
2025-03-10 16:34:54,605 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39232326481560514
2025-03-10 16:34:54,614 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38317897816892094
2025-03-10 16:34:54,623 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3938750569253666
2025-03-10 16:34:54,632 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.435587443919294
2025-03-10 16:34:54,641 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4044917561400578
2025-03-10 16:34:54,651 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4539266570312675
2025-03-10 16:34:54,660 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33366707533064
2025-03-10 16:34:54,669 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4324568505125273
2025-03-10 16:34:54,679 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41146788212323443
2025-03-10 16:34:54,688 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37189797794526697
2025-03-10 16:34:54,697 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4403534333328744
2025-03-10 16:34:54,708 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3962533641744618
2025-03-10 16:34:54,717 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.393181992747892
2025-03-10 16:34:54,726 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40185120508031147
2025-03-10 16:34:54,735 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39512860176547226
2025-03-10 16:34:54,744 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3667115825546909
2025-03-10 16:34:54,754 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3642648634367824
2025-03-10 16:34:54,763 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36469763846483366
2025-03-10 16:34:54,772 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3620569953117705
2025-03-10 16:34:54,781 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4378007759105811
2025-03-10 16:34:54,790 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4044474258529188
2025-03-10 16:34:54,799 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3604904953676835
2025-03-10 16:34:54,809 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4012273777703922
2025-03-10 16:34:54,818 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35170644690917696
2025-03-10 16:34:54,828 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38890077864607814
2025-03-10 16:34:54,837 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36381577439660595
2025-03-10 16:34:54,846 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38009444742328996
2025-03-10 16:34:54,857 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3809632364702207
2025-03-10 16:34:54,866 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39306095156310766
2025-03-10 16:34:54,875 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3864229833223684
2025-03-10 16:34:54,884 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3678963675225496
2025-03-10 16:34:54,893 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43360708235381495
2025-03-10 16:34:54,903 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3843321587714298
2025-03-10 16:34:54,912 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35182870251955656
2025-03-10 16:34:54,921 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37176061437675023
2025-03-10 16:34:54,931 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4325848225797405
2025-03-10 16:34:54,940 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36996468710147185
2025-03-10 16:34:54,949 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36575215040856973
2025-03-10 16:34:54,958 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36708866797458195
2025-03-10 16:34:54,967 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4453726360912846
2025-03-10 16:34:54,977 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3929008875590917
2025-03-10 16:34:54,986 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3313512076997592
2025-03-10 16:34:54,995 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.42903785646779374
2025-03-10 16:34:55,004 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40165226362898204
2025-03-10 16:34:55,013 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32914706673120636
2025-03-10 16:34:55,022 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39270301310647676
2025-03-10 16:34:55,031 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3774166829980177
2025-03-10 16:34:55,041 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3731396995277255
2025-03-10 16:34:55,050 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3226547574550883
2025-03-10 16:34:55,059 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4349548791458776
2025-03-10 16:34:55,068 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38476115257204874
2025-03-10 16:34:55,077 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3588319684906406
2025-03-10 16:34:55,087 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33520134147422276
2025-03-10 16:34:55,096 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30524645221082464
2025-03-10 16:34:55,105 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.371622464633226
2025-03-10 16:34:55,114 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40613002249679386
2025-03-10 16:34:55,124 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3300080967249815
2025-03-10 16:34:55,133 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35914966897047984
2025-03-10 16:34:55,142 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34584352561989706
2025-03-10 16:34:55,151 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4422133018886574
2025-03-10 16:34:55,161 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36630641938777775
2025-03-10 16:34:55,170 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33920808902051774
2025-03-10 16:34:55,179 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31860449512886463
2025-03-10 16:34:55,188 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40405541788132365
2025-03-10 16:34:55,197 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35686288727205157
2025-03-10 16:34:55,206 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38875605802389224
2025-03-10 16:34:55,215 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30088236351818787
2025-03-10 16:34:55,224 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3802467378007648
2025-03-10 16:34:55,233 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:55,244 - INFO - FONN2 Epoch 200:
2025-03-10 16:34:55,244 - INFO - Train MSE: 0.2044, Test MSE: 0.2201
2025-03-10 16:34:55,244 - INFO - Train R²: 0.7956, Test R²: 0.7393
2025-03-10 16:34:55,244 - INFO - Train MAE: 0.3265, Test MAE: 0.3001
2025-03-10 16:34:55,244 - INFO - Overfit ratio (train R² / test R²): 1.0762
Epoch 0, Loss: 0.36208439480808574
2025-03-10 16:34:55,254 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3666244024847382
2025-03-10 16:34:55,263 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35369489914268987
2025-03-10 16:34:55,272 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36515743787366717
2025-03-10 16:34:55,282 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40983601548603854
2025-03-10 16:34:55,291 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41993318929191437
2025-03-10 16:34:55,300 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34128141750831364
2025-03-10 16:34:55,309 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3370116991205903
2025-03-10 16:34:55,318 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41010967881179355
2025-03-10 16:34:55,327 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35447388857883433
2025-03-10 16:34:55,337 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3337433058701686
2025-03-10 16:34:55,346 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3301543789858615
2025-03-10 16:34:55,355 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3823340162667067
2025-03-10 16:34:55,365 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4093056347747516
2025-03-10 16:34:55,374 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33716665080512254
2025-03-10 16:34:55,383 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37142851125592025
2025-03-10 16:34:55,392 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.43056002500034124
2025-03-10 16:34:55,401 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37403072874342147
2025-03-10 16:34:55,411 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34972382996042345
2025-03-10 16:34:55,420 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3562104039015298
2025-03-10 16:34:55,429 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3985361812118207
2025-03-10 16:34:55,438 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3517026886030025
2025-03-10 16:34:55,448 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3519641003563421
2025-03-10 16:34:55,458 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38906822227779275
2025-03-10 16:34:55,468 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.46144137410924907
2025-03-10 16:34:55,477 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3585946805969185
2025-03-10 16:34:55,486 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36026598046019453
2025-03-10 16:34:55,495 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37911814059488885
2025-03-10 16:34:55,505 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36254345087700146
2025-03-10 16:34:55,514 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38064301749617224
2025-03-10 16:34:55,523 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40310740928238353
2025-03-10 16:34:55,533 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.375870883223815
2025-03-10 16:34:55,542 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3657510567816732
2025-03-10 16:34:55,551 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4149395500149674
2025-03-10 16:34:55,561 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37124662611266135
2025-03-10 16:34:55,570 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31841295409317005
2025-03-10 16:34:55,580 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3806020040197409
2025-03-10 16:34:55,589 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3616385547914193
2025-03-10 16:34:55,598 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3802424588073022
2025-03-10 16:34:55,608 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36792714635546653
2025-03-10 16:34:55,617 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3886244015333265
2025-03-10 16:34:55,627 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32030796652857846
2025-03-10 16:34:55,636 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40733818235801356
2025-03-10 16:34:55,646 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3933052271209418
2025-03-10 16:34:55,656 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3093263452509287
2025-03-10 16:34:55,665 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3360370705050086
2025-03-10 16:34:55,674 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4038310036712174
2025-03-10 16:34:55,683 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3655041451558008
2025-03-10 16:34:55,693 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38395073701180066
2025-03-10 16:34:55,702 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4352569234788888
2025-03-10 16:34:55,713 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.381072946331718
2025-03-10 16:34:55,723 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4184638623047361
2025-03-10 16:34:55,733 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34269553763904453
2025-03-10 16:34:55,742 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3579791340979722
2025-03-10 16:34:55,752 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38856330553476176
2025-03-10 16:34:55,761 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39467653108492723
2025-03-10 16:34:55,770 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3167097595901941
2025-03-10 16:34:55,780 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36304091057612864
2025-03-10 16:34:55,790 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3752558324144095
2025-03-10 16:34:55,802 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35603358347613606
2025-03-10 16:34:55,815 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31902020635893724
2025-03-10 16:34:55,827 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3416564764924675
2025-03-10 16:34:55,839 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3952052846095447
2025-03-10 16:34:55,851 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3502053352450694
2025-03-10 16:34:55,863 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3800428932218159
2025-03-10 16:34:55,875 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3419363957842871
2025-03-10 16:34:55,887 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3207037936294842
2025-03-10 16:34:55,900 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3717120089561676
2025-03-10 16:34:55,912 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34346245533766273
2025-03-10 16:34:55,924 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38840339319584294
2025-03-10 16:34:55,936 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38079877125395545
2025-03-10 16:34:55,948 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34319935863598655
2025-03-10 16:34:55,960 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34897464107949316
2025-03-10 16:34:55,972 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3330609756248119
2025-03-10 16:34:55,985 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.402883567350569
2025-03-10 16:34:55,997 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.365027885169109
2025-03-10 16:34:56,009 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35577412888526205
2025-03-10 16:34:56,022 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3442981033376912
2025-03-10 16:34:56,034 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33193160888907125
2025-03-10 16:34:56,046 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3523911748661246
2025-03-10 16:34:56,058 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3597352082692413
2025-03-10 16:34:56,070 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38186404829857346
2025-03-10 16:34:56,082 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3618960239103163
2025-03-10 16:34:56,095 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3413382543747343
2025-03-10 16:34:56,107 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35178575254967764
2025-03-10 16:34:56,119 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35105915758585354
2025-03-10 16:34:56,131 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30233585874151464
2025-03-10 16:34:56,144 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36195862541948787
2025-03-10 16:34:56,156 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3739273300911914
2025-03-10 16:34:56,168 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32679236742163353
2025-03-10 16:34:56,180 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3389635075548865
2025-03-10 16:34:56,193 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37340849167693185
2025-03-10 16:34:56,205 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3958013637271191
2025-03-10 16:34:56,217 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3789102682809516
2025-03-10 16:34:56,229 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34126326606001156
2025-03-10 16:34:56,241 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36871991304701945
2025-03-10 16:34:56,254 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3438240546033174
2025-03-10 16:34:56,266 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3982550976551943
2025-03-10 16:34:56,278 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39287235096992584
2025-03-10 16:34:56,290 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35958105876024643
2025-03-10 16:34:56,302 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:56,316 - INFO - FONN2 Epoch 300:
2025-03-10 16:34:56,316 - INFO - Train MSE: 0.2079, Test MSE: 0.2239
2025-03-10 16:34:56,316 - INFO - Train R²: 0.7921, Test R²: 0.7347
2025-03-10 16:34:56,316 - INFO - Train MAE: 0.3290, Test MAE: 0.3022
2025-03-10 16:34:56,317 - INFO - Overfit ratio (train R² / test R²): 1.0781
Epoch 0, Loss: 0.3348920249482196
2025-03-10 16:34:56,329 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3476949126061675
2025-03-10 16:34:56,341 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4044845919932756
2025-03-10 16:34:56,353 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40646625181985313
2025-03-10 16:34:56,366 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29914389143945597
2025-03-10 16:34:56,378 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3803029562321762
2025-03-10 16:34:56,390 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.347287695741142
2025-03-10 16:34:56,402 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3412015902378306
2025-03-10 16:34:56,414 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3953130190756393
2025-03-10 16:34:56,426 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3542313502865116
2025-03-10 16:34:56,438 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.356897557823296
2025-03-10 16:34:56,451 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30499837117612993
2025-03-10 16:34:56,463 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3391816709687659
2025-03-10 16:34:56,475 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29569829137947307
2025-03-10 16:34:56,487 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31385225545219436
2025-03-10 16:34:56,499 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3497870496126605
2025-03-10 16:34:56,511 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3706066927853419
2025-03-10 16:34:56,523 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3242632804016216
2025-03-10 16:34:56,534 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35303038242966045
2025-03-10 16:34:56,543 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3451449662002116
2025-03-10 16:34:56,552 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3399508778073297
2025-03-10 16:34:56,561 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35502163821329025
2025-03-10 16:34:56,570 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.360017274611616
2025-03-10 16:34:56,578 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3051427244434571
2025-03-10 16:34:56,587 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3889644076012029
2025-03-10 16:34:56,596 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32294843097305603
2025-03-10 16:34:56,605 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3795113099515011
2025-03-10 16:34:56,614 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34629221644683483
2025-03-10 16:34:56,623 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3207856075153712
2025-03-10 16:34:56,632 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34496649033300747
2025-03-10 16:34:56,641 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3711499656472138
2025-03-10 16:34:56,649 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4552791211568271
2025-03-10 16:34:56,659 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41126991372657
2025-03-10 16:34:56,668 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.370584592561384
2025-03-10 16:34:56,677 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3468865307921438
2025-03-10 16:34:56,686 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3473011022597013
2025-03-10 16:34:56,695 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3928667804996259
2025-03-10 16:34:56,704 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.328848738809553
2025-03-10 16:34:56,713 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38108637105829946
2025-03-10 16:34:56,722 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35323428772960824
2025-03-10 16:34:56,731 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3089597602796661
2025-03-10 16:34:56,740 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3191235736272778
2025-03-10 16:34:56,749 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.40555321841648834
2025-03-10 16:34:56,758 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4041404316061053
2025-03-10 16:34:56,767 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.328495477965221
2025-03-10 16:34:56,776 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30990854998520134
2025-03-10 16:34:56,785 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35580524035802996
2025-03-10 16:34:56,794 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3998824449380001
2025-03-10 16:34:56,803 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3655434239399337
2025-03-10 16:34:56,812 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3416708265696769
2025-03-10 16:34:56,821 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35142012474877865
2025-03-10 16:34:56,830 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3171673923370416
2025-03-10 16:34:56,839 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3074074461226419
2025-03-10 16:34:56,847 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35983399433343527
2025-03-10 16:34:56,856 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3955280107641557
2025-03-10 16:34:56,865 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34931800662157425
2025-03-10 16:34:56,874 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3572438072540977
2025-03-10 16:34:56,883 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33292286193296283
2025-03-10 16:34:56,892 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37659141297516935
2025-03-10 16:34:56,901 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29949355418143775
2025-03-10 16:34:56,912 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36466322345089897
2025-03-10 16:34:56,927 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35614888393643773
2025-03-10 16:34:56,942 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3290682215948529
2025-03-10 16:34:56,956 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39278208390679265
2025-03-10 16:34:56,967 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3542860120307046
2025-03-10 16:34:56,976 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31952261394114434
2025-03-10 16:34:56,985 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38451382913021726
2025-03-10 16:34:56,994 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3351153913777698
2025-03-10 16:34:57,005 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3363344053246536
2025-03-10 16:34:57,014 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3745299851471271
2025-03-10 16:34:57,023 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3299918800540533
2025-03-10 16:34:57,035 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37841104186072394
2025-03-10 16:34:57,044 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3627625552737867
2025-03-10 16:34:57,056 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37928398102391137
2025-03-10 16:34:57,068 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32504242573756065
2025-03-10 16:34:57,080 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.320342400476394
2025-03-10 16:34:57,089 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3676077116003963
2025-03-10 16:34:57,098 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3745170949226311
2025-03-10 16:34:57,107 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3156789999021848
2025-03-10 16:34:57,115 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3887712617558256
2025-03-10 16:34:57,125 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3287215780601463
2025-03-10 16:34:57,134 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3400822004022622
2025-03-10 16:34:57,143 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3406747259881516
2025-03-10 16:34:57,152 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3430811961280005
2025-03-10 16:34:57,162 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3440896690703771
2025-03-10 16:34:57,171 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3148770020841981
2025-03-10 16:34:57,180 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32881857817391386
2025-03-10 16:34:57,189 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33109720425527395
2025-03-10 16:34:57,199 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39238200877854534
2025-03-10 16:34:57,208 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34167581357948157
2025-03-10 16:34:57,217 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33496286302718187
2025-03-10 16:34:57,226 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3886047710167091
2025-03-10 16:34:57,235 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3315068923797768
2025-03-10 16:34:57,245 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3401207154722406
2025-03-10 16:34:57,254 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.333874015685877
2025-03-10 16:34:57,263 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3047592043638882
2025-03-10 16:34:57,272 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3987912103531706
2025-03-10 16:34:57,281 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31756078365184337
2025-03-10 16:34:57,291 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29864029249833735
2025-03-10 16:34:57,300 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37492234696881416
2025-03-10 16:34:57,309 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:57,320 - INFO - FONN2 Epoch 400:
2025-03-10 16:34:57,320 - INFO - Train MSE: 0.1864, Test MSE: 0.2048
2025-03-10 16:34:57,320 - INFO - Train R²: 0.8136, Test R²: 0.7574
2025-03-10 16:34:57,320 - INFO - Train MAE: 0.3160, Test MAE: 0.2938
2025-03-10 16:34:57,320 - INFO - Overfit ratio (train R² / test R²): 1.0742
Epoch 0, Loss: 0.34640314994127863
2025-03-10 16:34:57,329 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33567221529669455
2025-03-10 16:34:57,338 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38116712917895934
2025-03-10 16:34:57,347 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38797652407331884
2025-03-10 16:34:57,356 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3397974143151841
2025-03-10 16:34:57,365 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32218729638379495
2025-03-10 16:34:57,374 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37956765648154406
2025-03-10 16:34:57,383 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3353803311725186
2025-03-10 16:34:57,392 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41312888174403534
2025-03-10 16:34:57,401 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34741696795568877
2025-03-10 16:34:57,410 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33264132345957076
2025-03-10 16:34:57,419 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3270690907292043
2025-03-10 16:34:57,428 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33367332867971494
2025-03-10 16:34:57,437 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31626925783693344
2025-03-10 16:34:57,446 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33407358430026207
2025-03-10 16:34:57,455 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3395209928991511
2025-03-10 16:34:57,464 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3019924193977888
2025-03-10 16:34:57,473 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3766936731715917
2025-03-10 16:34:57,482 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31189902978537715
2025-03-10 16:34:57,491 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3608786493309405
2025-03-10 16:34:57,500 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3828855544522359
2025-03-10 16:34:57,509 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3445411101494797
2025-03-10 16:34:57,518 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3642401131653509
2025-03-10 16:34:57,527 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3238432483510128
2025-03-10 16:34:57,537 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35181832202007307
2025-03-10 16:34:57,546 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39673336883029064
2025-03-10 16:34:57,555 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3386505925096731
2025-03-10 16:34:57,564 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3444300211747355
2025-03-10 16:34:57,574 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33819267032603567
2025-03-10 16:34:57,583 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3689637094539742
2025-03-10 16:34:57,592 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3232271459655139
2025-03-10 16:34:57,601 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35483341718510475
2025-03-10 16:34:57,611 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.365574931476235
2025-03-10 16:34:57,620 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31883962551553513
2025-03-10 16:34:57,629 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3657039992045901
2025-03-10 16:34:57,638 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3741879774029253
2025-03-10 16:34:57,647 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3193669151453576
2025-03-10 16:34:57,657 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.330820189593558
2025-03-10 16:34:57,666 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4081036227845681
2025-03-10 16:34:57,675 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32516404505867663
2025-03-10 16:34:57,684 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3350256985463404
2025-03-10 16:34:57,693 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3343907182533309
2025-03-10 16:34:57,702 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36626486401607683
2025-03-10 16:34:57,712 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35199177731434966
2025-03-10 16:34:57,721 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3604092118210083
2025-03-10 16:34:57,730 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3471175443064898
2025-03-10 16:34:57,740 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30426427019908125
2025-03-10 16:34:57,748 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37346763768930535
2025-03-10 16:34:57,757 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3623680330634984
2025-03-10 16:34:57,767 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3414238920470504
2025-03-10 16:34:57,776 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4343786249027665
2025-03-10 16:34:57,787 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32040764487814555
2025-03-10 16:34:57,796 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3114560339259456
2025-03-10 16:34:57,805 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36575804503756043
2025-03-10 16:34:57,815 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29683823330692705
2025-03-10 16:34:57,824 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33458221503483754
2025-03-10 16:34:57,833 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2857989280134593
2025-03-10 16:34:57,843 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3114869490949112
2025-03-10 16:34:57,852 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3325931948600315
2025-03-10 16:34:57,861 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29699541031382615
2025-03-10 16:34:57,871 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2774983115878395
2025-03-10 16:34:57,880 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39308698455487734
2025-03-10 16:34:57,889 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35881255307387555
2025-03-10 16:34:57,898 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3555248413353108
2025-03-10 16:34:57,907 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3598092052987099
2025-03-10 16:34:57,917 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35685055498312546
2025-03-10 16:34:57,926 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31355947364306846
2025-03-10 16:34:57,935 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3628295974461034
2025-03-10 16:34:57,945 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33998881791202357
2025-03-10 16:34:57,954 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3295176606895906
2025-03-10 16:34:57,963 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3015824578349372
2025-03-10 16:34:57,972 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3667163664717385
2025-03-10 16:34:57,981 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3599352975156467
2025-03-10 16:34:57,991 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3566787851601966
2025-03-10 16:34:58,000 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26572090793853814
2025-03-10 16:34:58,012 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3336653496411619
2025-03-10 16:34:58,021 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31994570625930463
2025-03-10 16:34:58,031 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2959128101144259
2025-03-10 16:34:58,040 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3804323239406576
2025-03-10 16:34:58,051 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3557279136170892
2025-03-10 16:34:58,063 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3478482122181729
2025-03-10 16:34:58,072 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3399597028795321
2025-03-10 16:34:58,081 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3369963623453243
2025-03-10 16:34:58,090 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31714727876516924
2025-03-10 16:34:58,101 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3669948937509798
2025-03-10 16:34:58,110 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35331111114358427
2025-03-10 16:34:58,120 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3279372446743922
2025-03-10 16:34:58,129 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35883167208267785
2025-03-10 16:34:58,138 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33273131272737755
2025-03-10 16:34:58,148 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37612816911358915
2025-03-10 16:34:58,157 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3474668220948829
2025-03-10 16:34:58,167 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32667002186748045
2025-03-10 16:34:58,176 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35998390812894815
2025-03-10 16:34:58,185 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3036154030803625
2025-03-10 16:34:58,194 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3662310707037532
2025-03-10 16:34:58,204 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33399781503219017
2025-03-10 16:34:58,213 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33233133899267264
2025-03-10 16:34:58,222 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34874725331707424
2025-03-10 16:34:58,231 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33141855493340827
2025-03-10 16:34:58,240 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3295408031463576
2025-03-10 16:34:58,249 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:58,260 - INFO - FONN2 Epoch 500:
2025-03-10 16:34:58,260 - INFO - Train MSE: 0.1872, Test MSE: 0.2040
2025-03-10 16:34:58,261 - INFO - Train R²: 0.8128, Test R²: 0.7584
2025-03-10 16:34:58,261 - INFO - Train MAE: 0.3146, Test MAE: 0.2924
2025-03-10 16:34:58,261 - INFO - Overfit ratio (train R² / test R²): 1.0718
Epoch 0, Loss: 0.35531849809177474
2025-03-10 16:34:58,270 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3262324527232368
2025-03-10 16:34:58,280 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3259235830819081
2025-03-10 16:34:58,289 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36354523983695697
2025-03-10 16:34:58,298 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30298148224687194
2025-03-10 16:34:58,307 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3496746704170756
2025-03-10 16:34:58,317 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2819051408230582
2025-03-10 16:34:58,326 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3468488112047497
2025-03-10 16:34:58,335 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3875478043171404
2025-03-10 16:34:58,344 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29920502869695215
2025-03-10 16:34:58,354 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3321684999825592
2025-03-10 16:34:58,363 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3710611864790539
2025-03-10 16:34:58,372 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3585218547770139
2025-03-10 16:34:58,381 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3502774977833344
2025-03-10 16:34:58,391 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32277768633913045
2025-03-10 16:34:58,400 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30157440150991804
2025-03-10 16:34:58,410 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30087084266628233
2025-03-10 16:34:58,419 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3606083698128007
2025-03-10 16:34:58,428 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32546366225453116
2025-03-10 16:34:58,437 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3350637225066098
2025-03-10 16:34:58,446 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3652957678377663
2025-03-10 16:34:58,455 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3317415736054649
2025-03-10 16:34:58,464 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3345701654373068
2025-03-10 16:34:58,473 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.39629113404298993
2025-03-10 16:34:58,482 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31199107570202816
2025-03-10 16:34:58,491 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36483871911722676
2025-03-10 16:34:58,500 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35678334686447166
2025-03-10 16:34:58,509 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38298958951534806
2025-03-10 16:34:58,518 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34816746325233117
2025-03-10 16:34:58,527 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3348236448736589
2025-03-10 16:34:58,536 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3359648555725935
2025-03-10 16:34:58,546 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3182990879685871
2025-03-10 16:34:58,555 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37809369999937714
2025-03-10 16:34:58,565 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32596609765709494
2025-03-10 16:34:58,574 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3639214029018074
2025-03-10 16:34:58,583 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3335750382446894
2025-03-10 16:34:58,592 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3377345386277745
2025-03-10 16:34:58,601 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3876469382356347
2025-03-10 16:34:58,611 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3098383467669519
2025-03-10 16:34:58,620 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35048564488241407
2025-03-10 16:34:58,629 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31059415972578824
2025-03-10 16:34:58,638 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30933879708131073
2025-03-10 16:34:58,647 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3446894571161954
2025-03-10 16:34:58,657 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32403724443033505
2025-03-10 16:34:58,667 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36056993424081046
2025-03-10 16:34:58,677 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.353478773660507
2025-03-10 16:34:58,687 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37483259568530547
2025-03-10 16:34:58,697 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35187041942710245
2025-03-10 16:34:58,706 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34008628494113136
2025-03-10 16:34:58,716 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3744448622018306
2025-03-10 16:34:58,725 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35374154439689076
2025-03-10 16:34:58,734 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3645956886318949
2025-03-10 16:34:58,743 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.289065452724631
2025-03-10 16:34:58,752 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33938406718420305
2025-03-10 16:34:58,761 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32228682098011713
2025-03-10 16:34:58,770 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3381930297760091
2025-03-10 16:34:58,779 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3630245513772144
2025-03-10 16:34:58,788 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3446995723804193
2025-03-10 16:34:58,798 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35662991890196444
2025-03-10 16:34:58,807 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34629904457029487
2025-03-10 16:34:58,816 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.25606145168262706
2025-03-10 16:34:58,826 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3082725349654866
2025-03-10 16:34:58,835 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2801493245190645
2025-03-10 16:34:58,845 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31976076049175384
2025-03-10 16:34:58,854 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30322636356598404
2025-03-10 16:34:58,863 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34171360462290445
2025-03-10 16:34:58,872 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3605752727642845
2025-03-10 16:34:58,882 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3662782204376221
2025-03-10 16:34:58,891 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35918894623769543
2025-03-10 16:34:58,900 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.347842104163419
2025-03-10 16:34:58,909 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2761233291413149
2025-03-10 16:34:58,918 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31593267321845137
2025-03-10 16:34:58,927 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3481892326046612
2025-03-10 16:34:58,937 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3374905664788791
2025-03-10 16:34:58,946 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33849957343928855
2025-03-10 16:34:58,955 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32280882995820553
2025-03-10 16:34:58,964 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3346647089829955
2025-03-10 16:34:58,973 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3289225399964605
2025-03-10 16:34:58,983 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3645576684719898
2025-03-10 16:34:58,992 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37038113198688327
2025-03-10 16:34:59,002 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3175053243270894
2025-03-10 16:34:59,011 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33809129504739965
2025-03-10 16:34:59,020 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3031486280538449
2025-03-10 16:34:59,029 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3574530689495922
2025-03-10 16:34:59,038 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3299688260015121
2025-03-10 16:34:59,047 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31569563730131245
2025-03-10 16:34:59,057 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.301291733645421
2025-03-10 16:34:59,066 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35428595579306194
2025-03-10 16:34:59,075 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3219033301985282
2025-03-10 16:34:59,085 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31990799484103893
2025-03-10 16:34:59,094 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34215332532215903
2025-03-10 16:34:59,103 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3003753349582996
2025-03-10 16:34:59,112 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32995713290297496
2025-03-10 16:34:59,121 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3008101880176753
2025-03-10 16:34:59,131 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3356693682030391
2025-03-10 16:34:59,140 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31342696056402897
2025-03-10 16:34:59,150 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31639906762359576
2025-03-10 16:34:59,165 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3009703090111088
2025-03-10 16:34:59,180 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34288917089673576
2025-03-10 16:34:59,195 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3211935388673
2025-03-10 16:34:59,210 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:34:59,222 - INFO - FONN2 Epoch 600:
2025-03-10 16:34:59,222 - INFO - Train MSE: 0.1755, Test MSE: 0.1929
2025-03-10 16:34:59,222 - INFO - Train R²: 0.8245, Test R²: 0.7715
2025-03-10 16:34:59,222 - INFO - Train MAE: 0.3064, Test MAE: 0.2856
2025-03-10 16:34:59,222 - INFO - Overfit ratio (train R² / test R²): 1.0687
Epoch 0, Loss: 0.2951046477807186
2025-03-10 16:34:59,232 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3290439157477016
2025-03-10 16:34:59,242 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31791114977517054
2025-03-10 16:34:59,251 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.334356229225731
2025-03-10 16:34:59,261 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3495224759609017
2025-03-10 16:34:59,271 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2676831704920294
2025-03-10 16:34:59,280 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32782917222235064
2025-03-10 16:34:59,290 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3489943962418734
2025-03-10 16:34:59,300 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3660970959985542
2025-03-10 16:34:59,310 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28431144646509793
2025-03-10 16:34:59,320 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3667153830610308
2025-03-10 16:34:59,330 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3009727125879715
2025-03-10 16:34:59,340 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31627148622388357
2025-03-10 16:34:59,349 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3428435457026429
2025-03-10 16:34:59,359 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3611719611904965
2025-03-10 16:34:59,368 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28823398896997793
2025-03-10 16:34:59,378 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3143450656678635
2025-03-10 16:34:59,387 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30234659510182615
2025-03-10 16:34:59,396 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3392409558599033
2025-03-10 16:34:59,406 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29843435212503494
2025-03-10 16:34:59,416 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3300955663560122
2025-03-10 16:34:59,426 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2683408945662149
2025-03-10 16:34:59,435 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36089657460341823
2025-03-10 16:34:59,445 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35523330706883677
2025-03-10 16:34:59,454 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35234346460623667
2025-03-10 16:34:59,463 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2851557656112986
2025-03-10 16:34:59,473 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3536775709446465
2025-03-10 16:34:59,482 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33419445583744267
2025-03-10 16:34:59,492 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3256071956626322
2025-03-10 16:34:59,502 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3021847109533442
2025-03-10 16:34:59,511 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3236840275848089
2025-03-10 16:34:59,521 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33644176782810575
2025-03-10 16:34:59,530 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3625582049647987
2025-03-10 16:34:59,539 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30236820828386474
2025-03-10 16:34:59,548 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3819505382080715
2025-03-10 16:34:59,557 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31027901192600843
2025-03-10 16:34:59,567 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32262886023839055
2025-03-10 16:34:59,576 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33016119685456585
2025-03-10 16:34:59,586 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3494840426186172
2025-03-10 16:34:59,595 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.42549864337135773
2025-03-10 16:34:59,604 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37174226953327094
2025-03-10 16:34:59,614 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3391703246662937
2025-03-10 16:34:59,623 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31858278785063554
2025-03-10 16:34:59,632 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3391684568968618
2025-03-10 16:34:59,641 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2875806680250674
2025-03-10 16:34:59,651 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29000276037785355
2025-03-10 16:34:59,660 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.315641570868558
2025-03-10 16:34:59,669 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34487434232730646
2025-03-10 16:34:59,678 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33821552855735004
2025-03-10 16:34:59,688 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3273105017866671
2025-03-10 16:34:59,697 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3859737159916295
2025-03-10 16:34:59,706 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30333045440621886
2025-03-10 16:34:59,715 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3202831559644418
2025-03-10 16:34:59,724 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3701336779756017
2025-03-10 16:34:59,733 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2821975351538763
2025-03-10 16:34:59,743 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32400446300133545
2025-03-10 16:34:59,752 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3183050999404912
2025-03-10 16:34:59,762 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2866777883969321
2025-03-10 16:34:59,771 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33052761943163983
2025-03-10 16:34:59,780 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36921096040234613
2025-03-10 16:34:59,789 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3540929652165297
2025-03-10 16:34:59,798 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35124054383840303
2025-03-10 16:34:59,807 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29870885508394196
2025-03-10 16:34:59,816 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30895548334569606
2025-03-10 16:34:59,825 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.340815384393569
2025-03-10 16:34:59,835 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31017088331152776
2025-03-10 16:34:59,844 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2699447743880697
2025-03-10 16:34:59,853 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32541662090390927
2025-03-10 16:34:59,862 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3289774404794922
2025-03-10 16:34:59,871 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3435887086616269
2025-03-10 16:34:59,881 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31906754773434787
2025-03-10 16:34:59,890 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34533656839765015
2025-03-10 16:34:59,899 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2986504410411304
2025-03-10 16:34:59,908 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3606163420994853
2025-03-10 16:34:59,917 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30006448389699064
2025-03-10 16:34:59,927 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36275416243255576
2025-03-10 16:34:59,936 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31941809344672095
2025-03-10 16:34:59,945 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28589453299114537
2025-03-10 16:34:59,954 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34644787557224566
2025-03-10 16:34:59,963 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3148717574334301
2025-03-10 16:34:59,972 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3708410296421421
2025-03-10 16:34:59,981 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3115030124975574
2025-03-10 16:34:59,991 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32562983510734356
2025-03-10 16:35:00,000 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3285518572077419
2025-03-10 16:35:00,009 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2526376456475543
2025-03-10 16:35:00,018 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29836824328001244
2025-03-10 16:35:00,028 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3787869368542107
2025-03-10 16:35:00,037 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26715163386966767
2025-03-10 16:35:00,046 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.24645494311228613
2025-03-10 16:35:00,055 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3312421588601339
2025-03-10 16:35:00,064 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2823514656030509
2025-03-10 16:35:00,073 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3581722528242692
2025-03-10 16:35:00,082 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29354337884429627
2025-03-10 16:35:00,091 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35463459260988217
2025-03-10 16:35:00,100 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31250763793556946
2025-03-10 16:35:00,109 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2736407922745099
2025-03-10 16:35:00,118 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26757889499520465
2025-03-10 16:35:00,127 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2957802791114716
2025-03-10 16:35:00,136 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3452429852769497
2025-03-10 16:35:00,145 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3360550768267943
2025-03-10 16:35:00,154 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:35:00,165 - INFO - FONN2 Epoch 700:
2025-03-10 16:35:00,165 - INFO - Train MSE: 0.1712, Test MSE: 0.1891
2025-03-10 16:35:00,165 - INFO - Train R²: 0.8288, Test R²: 0.7760
2025-03-10 16:35:00,165 - INFO - Train MAE: 0.3029, Test MAE: 0.2831
2025-03-10 16:35:00,166 - INFO - Overfit ratio (train R² / test R²): 1.0679
Epoch 0, Loss: 0.30783508051524
2025-03-10 16:35:00,176 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3548310037513998
2025-03-10 16:35:00,186 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3457500293830301
2025-03-10 16:35:00,195 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3274360897018321
2025-03-10 16:35:00,204 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35628248788922573
2025-03-10 16:35:00,213 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3557421422579392
2025-03-10 16:35:00,223 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2919796464581561
2025-03-10 16:35:00,232 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30492693639581636
2025-03-10 16:35:00,241 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32183098717183733
2025-03-10 16:35:00,251 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29338271534282817
2025-03-10 16:35:00,260 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29721575419878665
2025-03-10 16:35:00,269 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2890229699474371
2025-03-10 16:35:00,278 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2564284996689022
2025-03-10 16:35:00,287 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2981451090691932
2025-03-10 16:35:00,297 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36395547251906196
2025-03-10 16:35:00,306 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2858421441924342
2025-03-10 16:35:00,316 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2919088687238902
2025-03-10 16:35:00,325 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38361149427636365
2025-03-10 16:35:00,334 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2945636530163026
2025-03-10 16:35:00,344 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32609347331625044
2025-03-10 16:35:00,353 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.281977666135717
2025-03-10 16:35:00,363 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30706823481396883
2025-03-10 16:35:00,372 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32175664037376606
2025-03-10 16:35:00,381 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3106951618372196
2025-03-10 16:35:00,390 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34562114965476054
2025-03-10 16:35:00,400 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2908467161710175
2025-03-10 16:35:00,409 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3103126575735136
2025-03-10 16:35:00,418 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2931967592744655
2025-03-10 16:35:00,427 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35299912068301376
2025-03-10 16:35:00,437 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2724693976594135
2025-03-10 16:35:00,446 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3613498008209732
2025-03-10 16:35:00,455 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3834606294433179
2025-03-10 16:35:00,464 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.347876720197039
2025-03-10 16:35:00,474 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4081462277970465
2025-03-10 16:35:00,483 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3033965135632817
2025-03-10 16:35:00,492 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30096943803380305
2025-03-10 16:35:00,501 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27892813973899305
2025-03-10 16:35:00,511 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33802033402270726
2025-03-10 16:35:00,520 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37441188534455644
2025-03-10 16:35:00,530 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38656569572140187
2025-03-10 16:35:00,539 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30993461004952877
2025-03-10 16:35:00,548 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3219832780329294
2025-03-10 16:35:00,557 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3147950943090134
2025-03-10 16:35:00,566 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2904646634857503
2025-03-10 16:35:00,575 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.41016444627385323
2025-03-10 16:35:00,585 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30988197539618495
2025-03-10 16:35:00,594 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3191248335538412
2025-03-10 16:35:00,603 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34220084089146385
2025-03-10 16:35:00,612 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33478524924541586
2025-03-10 16:35:00,621 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31198081444301135
2025-03-10 16:35:00,631 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27468068881025837
2025-03-10 16:35:00,640 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3380425005628954
2025-03-10 16:35:00,650 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3245018802658561
2025-03-10 16:35:00,659 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32314081819078955
2025-03-10 16:35:00,668 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30862048084762694
2025-03-10 16:35:00,678 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2881516938721217
2025-03-10 16:35:00,687 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3355882681178633
2025-03-10 16:35:00,696 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.356015031460084
2025-03-10 16:35:00,705 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35774713108786327
2025-03-10 16:35:00,715 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30542901513177423
2025-03-10 16:35:00,724 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28879801289691415
2025-03-10 16:35:00,733 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3501840904770975
2025-03-10 16:35:00,743 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3343052738410048
2025-03-10 16:35:00,752 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26103147247887865
2025-03-10 16:35:00,761 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3729549483320375
2025-03-10 16:35:00,771 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3075527132819605
2025-03-10 16:35:00,780 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36287643279794
2025-03-10 16:35:00,789 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3253334938259994
2025-03-10 16:35:00,799 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32109824838367784
2025-03-10 16:35:00,808 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33021983907529806
2025-03-10 16:35:00,817 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.4340614083165435
2025-03-10 16:35:00,827 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31201144471272574
2025-03-10 16:35:00,836 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3254785098104257
2025-03-10 16:35:00,845 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3805485593395305
2025-03-10 16:35:00,854 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3282583922849407
2025-03-10 16:35:00,864 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28468105067822724
2025-03-10 16:35:00,873 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.37260874120803444
2025-03-10 16:35:00,882 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2759435468542464
2025-03-10 16:35:00,891 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28703498906464936
2025-03-10 16:35:00,901 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2883036121581942
2025-03-10 16:35:00,910 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3272343120090632
2025-03-10 16:35:00,919 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28128076353069303
2025-03-10 16:35:00,928 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31792339366140376
2025-03-10 16:35:00,938 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.242502952273933
2025-03-10 16:35:00,948 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2969429873527197
2025-03-10 16:35:00,957 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3134201254189286
2025-03-10 16:35:00,966 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3276812364807402
2025-03-10 16:35:00,976 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28769641720666916
2025-03-10 16:35:00,985 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3222593173965801
2025-03-10 16:35:00,994 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3011589315879494
2025-03-10 16:35:01,003 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28879504043942167
2025-03-10 16:35:01,013 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2641730193447297
2025-03-10 16:35:01,022 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3573189421556494
2025-03-10 16:35:01,032 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3242578716873626
2025-03-10 16:35:01,041 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2843165720024791
2025-03-10 16:35:01,050 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3226938176511877
2025-03-10 16:35:01,060 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.275913443228188
2025-03-10 16:35:01,069 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30300133982506383
2025-03-10 16:35:01,078 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33577610411171493
2025-03-10 16:35:01,088 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3399771710469635
2025-03-10 16:35:01,098 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:35:01,108 - INFO - FONN2 Epoch 800:
2025-03-10 16:35:01,108 - INFO - Train MSE: 0.1626, Test MSE: 0.1807
2025-03-10 16:35:01,108 - INFO - Train R²: 0.8374, Test R²: 0.7860
2025-03-10 16:35:01,109 - INFO - Train MAE: 0.2967, Test MAE: 0.2784
2025-03-10 16:35:01,109 - INFO - Overfit ratio (train R² / test R²): 1.0654
Epoch 0, Loss: 0.2780511632229716
2025-03-10 16:35:01,118 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30583983591662633
2025-03-10 16:35:01,128 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3507853163334838
2025-03-10 16:35:01,137 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27210143905887185
2025-03-10 16:35:01,146 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2650335081109637
2025-03-10 16:35:01,155 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3228985345945184
2025-03-10 16:35:01,165 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34449422885916325
2025-03-10 16:35:01,174 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28843478000431977
2025-03-10 16:35:01,183 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2730375590363891
2025-03-10 16:35:01,192 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3034014426122735
2025-03-10 16:35:01,202 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32585033445211203
2025-03-10 16:35:01,211 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3656881895012445
2025-03-10 16:35:01,220 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29308505771112303
2025-03-10 16:35:01,229 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30747071952781707
2025-03-10 16:35:01,239 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2833838614166671
2025-03-10 16:35:01,248 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2979801088728903
2025-03-10 16:35:01,257 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3515393502307991
2025-03-10 16:35:01,266 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38876988527561573
2025-03-10 16:35:01,275 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3004384689769983
2025-03-10 16:35:01,284 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.25019361547671365
2025-03-10 16:35:01,294 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28216408677853105
2025-03-10 16:35:01,303 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35102417688942206
2025-03-10 16:35:01,312 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31009410598279813
2025-03-10 16:35:01,321 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3033519484298791
2025-03-10 16:35:01,330 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.320714392765866
2025-03-10 16:35:01,339 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34947434453654047
2025-03-10 16:35:01,348 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3236811815454928
2025-03-10 16:35:01,357 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30412762020124745
2025-03-10 16:35:01,366 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3007374199907259
2025-03-10 16:35:01,375 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28760620918821744
2025-03-10 16:35:01,384 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32895370891618897
2025-03-10 16:35:01,393 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.38322880112997854
2025-03-10 16:35:01,402 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28837797915571306
2025-03-10 16:35:01,412 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3657897862223186
2025-03-10 16:35:01,421 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33703505155474045
2025-03-10 16:35:01,431 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2837144292860379
2025-03-10 16:35:01,440 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3191646566040889
2025-03-10 16:35:01,449 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3128380728484374
2025-03-10 16:35:01,458 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28761599447821845
2025-03-10 16:35:01,467 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.288051285489598
2025-03-10 16:35:01,476 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.295267838456437
2025-03-10 16:35:01,485 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2903626501952995
2025-03-10 16:35:01,494 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2975298622741154
2025-03-10 16:35:01,503 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31664604004526875
2025-03-10 16:35:01,512 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3740334991559512
2025-03-10 16:35:01,521 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.299814567013657
2025-03-10 16:35:01,530 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31215605004862457
2025-03-10 16:35:01,540 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26587531087493554
2025-03-10 16:35:01,549 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.314582909951731
2025-03-10 16:35:01,559 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36664721559084384
2025-03-10 16:35:01,568 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32116916166771814
2025-03-10 16:35:01,577 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33363230248869363
2025-03-10 16:35:01,588 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3413033666396008
2025-03-10 16:35:01,597 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3539850844833804
2025-03-10 16:35:01,606 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33314551082594934
2025-03-10 16:35:01,615 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32715394897760114
2025-03-10 16:35:01,625 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33289258442405023
2025-03-10 16:35:01,634 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.348685347958372
2025-03-10 16:35:01,643 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3303960785665159
2025-03-10 16:35:01,652 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3300984198430501
2025-03-10 16:35:01,662 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33189270758173406
2025-03-10 16:35:01,671 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28528902707765874
2025-03-10 16:35:01,680 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3565929644727151
2025-03-10 16:35:01,689 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3304273137594662
2025-03-10 16:35:01,699 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2518279762546368
2025-03-10 16:35:01,708 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3441521865160274
2025-03-10 16:35:01,717 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28520478961951223
2025-03-10 16:35:01,727 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2765482165778955
2025-03-10 16:35:01,736 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2913284155711148
2025-03-10 16:35:01,745 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26047420362789825
2025-03-10 16:35:01,754 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.25834478395926647
2025-03-10 16:35:01,763 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3850287466227755
2025-03-10 16:35:01,772 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32988874916230077
2025-03-10 16:35:01,781 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29998220048657875
2025-03-10 16:35:01,790 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32795613564817505
2025-03-10 16:35:01,800 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36064648693784557
2025-03-10 16:35:01,809 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36766151113841467
2025-03-10 16:35:01,818 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34741403637736196
2025-03-10 16:35:01,827 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3390765685545708
2025-03-10 16:35:01,836 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28418848658740653
2025-03-10 16:35:01,845 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3017164168547239
2025-03-10 16:35:01,854 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34282516292096143
2025-03-10 16:35:01,863 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3445135926834284
2025-03-10 16:35:01,872 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34542769443283433
2025-03-10 16:35:01,882 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31397624170882205
2025-03-10 16:35:01,891 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27834124653826464
2025-03-10 16:35:01,900 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3120133042872369
2025-03-10 16:35:01,910 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2874941457302122
2025-03-10 16:35:01,919 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2816375208258277
2025-03-10 16:35:01,929 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30331408026635787
2025-03-10 16:35:01,938 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3634833833330921
2025-03-10 16:35:01,948 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.287490288204585
2025-03-10 16:35:01,957 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3450870674450751
2025-03-10 16:35:01,968 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30482240876545136
2025-03-10 16:35:01,978 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32623253670818336
2025-03-10 16:35:01,987 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3127773688039294
2025-03-10 16:35:01,997 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2899882429007155
2025-03-10 16:35:02,008 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2793326180441188
2025-03-10 16:35:02,019 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3421307146252003
2025-03-10 16:35:02,034 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3795394148880968
2025-03-10 16:35:02,049 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:35:02,065 - INFO - FONN2 Epoch 900:
2025-03-10 16:35:02,065 - INFO - Train MSE: 0.1675, Test MSE: 0.1865
2025-03-10 16:35:02,065 - INFO - Train R²: 0.8325, Test R²: 0.7791
2025-03-10 16:35:02,065 - INFO - Train MAE: 0.2989, Test MAE: 0.2805
2025-03-10 16:35:02,065 - INFO - Overfit ratio (train R² / test R²): 1.0686
Epoch 0, Loss: 0.3412106951755142
2025-03-10 16:35:02,080 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.331727488494087
2025-03-10 16:35:02,093 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3230574003749328
2025-03-10 16:35:02,103 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29585954000383263
2025-03-10 16:35:02,114 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2933279874126183
2025-03-10 16:35:02,123 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3258006857088138
2025-03-10 16:35:02,132 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2876460180953396
2025-03-10 16:35:02,141 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2973371181076653
2025-03-10 16:35:02,151 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3143957314885453
2025-03-10 16:35:02,160 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29846458965607564
2025-03-10 16:35:02,170 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33168054778686423
2025-03-10 16:35:02,180 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.24823560712583648
2025-03-10 16:35:02,189 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2550936215161397
2025-03-10 16:35:02,199 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27009548966788566
2025-03-10 16:35:02,209 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2851462587664567
2025-03-10 16:35:02,218 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3036834775339399
2025-03-10 16:35:02,227 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3537416299609557
2025-03-10 16:35:02,236 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29406147646158787
2025-03-10 16:35:02,247 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32844655902489256
2025-03-10 16:35:02,256 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29358255302312025
2025-03-10 16:35:02,266 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2930113375699466
2025-03-10 16:35:02,275 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31926478849201284
2025-03-10 16:35:02,284 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3279347019203232
2025-03-10 16:35:02,293 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2897024972822072
2025-03-10 16:35:02,303 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33067208154400635
2025-03-10 16:35:02,312 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29180893284970116
2025-03-10 16:35:02,321 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3180089193231991
2025-03-10 16:35:02,331 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3209080600903185
2025-03-10 16:35:02,340 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3335144072412195
2025-03-10 16:35:02,349 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35614001154434993
2025-03-10 16:35:02,358 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2547319681542541
2025-03-10 16:35:02,367 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27892414325436005
2025-03-10 16:35:02,376 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3072951646173088
2025-03-10 16:35:02,386 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.28694682263249643
2025-03-10 16:35:02,395 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32154100123675167
2025-03-10 16:35:02,404 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35285021000347033
2025-03-10 16:35:02,413 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2684921915717859
2025-03-10 16:35:02,423 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3582317789283969
2025-03-10 16:35:02,432 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2895015055578948
2025-03-10 16:35:02,441 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3266053708668747
2025-03-10 16:35:02,451 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3076046344116095
2025-03-10 16:35:02,460 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29175976955924127
2025-03-10 16:35:02,469 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3649538267568307
2025-03-10 16:35:02,478 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3109792709049322
2025-03-10 16:35:02,488 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34987698083287827
2025-03-10 16:35:02,497 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29511933650076866
2025-03-10 16:35:02,506 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30841865897232695
2025-03-10 16:35:02,516 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31140161086413404
2025-03-10 16:35:02,525 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29020619318929575
2025-03-10 16:35:02,535 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33053859350542003
2025-03-10 16:35:02,544 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.326499642717616
2025-03-10 16:35:02,553 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33632777423876353
2025-03-10 16:35:02,562 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.36557208743958136
2025-03-10 16:35:02,571 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2661549626796879
2025-03-10 16:35:02,580 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.337756149341296
2025-03-10 16:35:02,590 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3018965573569604
2025-03-10 16:35:02,599 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.35209996379272845
2025-03-10 16:35:02,608 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32324478992898525
2025-03-10 16:35:02,618 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33274904820831464
2025-03-10 16:35:02,628 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2847025653008407
2025-03-10 16:35:02,637 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.333727291235047
2025-03-10 16:35:02,646 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31719820530320275
2025-03-10 16:35:02,656 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2906122684429451
2025-03-10 16:35:02,665 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2677714571820283
2025-03-10 16:35:02,674 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3399967109745221
2025-03-10 16:35:02,683 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2895610991244871
2025-03-10 16:35:02,692 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3380183698845817
2025-03-10 16:35:02,703 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2623646215934301
2025-03-10 16:35:02,718 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31238513950980384
2025-03-10 16:35:02,730 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.33643090399361886
2025-03-10 16:35:02,740 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29502844907223347
2025-03-10 16:35:02,749 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2665630189370313
2025-03-10 16:35:02,759 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3590411709178225
2025-03-10 16:35:02,768 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29850094523964193
2025-03-10 16:35:02,777 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.305047786011669
2025-03-10 16:35:02,786 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.30869761846959326
2025-03-10 16:35:02,795 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.308253840258542
2025-03-10 16:35:02,805 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29812916609094614
2025-03-10 16:35:02,815 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2651319334277066
2025-03-10 16:35:02,824 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.27486475438640723
2025-03-10 16:35:02,834 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3234163716461395
2025-03-10 16:35:02,843 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3268540806509789
2025-03-10 16:35:02,852 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2581225397331392
2025-03-10 16:35:02,861 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34645496530048076
2025-03-10 16:35:02,870 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.34084987732472544
2025-03-10 16:35:02,880 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2680889437569754
2025-03-10 16:35:02,889 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3092445208186016
2025-03-10 16:35:02,899 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3168492814466676
2025-03-10 16:35:02,908 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3727055640276206
2025-03-10 16:35:02,917 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3646049838924034
2025-03-10 16:35:02,926 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3000473765725192
2025-03-10 16:35:02,936 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.2914612389091474
2025-03-10 16:35:02,945 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.31324589628537947
2025-03-10 16:35:02,954 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.26169222849242757
2025-03-10 16:35:02,963 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3356513856249766
2025-03-10 16:35:02,972 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.3338404446089971
2025-03-10 16:35:02,981 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.342432122557456
2025-03-10 16:35:02,991 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.32003530350312687
2025-03-10 16:35:03,000 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
Epoch 0, Loss: 0.29775586320260466
2025-03-10 16:35:03,009 - INFO - Skipping tree regularization for FONN2 - feature_importances_ is read-only
2025-03-10 16:35:03,021 - INFO - FONN2 Epoch 999:
2025-03-10 16:35:03,021 - INFO - Train MSE: 0.1614, Test MSE: 0.1791
2025-03-10 16:35:03,021 - INFO - Train R²: 0.8386, Test R²: 0.7879
2025-03-10 16:35:03,021 - INFO - Train MAE: 0.2942, Test MAE: 0.2758
2025-03-10 16:35:03,022 - INFO - Overfit ratio (train R² / test R²): 1.0644
2025-03-10 16:35:03,032 - INFO -
FONN2 Final Metrics:
2025-03-10 16:35:03,032 - INFO - R² Score: 0.7879
2025-03-10 16:35:03,032 - INFO - MAE: 0.2758
2025-03-10 16:35:03,033 - INFO - MSE: 0.1791
2025-03-10 16:35:03,033 - INFO - Train R²: 0.8386
2025-03-10 16:35:03,033 - INFO - Overfit Ratio: 1.0644
2025-03-10 16:35:03,033 - INFO - FONN2 evaluation successful!
2025-03-10 16:35:03,033 - INFO -
Initializing FONN3...
2025-03-10 16:35:03,033 - INFO - Using reduced learning rate for FONN3: 0.001
2025-03-10 16:35:03,033 - INFO - Using reduced alpha for FONN3: 0.1
2025-03-10 16:35:03,034 - INFO - Model class: FONN3
2025-03-10 16:35:03,080 - INFO - FONN3 model initialized successfully!
2025-03-10 16:35:03,081 - INFO - FONN3 architecture:
2025-03-10 16:35:03,081 - INFO - Input dimension: 12
2025-03-10 16:35:03,081 - INFO - Hidden dimension: 64
2025-03-10 16:35:03,081 - INFO - Output dimension: 1
2025-03-10 16:35:03,081 - INFO - Alpha (tree contribution): 0.1
2025-03-10 16:35:03,082 - INFO - Applying regularization: L2 strength=0.001, Dropout rate=0.2
2025-03-10 16:35:03,082 - INFO - Training FONN3...
Epoch 0, Loss: 4.582699911572839
2025-03-10 16:35:03,096 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:03,118 - INFO - FONN3 Epoch 0:
2025-03-10 16:35:03,118 - INFO - Train MSE: 4.7794, Test MSE: 5.4427
2025-03-10 16:35:03,118 - INFO - Train R²: -3.7794, Test R²: -5.4476
2025-03-10 16:35:03,118 - INFO - Train MAE: 1.8521, Test MAE: 1.9117
2025-03-10 16:35:03,119 - INFO - Overfit ratio (train R² / test R²): 0.6938
Epoch 0, Loss: 4.741828570437574
2025-03-10 16:35:03,134 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.696151104253059
2025-03-10 16:35:03,146 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.18846921617278
2025-03-10 16:35:03,159 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.163505840508886
2025-03-10 16:35:03,174 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.5171730789732445
2025-03-10 16:35:03,189 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.957420011877725
2025-03-10 16:35:03,204 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.22451111992028
2025-03-10 16:35:03,217 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.285729094322892
2025-03-10 16:35:03,227 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.362333240256311
2025-03-10 16:35:03,239 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.860411725488889
2025-03-10 16:35:03,249 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.3550688145334355
2025-03-10 16:35:03,261 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.191641705634686
2025-03-10 16:35:03,272 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.392382423698986
2025-03-10 16:35:03,283 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.136907013583686
2025-03-10 16:35:03,298 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.229976353757522
2025-03-10 16:35:03,311 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.062307146996354
2025-03-10 16:35:03,321 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.020066332924106
2025-03-10 16:35:03,333 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.9342683189764918
2025-03-10 16:35:03,343 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.980782855708633
2025-03-10 16:35:03,355 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.9649615429402516
2025-03-10 16:35:03,367 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.9977535879410513
2025-03-10 16:35:03,378 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.9219888049560736
2025-03-10 16:35:03,387 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.1841252271768665
2025-03-10 16:35:03,397 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.6839414126137022
2025-03-10 16:35:03,407 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.7127044552624677
2025-03-10 16:35:03,417 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.6090110278238856
2025-03-10 16:35:03,426 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.145095143888046
2025-03-10 16:35:03,436 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.7114482396619146
2025-03-10 16:35:03,445 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.7925607027445736
2025-03-10 16:35:03,456 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 4.019988202752446
2025-03-10 16:35:03,466 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.6632192340223706
2025-03-10 16:35:03,475 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.67750650643526
2025-03-10 16:35:03,485 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.5471572641641926
2025-03-10 16:35:03,494 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.628585813279111
2025-03-10 16:35:03,503 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.460366397724295
2025-03-10 16:35:03,513 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.909013973977589
2025-03-10 16:35:03,522 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.5323955034163466
2025-03-10 16:35:03,532 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.9611206522044613
2025-03-10 16:35:03,541 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.3341404506379733
2025-03-10 16:35:03,551 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.685291347663259
2025-03-10 16:35:03,560 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.649118187387869
2025-03-10 16:35:03,570 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.6857666985812942
2025-03-10 16:35:03,579 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.6358340621193213
2025-03-10 16:35:03,588 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.725486718427765
2025-03-10 16:35:03,598 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.5330827506107663
2025-03-10 16:35:03,607 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.4034428640420287
2025-03-10 16:35:03,617 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.352246945333202
2025-03-10 16:35:03,626 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.4763535965231673
2025-03-10 16:35:03,636 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.3955537349429776
2025-03-10 16:35:03,645 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.456617723327664
2025-03-10 16:35:03,655 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.500560229378953
2025-03-10 16:35:03,665 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.2567514007823077
2025-03-10 16:35:03,675 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9935788393117653
2025-03-10 16:35:03,685 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0149517176354177
2025-03-10 16:35:03,695 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.3650082319448376
2025-03-10 16:35:03,705 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.197572694914411
2025-03-10 16:35:03,715 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.934977271676976
2025-03-10 16:35:03,725 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.461375409499798
2025-03-10 16:35:03,735 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.091314803054891
2025-03-10 16:35:03,745 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7977835541284954
2025-03-10 16:35:03,755 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8673967060002554
2025-03-10 16:35:03,766 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.191024138337152
2025-03-10 16:35:03,775 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.196684522268025
2025-03-10 16:35:03,786 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.957143469363644
2025-03-10 16:35:03,802 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.179619589896016
2025-03-10 16:35:03,819 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.92970119459984
2025-03-10 16:35:03,836 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.933260011194506
2025-03-10 16:35:03,852 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0705067057164768
2025-03-10 16:35:03,863 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.353629793903143
2025-03-10 16:35:03,873 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9109430815127086
2025-03-10 16:35:03,883 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0587691876441627
2025-03-10 16:35:03,893 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.16614918681627
2025-03-10 16:35:03,903 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8586520493394474
2025-03-10 16:35:03,913 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.046695293806198
2025-03-10 16:35:03,922 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.1812287845284946
2025-03-10 16:35:03,932 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.826875368182403
2025-03-10 16:35:03,942 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.155928464094971
2025-03-10 16:35:03,951 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7560857900636124
2025-03-10 16:35:03,961 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9484941587670632
2025-03-10 16:35:03,970 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6301338301259882
2025-03-10 16:35:03,980 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9582857717509663
2025-03-10 16:35:03,990 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9867895783424077
2025-03-10 16:35:03,999 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.604962992541099
2025-03-10 16:35:04,009 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0844286350726215
2025-03-10 16:35:04,019 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8313729736141298
2025-03-10 16:35:04,029 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0521527207335892
2025-03-10 16:35:04,038 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.834293924356658
2025-03-10 16:35:04,048 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.85273953690073
2025-03-10 16:35:04,057 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.522446726507246
2025-03-10 16:35:04,067 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6534024948081423
2025-03-10 16:35:04,077 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4194877394579626
2025-03-10 16:35:04,087 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7940984672372386
2025-03-10 16:35:04,096 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.095789630445751
2025-03-10 16:35:04,106 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9993389305023643
2025-03-10 16:35:04,116 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.806481038834923
2025-03-10 16:35:04,125 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.623024251836864
2025-03-10 16:35:04,135 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5578160069620552
2025-03-10 16:35:04,145 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5528190410498626
2025-03-10 16:35:04,154 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.827093215128968
2025-03-10 16:35:04,164 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.819574845891358
2025-03-10 16:35:04,174 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:04,187 - INFO - FONN3 Epoch 100:
2025-03-10 16:35:04,187 - INFO - Train MSE: 1.7696, Test MSE: 2.3000
2025-03-10 16:35:04,187 - INFO - Train R²: -0.7696, Test R²: -1.7246
2025-03-10 16:35:04,187 - INFO - Train MAE: 1.0482, Test MAE: 1.1264
2025-03-10 16:35:04,188 - INFO - Overfit ratio (train R² / test R²): 0.4463
Epoch 0, Loss: 2.7353495314224654
2025-03-10 16:35:04,197 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.748728057066498
2025-03-10 16:35:04,207 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3787706724308446
2025-03-10 16:35:04,217 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6569026842970933
2025-03-10 16:35:04,226 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4989007838708637
2025-03-10 16:35:04,236 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.392011064730944
2025-03-10 16:35:04,245 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7172025005502927
2025-03-10 16:35:04,255 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.037403677055664
2025-03-10 16:35:04,264 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 3.0448816539177708
2025-03-10 16:35:04,275 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8241679133774396
2025-03-10 16:35:04,284 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5186956122947186
2025-03-10 16:35:04,293 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6012957156191803
2025-03-10 16:35:04,303 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.428557152315286
2025-03-10 16:35:04,312 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.614876619510358
2025-03-10 16:35:04,322 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5614013579513766
2025-03-10 16:35:04,331 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3346450013658484
2025-03-10 16:35:04,341 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.55337144751796
2025-03-10 16:35:04,351 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6746800913177835
2025-03-10 16:35:04,360 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.569539017577153
2025-03-10 16:35:04,370 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.577890748469252
2025-03-10 16:35:04,380 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5687422464005722
2025-03-10 16:35:04,389 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.561967756121147
2025-03-10 16:35:04,399 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2707063628776796
2025-03-10 16:35:04,408 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.60852302717616
2025-03-10 16:35:04,418 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5006099208785195
2025-03-10 16:35:04,427 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.9107077480745502
2025-03-10 16:35:04,437 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5654792697300866
2025-03-10 16:35:04,447 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3861370983440535
2025-03-10 16:35:04,457 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.815543034797621
2025-03-10 16:35:04,467 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6965173984045614
2025-03-10 16:35:04,476 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.574531183256469
2025-03-10 16:35:04,486 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4970963803616852
2025-03-10 16:35:04,496 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.310063814992336
2025-03-10 16:35:04,506 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.316893308259728
2025-03-10 16:35:04,515 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.508256581917276
2025-03-10 16:35:04,525 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6816234043625085
2025-03-10 16:35:04,535 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7369223894148864
2025-03-10 16:35:04,545 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3804440937737628
2025-03-10 16:35:04,555 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1255064630336147
2025-03-10 16:35:04,565 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2822902692489055
2025-03-10 16:35:04,575 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5317457708869124
2025-03-10 16:35:04,584 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.890941140926526
2025-03-10 16:35:04,594 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.435273065937285
2025-03-10 16:35:04,604 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.52889285559134
2025-03-10 16:35:04,614 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2381280933640335
2025-03-10 16:35:04,623 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2509990865737493
2025-03-10 16:35:04,633 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3075881835217937
2025-03-10 16:35:04,643 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.242817627176614
2025-03-10 16:35:04,653 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5202541316450793
2025-03-10 16:35:04,662 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.81388968882129
2025-03-10 16:35:04,672 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.340061602461423
2025-03-10 16:35:04,681 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.365242127719278
2025-03-10 16:35:04,691 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.501768116099687
2025-03-10 16:35:04,701 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8639055715006956
2025-03-10 16:35:04,711 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7222997312895414
2025-03-10 16:35:04,720 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2542625644145424
2025-03-10 16:35:04,730 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.556949839698727
2025-03-10 16:35:04,740 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.391853355741503
2025-03-10 16:35:04,750 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.527073974955484
2025-03-10 16:35:04,760 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5020260138730017
2025-03-10 16:35:04,770 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0921005699767603
2025-03-10 16:35:04,779 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.416720753737606
2025-03-10 16:35:04,789 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6040144500703994
2025-03-10 16:35:04,799 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6637659076368676
2025-03-10 16:35:04,808 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.131356803911711
2025-03-10 16:35:04,818 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.518593452250126
2025-03-10 16:35:04,828 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.602089315846315
2025-03-10 16:35:04,837 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5352908162383154
2025-03-10 16:35:04,847 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4238647091672387
2025-03-10 16:35:04,857 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2793496525686545
2025-03-10 16:35:04,866 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.357844538960998
2025-03-10 16:35:04,876 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.629058404304675
2025-03-10 16:35:04,885 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.562097431288683
2025-03-10 16:35:04,895 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8936123271643943
2025-03-10 16:35:04,905 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4425644842035066
2025-03-10 16:35:04,914 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.373676279301629
2025-03-10 16:35:04,924 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.708257001561927
2025-03-10 16:35:04,933 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.235604740386506
2025-03-10 16:35:04,943 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5187040652255352
2025-03-10 16:35:04,954 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.431111024254237
2025-03-10 16:35:04,964 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3906387870721058
2025-03-10 16:35:04,974 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2660701561272902
2025-03-10 16:35:04,983 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6629118576218254
2025-03-10 16:35:04,993 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0226413043381473
2025-03-10 16:35:05,003 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.355745157812884
2025-03-10 16:35:05,013 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.056437509835619
2025-03-10 16:35:05,023 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1017445112263458
2025-03-10 16:35:05,033 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3403848210171945
2025-03-10 16:35:05,043 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.347461873187717
2025-03-10 16:35:05,053 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.215833755931427
2025-03-10 16:35:05,063 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2542977620431826
2025-03-10 16:35:05,072 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5229224981799936
2025-03-10 16:35:05,082 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2899710586584865
2025-03-10 16:35:05,091 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.671713019607868
2025-03-10 16:35:05,101 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4323850811839707
2025-03-10 16:35:05,111 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.242942111073605
2025-03-10 16:35:05,121 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1367205157972777
2025-03-10 16:35:05,130 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.463676764094681
2025-03-10 16:35:05,140 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.526474668758903
2025-03-10 16:35:05,150 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.450176938589376
2025-03-10 16:35:05,159 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:05,173 - INFO - FONN3 Epoch 200:
2025-03-10 16:35:05,173 - INFO - Train MSE: 1.1123, Test MSE: 1.5907
2025-03-10 16:35:05,173 - INFO - Train R²: -0.1123, Test R²: -0.8844
2025-03-10 16:35:05,173 - INFO - Train MAE: 0.8128, Test MAE: 0.9014
2025-03-10 16:35:05,173 - INFO - Overfit ratio (train R² / test R²): 0.1270
Epoch 0, Loss: 2.439341846242357
2025-03-10 16:35:05,183 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2949933582302213
2025-03-10 16:35:05,192 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.273212448428414
2025-03-10 16:35:05,202 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3863884033804514
2025-03-10 16:35:05,212 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.295450267496702
2025-03-10 16:35:05,222 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.097920549068965
2025-03-10 16:35:05,231 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5932987431988583
2025-03-10 16:35:05,241 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6115844677172477
2025-03-10 16:35:05,251 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7540658869194505
2025-03-10 16:35:05,260 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2622032607859333
2025-03-10 16:35:05,270 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.356350907134345
2025-03-10 16:35:05,280 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.8955766377024283
2025-03-10 16:35:05,289 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1867540889784696
2025-03-10 16:35:05,299 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.244430237383816
2025-03-10 16:35:05,308 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3491398519869153
2025-03-10 16:35:05,318 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5582621467621984
2025-03-10 16:35:05,327 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2249782006605456
2025-03-10 16:35:05,337 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.348092092173598
2025-03-10 16:35:05,347 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2233879881322927
2025-03-10 16:35:05,357 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9146480553844039
2025-03-10 16:35:05,366 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8925189687163857
2025-03-10 16:35:05,376 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2639379717116586
2025-03-10 16:35:05,385 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4909064673049697
2025-03-10 16:35:05,395 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.32015586218606
2025-03-10 16:35:05,404 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6215312443359946
2025-03-10 16:35:05,414 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.247342467048661
2025-03-10 16:35:05,424 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3868610579441754
2025-03-10 16:35:05,434 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2985865609883662
2025-03-10 16:35:05,444 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1795969799948023
2025-03-10 16:35:05,454 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2138703442905943
2025-03-10 16:35:05,463 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6535969723037947
2025-03-10 16:35:05,472 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.272380607661043
2025-03-10 16:35:05,482 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2828798106435473
2025-03-10 16:35:05,492 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.686637328391854
2025-03-10 16:35:05,502 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.108989902669024
2025-03-10 16:35:05,511 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.277115351120483
2025-03-10 16:35:05,521 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9973568275956675
2025-03-10 16:35:05,530 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.398474759917336
2025-03-10 16:35:05,540 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.627152503908347
2025-03-10 16:35:05,550 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1593616673450424
2025-03-10 16:35:05,559 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1393549329649573
2025-03-10 16:35:05,569 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.333855826452607
2025-03-10 16:35:05,578 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.193911434326723
2025-03-10 16:35:05,588 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4681581931794603
2025-03-10 16:35:05,598 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2351692523932014
2025-03-10 16:35:05,608 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2740951147896067
2025-03-10 16:35:05,618 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.536179996111502
2025-03-10 16:35:05,628 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.6004187502189566
2025-03-10 16:35:05,639 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.483125482932115
2025-03-10 16:35:05,649 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.04558071011321
2025-03-10 16:35:05,659 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.146968786028969
2025-03-10 16:35:05,669 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5118810522838557
2025-03-10 16:35:05,678 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.092826619216543
2025-03-10 16:35:05,688 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.197365336718365
2025-03-10 16:35:05,698 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.136763281970892
2025-03-10 16:35:05,708 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.280560433774935
2025-03-10 16:35:05,717 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2000543725936645
2025-03-10 16:35:05,727 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.403913592281067
2025-03-10 16:35:05,737 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.200898906472217
2025-03-10 16:35:05,747 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.098193949781409
2025-03-10 16:35:05,756 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.098849856371157
2025-03-10 16:35:05,766 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0880633597391554
2025-03-10 16:35:05,775 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.100049991014366
2025-03-10 16:35:05,785 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2774808617395124
2025-03-10 16:35:05,794 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3973714528605656
2025-03-10 16:35:05,804 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2219553205670435
2025-03-10 16:35:05,814 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.119821393941568
2025-03-10 16:35:05,824 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.258296452409605
2025-03-10 16:35:05,834 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.386258749137161
2025-03-10 16:35:05,844 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3056708566274087
2025-03-10 16:35:05,854 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0542256855369723
2025-03-10 16:35:05,864 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.046420488583598
2025-03-10 16:35:05,873 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2190260869000644
2025-03-10 16:35:05,883 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.148242291411141
2025-03-10 16:35:05,893 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.288381317418605
2025-03-10 16:35:05,903 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.66581202112041
2025-03-10 16:35:05,912 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2951917395682355
2025-03-10 16:35:05,922 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1289206128340132
2025-03-10 16:35:05,932 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3930127171878244
2025-03-10 16:35:05,941 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9889846637203408
2025-03-10 16:35:05,951 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3711452493851803
2025-03-10 16:35:05,961 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.261050394547193
2025-03-10 16:35:05,971 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1040587748579083
2025-03-10 16:35:05,981 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.438865406848776
2025-03-10 16:35:05,991 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9635293979204698
2025-03-10 16:35:06,001 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4640200043255613
2025-03-10 16:35:06,010 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1341246952913213
2025-03-10 16:35:06,020 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8361374755931867
2025-03-10 16:35:06,030 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.132496713026446
2025-03-10 16:35:06,040 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9431001445807312
2025-03-10 16:35:06,050 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.139592166532407
2025-03-10 16:35:06,061 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2635233959062124
2025-03-10 16:35:06,071 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0823585395226245
2025-03-10 16:35:06,081 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.042511941872333
2025-03-10 16:35:06,090 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.082560148881886
2025-03-10 16:35:06,100 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.098857042827226
2025-03-10 16:35:06,111 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8370497807925832
2025-03-10 16:35:06,121 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.7118173105286902
2025-03-10 16:35:06,132 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.22761374368014
2025-03-10 16:35:06,142 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1276126844830388
2025-03-10 16:35:06,151 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:06,165 - INFO - FONN3 Epoch 300:
2025-03-10 16:35:06,165 - INFO - Train MSE: 0.9084, Test MSE: 1.3648
2025-03-10 16:35:06,165 - INFO - Train R²: 0.0916, Test R²: -0.6168
2025-03-10 16:35:06,165 - INFO - Train MAE: 0.7260, Test MAE: 0.8358
2025-03-10 16:35:06,166 - INFO - Overfit ratio (train R² / test R²): -0.1486
Epoch 0, Loss: 2.214775778825755
2025-03-10 16:35:06,176 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.454230729252151
2025-03-10 16:35:06,186 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.658382020899931
2025-03-10 16:35:06,196 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.104518492888212
2025-03-10 16:35:06,206 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2097489466811133
2025-03-10 16:35:06,217 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0368093020976197
2025-03-10 16:35:06,227 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5404567613655495
2025-03-10 16:35:06,236 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.150573923673429
2025-03-10 16:35:06,247 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.166719013648411
2025-03-10 16:35:06,257 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8175512423395617
2025-03-10 16:35:06,267 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.146046726615678
2025-03-10 16:35:06,277 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4515898266649914
2025-03-10 16:35:06,287 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.032086317452405
2025-03-10 16:35:06,296 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.123865228548095
2025-03-10 16:35:06,306 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.261335412620543
2025-03-10 16:35:06,316 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1414581417560017
2025-03-10 16:35:06,325 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.139186588025455
2025-03-10 16:35:06,336 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.973000136801349
2025-03-10 16:35:06,346 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9195030224257643
2025-03-10 16:35:06,356 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2362153545989494
2025-03-10 16:35:06,367 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0076975229831455
2025-03-10 16:35:06,377 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0288885922923385
2025-03-10 16:35:06,387 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1137509076085372
2025-03-10 16:35:06,397 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8126172000643193
2025-03-10 16:35:06,408 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.198387646570697
2025-03-10 16:35:06,419 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1600178513068564
2025-03-10 16:35:06,429 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9866980926210693
2025-03-10 16:35:06,440 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.804679549687284
2025-03-10 16:35:06,454 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.448142919150481
2025-03-10 16:35:06,464 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.197977408270755
2025-03-10 16:35:06,474 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0065642240073904
2025-03-10 16:35:06,485 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.150244579011705
2025-03-10 16:35:06,496 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.035416862771525
2025-03-10 16:35:06,506 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.828477328458249
2025-03-10 16:35:06,516 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.990244289545824
2025-03-10 16:35:06,526 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.908677400716745
2025-03-10 16:35:06,536 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3290118747706394
2025-03-10 16:35:06,546 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.793033893119221
2025-03-10 16:35:06,556 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2339810531830024
2025-03-10 16:35:06,566 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.217335090617444
2025-03-10 16:35:06,577 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3349105996595947
2025-03-10 16:35:06,587 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9232952744998264
2025-03-10 16:35:06,597 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0063792039431148
2025-03-10 16:35:06,607 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1666994022117883
2025-03-10 16:35:06,616 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.992688937808503
2025-03-10 16:35:06,626 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3735774743351135
2025-03-10 16:35:06,636 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1981917331233447
2025-03-10 16:35:06,646 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.653536347825098
2025-03-10 16:35:06,656 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3317755702918475
2025-03-10 16:35:06,666 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7268661855397949
2025-03-10 16:35:06,676 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.989555591401668
2025-03-10 16:35:06,686 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3676199100729147
2025-03-10 16:35:06,696 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3762144747372296
2025-03-10 16:35:06,706 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9583864333887
2025-03-10 16:35:06,716 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.262143597098317
2025-03-10 16:35:06,726 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3998307899965083
2025-03-10 16:35:06,737 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2365049728992683
2025-03-10 16:35:06,748 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2629535022069343
2025-03-10 16:35:06,758 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0219901949233394
2025-03-10 16:35:06,769 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1968607101569293
2025-03-10 16:35:06,779 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4270497630624392
2025-03-10 16:35:06,789 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7802766290597851
2025-03-10 16:35:06,800 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.115848130547668
2025-03-10 16:35:06,810 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4986163228962686
2025-03-10 16:35:06,821 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4838359638822456
2025-03-10 16:35:06,831 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1772624737554294
2025-03-10 16:35:06,840 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0946239117880383
2025-03-10 16:35:06,852 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.949426301608854
2025-03-10 16:35:06,861 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0444843762309963
2025-03-10 16:35:06,871 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.159041402778519
2025-03-10 16:35:06,881 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9312509194416436
2025-03-10 16:35:06,891 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0583659873098266
2025-03-10 16:35:06,902 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.508286890486352
2025-03-10 16:35:06,912 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.306814899518781
2025-03-10 16:35:06,923 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.073315859331347
2025-03-10 16:35:06,935 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.159490596010657
2025-03-10 16:35:06,948 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.938600678731358
2025-03-10 16:35:06,959 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8864382577566594
2025-03-10 16:35:06,969 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2587810844746476
2025-03-10 16:35:06,979 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.341464031816631
2025-03-10 16:35:06,990 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1054909109131943
2025-03-10 16:35:07,000 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1772631851125586
2025-03-10 16:35:07,011 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.082285342587697
2025-03-10 16:35:07,023 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3322309427497276
2025-03-10 16:35:07,034 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0620160008914934
2025-03-10 16:35:07,045 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.347560683666253
2025-03-10 16:35:07,055 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3810624046413014
2025-03-10 16:35:07,065 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7962610412045812
2025-03-10 16:35:07,076 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1964277391506477
2025-03-10 16:35:07,086 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.077041515702363
2025-03-10 16:35:07,096 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.177978321650341
2025-03-10 16:35:07,106 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.184198889689412
2025-03-10 16:35:07,116 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.195151712545852
2025-03-10 16:35:07,126 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0931378556779756
2025-03-10 16:35:07,136 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.066682972954037
2025-03-10 16:35:07,146 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.290812724959447
2025-03-10 16:35:07,156 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3218023229709215
2025-03-10 16:35:07,166 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0410132043207576
2025-03-10 16:35:07,176 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.138690851074006
2025-03-10 16:35:07,185 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.47308249969077
2025-03-10 16:35:07,195 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:07,211 - INFO - FONN3 Epoch 400:
2025-03-10 16:35:07,211 - INFO - Train MSE: 0.8098, Test MSE: 1.2514
2025-03-10 16:35:07,211 - INFO - Train R²: 0.1902, Test R²: -0.4825
2025-03-10 16:35:07,211 - INFO - Train MAE: 0.6797, Test MAE: 0.8118
2025-03-10 16:35:07,211 - INFO - Overfit ratio (train R² / test R²): -0.3942
Epoch 0, Loss: 2.079259605035902
2025-03-10 16:35:07,221 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1218776296579094
2025-03-10 16:35:07,231 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4351378521202216
2025-03-10 16:35:07,241 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9739005002840884
2025-03-10 16:35:07,251 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.102413254882873
2025-03-10 16:35:07,261 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.114433165274656
2025-03-10 16:35:07,271 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.226263728858216
2025-03-10 16:35:07,281 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9365294976190328
2025-03-10 16:35:07,290 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9081840853938825
2025-03-10 16:35:07,302 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7904529251603716
2025-03-10 16:35:07,312 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1219776251931997
2025-03-10 16:35:07,322 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.249012758060556
2025-03-10 16:35:07,332 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.190770267080399
2025-03-10 16:35:07,341 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9967953977623731
2025-03-10 16:35:07,351 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.346205545064451
2025-03-10 16:35:07,360 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5955498999557793
2025-03-10 16:35:07,370 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9218365430881494
2025-03-10 16:35:07,380 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0598901268874745
2025-03-10 16:35:07,389 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8265352856664203
2025-03-10 16:35:07,400 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1861180343783766
2025-03-10 16:35:07,409 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.27969998248834
2025-03-10 16:35:07,419 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2098789076195127
2025-03-10 16:35:07,430 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2631322499527045
2025-03-10 16:35:07,440 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.403959114863947
2025-03-10 16:35:07,450 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9361811251247067
2025-03-10 16:35:07,460 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3286662750328513
2025-03-10 16:35:07,470 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8670996931610966
2025-03-10 16:35:07,480 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3481737246954415
2025-03-10 16:35:07,490 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7991842701143628
2025-03-10 16:35:07,499 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7785150255436315
2025-03-10 16:35:07,509 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.86528638417368
2025-03-10 16:35:07,519 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0626648484869956
2025-03-10 16:35:07,528 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1140273855467377
2025-03-10 16:35:07,539 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8211512898534277
2025-03-10 16:35:07,550 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.832078862512933
2025-03-10 16:35:07,560 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9035491433596696
2025-03-10 16:35:07,570 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1327784358837216
2025-03-10 16:35:07,581 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0216483696356353
2025-03-10 16:35:07,591 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9917398527585939
2025-03-10 16:35:07,601 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5075848579481352
2025-03-10 16:35:07,611 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.011558371461151
2025-03-10 16:35:07,621 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.060806659780984
2025-03-10 16:35:07,631 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.372983461848051
2025-03-10 16:35:07,641 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.185787142514256
2025-03-10 16:35:07,650 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8522212554463944
2025-03-10 16:35:07,660 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.308098811791128
2025-03-10 16:35:07,670 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8787390362281517
2025-03-10 16:35:07,680 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9243883313797832
2025-03-10 16:35:07,690 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1353880231004174
2025-03-10 16:35:07,700 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.239804409229631
2025-03-10 16:35:07,709 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.817501484423022
2025-03-10 16:35:07,719 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.940153618749169
2025-03-10 16:35:07,729 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0819259856499146
2025-03-10 16:35:07,739 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1393460020436548
2025-03-10 16:35:07,750 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.022939710337889
2025-03-10 16:35:07,759 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3091516693553444
2025-03-10 16:35:07,769 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8627931087683827
2025-03-10 16:35:07,779 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.205803409193064
2025-03-10 16:35:07,789 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0666500358770015
2025-03-10 16:35:07,800 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.189420605138797
2025-03-10 16:35:07,811 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2039090505261667
2025-03-10 16:35:07,821 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.653869821301159
2025-03-10 16:35:07,831 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1752274843633463
2025-03-10 16:35:07,841 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9360764089125393
2025-03-10 16:35:07,853 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2173367329145637
2025-03-10 16:35:07,863 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1117739559958264
2025-03-10 16:35:07,873 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.328402413871273
2025-03-10 16:35:07,883 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4963473322636167
2025-03-10 16:35:07,893 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.965523818981409
2025-03-10 16:35:07,903 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.230697628777799
2025-03-10 16:35:07,914 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8556886827255143
2025-03-10 16:35:07,927 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1434300777713915
2025-03-10 16:35:07,942 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2704060167583062
2025-03-10 16:35:07,955 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9859061612855415
2025-03-10 16:35:07,965 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0661894849710265
2025-03-10 16:35:07,974 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9518368135217623
2025-03-10 16:35:07,984 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9952767517963916
2025-03-10 16:35:07,994 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9261050944385616
2025-03-10 16:35:08,004 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8412223017704705
2025-03-10 16:35:08,014 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2857104347249666
2025-03-10 16:35:08,023 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.95086371629786
2025-03-10 16:35:08,033 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6679186893630464
2025-03-10 16:35:08,045 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0208117120691482
2025-03-10 16:35:08,056 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1381452517664092
2025-03-10 16:35:08,066 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9024803405480575
2025-03-10 16:35:08,076 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.037648301547899
2025-03-10 16:35:08,088 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.000772052295436
2025-03-10 16:35:08,101 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.083947548136698
2025-03-10 16:35:08,112 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0474567802401276
2025-03-10 16:35:08,122 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4297455161411263
2025-03-10 16:35:08,132 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.038841811258818
2025-03-10 16:35:08,141 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0529945661738433
2025-03-10 16:35:08,152 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9903954385922753
2025-03-10 16:35:08,163 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.46433257305912
2025-03-10 16:35:08,173 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.313382317986363
2025-03-10 16:35:08,184 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.75571786884598
2025-03-10 16:35:08,194 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0700933890682833
2025-03-10 16:35:08,206 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2863613407141514
2025-03-10 16:35:08,218 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.042006100116312
2025-03-10 16:35:08,228 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.237743020105987
2025-03-10 16:35:08,239 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:08,253 - INFO - FONN3 Epoch 500:
2025-03-10 16:35:08,253 - INFO - Train MSE: 0.7613, Test MSE: 1.1947
2025-03-10 16:35:08,253 - INFO - Train R²: 0.2387, Test R²: -0.4152
2025-03-10 16:35:08,254 - INFO - Train MAE: 0.6583, Test MAE: 0.8050
2025-03-10 16:35:08,254 - INFO - Overfit ratio (train R² / test R²): -0.5749
Epoch 0, Loss: 1.8134870594956238
2025-03-10 16:35:08,264 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.039758821881908
2025-03-10 16:35:08,275 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9010009901582223
2025-03-10 16:35:08,285 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1155091189535167
2025-03-10 16:35:08,296 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.034811931463647
2025-03-10 16:35:08,306 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0357775122737203
2025-03-10 16:35:08,316 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7735149267425312
2025-03-10 16:35:08,326 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.026469925754044
2025-03-10 16:35:08,337 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.18735289754287
2025-03-10 16:35:08,347 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9827806416583074
2025-03-10 16:35:08,358 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0697982275861326
2025-03-10 16:35:08,368 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9400757032268523
2025-03-10 16:35:08,378 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2405884624960803
2025-03-10 16:35:08,388 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8529603488515605
2025-03-10 16:35:08,398 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.819692122509687
2025-03-10 16:35:08,408 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1119242500423194
2025-03-10 16:35:08,418 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4662836789923945
2025-03-10 16:35:08,429 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0597859652589947
2025-03-10 16:35:08,439 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.533391756150969
2025-03-10 16:35:08,449 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.29607663578494
2025-03-10 16:35:08,459 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9714040086938007
2025-03-10 16:35:08,469 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9831087506548923
2025-03-10 16:35:08,479 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.798630367283935
2025-03-10 16:35:08,488 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8364194212243616
2025-03-10 16:35:08,498 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.100616552340585
2025-03-10 16:35:08,508 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.140361790682438
2025-03-10 16:35:08,518 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1118568148650225
2025-03-10 16:35:08,528 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.288880355624068
2025-03-10 16:35:08,538 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8174819554145316
2025-03-10 16:35:08,548 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.134456148350182
2025-03-10 16:35:08,558 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1724179661993546
2025-03-10 16:35:08,568 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1362360453654605
2025-03-10 16:35:08,577 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0863430170870063
2025-03-10 16:35:08,587 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9810142978119074
2025-03-10 16:35:08,596 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0413624385326776
2025-03-10 16:35:08,606 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2978268379161393
2025-03-10 16:35:08,616 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.01818642124686
2025-03-10 16:35:08,625 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2745000795454855
2025-03-10 16:35:08,635 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.110498536878846
2025-03-10 16:35:08,645 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0561419346856837
2025-03-10 16:35:08,654 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3956778019385268
2025-03-10 16:35:08,664 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.145200826803155
2025-03-10 16:35:08,674 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2377656317653005
2025-03-10 16:35:08,684 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7511256355704274
2025-03-10 16:35:08,694 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.092045300428991
2025-03-10 16:35:08,704 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8368772934139752
2025-03-10 16:35:08,714 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.018477055577668
2025-03-10 16:35:08,723 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.074421163183459
2025-03-10 16:35:08,734 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1300307330109978
2025-03-10 16:35:08,744 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2556206092313897
2025-03-10 16:35:08,754 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8074949495367554
2025-03-10 16:35:08,763 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2091721865312306
2025-03-10 16:35:08,773 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.426366129812385
2025-03-10 16:35:08,783 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.411496892936975
2025-03-10 16:35:08,793 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7687958755829993
2025-03-10 16:35:08,803 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6452443590434283
2025-03-10 16:35:08,813 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0188984949172677
2025-03-10 16:35:08,822 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9786015329339413
2025-03-10 16:35:08,832 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7413474706242476
2025-03-10 16:35:08,843 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2593998504432578
2025-03-10 16:35:08,853 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9842617953792312
2025-03-10 16:35:08,863 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7812943390184734
2025-03-10 16:35:08,873 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5835765715264352
2025-03-10 16:35:08,883 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.004597740922032
2025-03-10 16:35:08,892 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0856986693468915
2025-03-10 16:35:08,902 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3047487768335944
2025-03-10 16:35:08,911 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2545530946349652
2025-03-10 16:35:08,921 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8134464822291168
2025-03-10 16:35:08,930 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.832953191411138
2025-03-10 16:35:08,940 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9696491227571458
2025-03-10 16:35:08,950 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.981251803203945
2025-03-10 16:35:08,959 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.891215114298065
2025-03-10 16:35:08,969 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.285617116712602
2025-03-10 16:35:08,979 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.429398054147544
2025-03-10 16:35:08,989 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9607678820899193
2025-03-10 16:35:08,998 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.734200352095548
2025-03-10 16:35:09,008 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.08356602078327
2025-03-10 16:35:09,018 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.139582973725124
2025-03-10 16:35:09,028 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.865481370389597
2025-03-10 16:35:09,037 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0219980668183344
2025-03-10 16:35:09,047 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0016256919361233
2025-03-10 16:35:09,057 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8592649666531598
2025-03-10 16:35:09,067 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.384602804852626
2025-03-10 16:35:09,078 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2132205655759414
2025-03-10 16:35:09,088 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9430714452844218
2025-03-10 16:35:09,098 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9662212960680583
2025-03-10 16:35:09,108 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7457770576585796
2025-03-10 16:35:09,117 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.197794727258186
2025-03-10 16:35:09,128 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9357169401190892
2025-03-10 16:35:09,138 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3228739616012213
2025-03-10 16:35:09,148 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1634214079795293
2025-03-10 16:35:09,157 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8423871306574608
2025-03-10 16:35:09,167 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7841408405710735
2025-03-10 16:35:09,177 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0494485017091706
2025-03-10 16:35:09,187 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.162900813011741
2025-03-10 16:35:09,196 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.837029000599628
2025-03-10 16:35:09,206 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9972601813228774
2025-03-10 16:35:09,216 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.010806451214586
2025-03-10 16:35:09,226 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.301934166332798
2025-03-10 16:35:09,235 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0206261603598783
2025-03-10 16:35:09,245 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:09,258 - INFO - FONN3 Epoch 600:
2025-03-10 16:35:09,258 - INFO - Train MSE: 0.7231, Test MSE: 1.1452
2025-03-10 16:35:09,258 - INFO - Train R²: 0.2769, Test R²: -0.3566
2025-03-10 16:35:09,259 - INFO - Train MAE: 0.6406, Test MAE: 0.7947
2025-03-10 16:35:09,259 - INFO - Overfit ratio (train R² / test R²): -0.7765
Epoch 0, Loss: 2.0283083264575303
2025-03-10 16:35:09,269 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.886446098315426
2025-03-10 16:35:09,279 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.067421748147995
2025-03-10 16:35:09,289 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8951556005796126
2025-03-10 16:35:09,298 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9339371683907987
2025-03-10 16:35:09,308 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9402038721155488
2025-03-10 16:35:09,318 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.14113225439593
2025-03-10 16:35:09,328 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6556174562379984
2025-03-10 16:35:09,338 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6201958513699133
2025-03-10 16:35:09,348 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.248614940769961
2025-03-10 16:35:09,358 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.014646626780608
2025-03-10 16:35:09,368 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0147841224036576
2025-03-10 16:35:09,377 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2372095291824765
2025-03-10 16:35:09,387 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1254336881669027
2025-03-10 16:35:09,396 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.102968802285749
2025-03-10 16:35:09,406 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9644947500651475
2025-03-10 16:35:09,415 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.862688449374554
2025-03-10 16:35:09,427 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0954028189637324
2025-03-10 16:35:09,437 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8845716079080994
2025-03-10 16:35:09,447 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8827228454682137
2025-03-10 16:35:09,456 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.194151384770203
2025-03-10 16:35:09,466 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3458813222303467
2025-03-10 16:35:09,476 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2158315637449832
2025-03-10 16:35:09,487 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.029009146678526
2025-03-10 16:35:09,497 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.126963232732165
2025-03-10 16:35:09,507 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9116005286905065
2025-03-10 16:35:09,517 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9818556339538294
2025-03-10 16:35:09,527 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8854053572998017
2025-03-10 16:35:09,537 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.150283989115731
2025-03-10 16:35:09,547 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1356210264808806
2025-03-10 16:35:09,557 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8470328184956193
2025-03-10 16:35:09,567 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0731278587863926
2025-03-10 16:35:09,577 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.070220550028752
2025-03-10 16:35:09,586 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9405013234266781
2025-03-10 16:35:09,596 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.178706272844612
2025-03-10 16:35:09,605 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.346158863578128
2025-03-10 16:35:09,616 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3095220075766574
2025-03-10 16:35:09,625 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.09697927816933
2025-03-10 16:35:09,635 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.865749117164399
2025-03-10 16:35:09,645 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8973395729212794
2025-03-10 16:35:09,654 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0789268200032893
2025-03-10 16:35:09,664 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.266198796548688
2025-03-10 16:35:09,674 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9370155626055712
2025-03-10 16:35:09,685 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.907173627854965
2025-03-10 16:35:09,695 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8872496327929529
2025-03-10 16:35:09,710 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8210161387906278
2025-03-10 16:35:09,728 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.942363960452335
2025-03-10 16:35:09,746 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.950793284714258
2025-03-10 16:35:09,764 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2481850960075582
2025-03-10 16:35:09,781 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.031623481954531
2025-03-10 16:35:09,799 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.943884252637938
2025-03-10 16:35:09,816 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.825961884942854
2025-03-10 16:35:09,827 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9651510976030062
2025-03-10 16:35:09,838 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.660270130609856
2025-03-10 16:35:09,848 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8392546075144753
2025-03-10 16:35:09,858 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.224869222026915
2025-03-10 16:35:09,868 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9825201549253517
2025-03-10 16:35:09,878 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.321927592922137
2025-03-10 16:35:09,888 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6157473263149065
2025-03-10 16:35:09,898 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.164832030225285
2025-03-10 16:35:09,908 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8963193819123503
2025-03-10 16:35:09,917 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.799018627738603
2025-03-10 16:35:09,927 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2270886388532127
2025-03-10 16:35:09,937 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9199827592010903
2025-03-10 16:35:09,946 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8590874124561871
2025-03-10 16:35:09,956 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.817390078057913
2025-03-10 16:35:09,966 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0851870882071717
2025-03-10 16:35:09,975 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.774427915809193
2025-03-10 16:35:09,985 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1554845046382467
2025-03-10 16:35:09,994 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3845771610829987
2025-03-10 16:35:10,004 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2325979223093824
2025-03-10 16:35:10,014 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7941678313022584
2025-03-10 16:35:10,023 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8798538109023175
2025-03-10 16:35:10,033 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.823165815145342
2025-03-10 16:35:10,043 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7661648352255181
2025-03-10 16:35:10,053 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6645063967117373
2025-03-10 16:35:10,062 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9420473256803232
2025-03-10 16:35:10,072 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.976354887650193
2025-03-10 16:35:10,083 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0655911441141037
2025-03-10 16:35:10,092 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5878498472836466
2025-03-10 16:35:10,102 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.19419501140151
2025-03-10 16:35:10,111 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.126695425902083
2025-03-10 16:35:10,121 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3850747534860237
2025-03-10 16:35:10,131 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.533978069523569
2025-03-10 16:35:10,142 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7300479445404178
2025-03-10 16:35:10,152 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8522259586030185
2025-03-10 16:35:10,161 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8976634537770452
2025-03-10 16:35:10,171 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9680137190867164
2025-03-10 16:35:10,181 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.178755264648633
2025-03-10 16:35:10,191 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.123332371874712
2025-03-10 16:35:10,201 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.086198529483866
2025-03-10 16:35:10,211 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2179918338282976
2025-03-10 16:35:10,221 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5166347404067588
2025-03-10 16:35:10,233 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7065420853990736
2025-03-10 16:35:10,242 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0057454319357437
2025-03-10 16:35:10,252 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.187202623107412
2025-03-10 16:35:10,262 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7412768566533998
2025-03-10 16:35:10,271 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9789293938147878
2025-03-10 16:35:10,281 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7076485808636273
2025-03-10 16:35:10,291 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8304210549703273
2025-03-10 16:35:10,300 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:10,313 - INFO - FONN3 Epoch 700:
2025-03-10 16:35:10,314 - INFO - Train MSE: 0.6940, Test MSE: 1.1070
2025-03-10 16:35:10,314 - INFO - Train R²: 0.3060, Test R²: -0.3113
2025-03-10 16:35:10,314 - INFO - Train MAE: 0.6277, Test MAE: 0.7851
2025-03-10 16:35:10,314 - INFO - Overfit ratio (train R² / test R²): -0.9828
Epoch 0, Loss: 2.1167126538238805
2025-03-10 16:35:10,326 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8089658388098764
2025-03-10 16:35:10,336 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7570954494209727
2025-03-10 16:35:10,346 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1610562062536607
2025-03-10 16:35:10,356 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2444845914878555
2025-03-10 16:35:10,366 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1328915790552427
2025-03-10 16:35:10,376 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.045127148879487
2025-03-10 16:35:10,385 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8751184204827946
2025-03-10 16:35:10,395 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0275016900164773
2025-03-10 16:35:10,405 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3643713534311126
2025-03-10 16:35:10,415 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0274904659869364
2025-03-10 16:35:10,424 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6381455916985657
2025-03-10 16:35:10,434 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9842758768695996
2025-03-10 16:35:10,444 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1756861189744625
2025-03-10 16:35:10,453 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0419405247804745
2025-03-10 16:35:10,463 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3147767489337383
2025-03-10 16:35:10,473 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8094518469314742
2025-03-10 16:35:10,483 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.049013073211265
2025-03-10 16:35:10,492 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.067957724724382
2025-03-10 16:35:10,502 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.75647705651736
2025-03-10 16:35:10,512 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9246648811592337
2025-03-10 16:35:10,521 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9524208846452114
2025-03-10 16:35:10,531 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8175152307746716
2025-03-10 16:35:10,541 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1673108353217794
2025-03-10 16:35:10,551 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9161392413070721
2025-03-10 16:35:10,560 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0299934794486547
2025-03-10 16:35:10,570 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5217533157656766
2025-03-10 16:35:10,581 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7836235699618583
2025-03-10 16:35:10,592 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7200888212673016
2025-03-10 16:35:10,602 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1717760570385707
2025-03-10 16:35:10,612 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.201663291519365
2025-03-10 16:35:10,622 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.245418203642697
2025-03-10 16:35:10,633 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7738940525452358
2025-03-10 16:35:10,644 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9106928015287457
2025-03-10 16:35:10,653 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.128168119565247
2025-03-10 16:35:10,663 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1724606252354093
2025-03-10 16:35:10,672 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8309623458672881
2025-03-10 16:35:10,682 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.78891742462642
2025-03-10 16:35:10,692 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6599512064503892
2025-03-10 16:35:10,702 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.198672458500526
2025-03-10 16:35:10,712 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7352448725691316
2025-03-10 16:35:10,722 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8687088944285777
2025-03-10 16:35:10,731 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.156947038129989
2025-03-10 16:35:10,741 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9245591583557808
2025-03-10 16:35:10,751 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0777313325679576
2025-03-10 16:35:10,760 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0136977759316848
2025-03-10 16:35:10,769 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9400613759079244
2025-03-10 16:35:10,779 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6733424557713659
2025-03-10 16:35:10,789 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7269633815176664
2025-03-10 16:35:10,799 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.035767836855356
2025-03-10 16:35:10,808 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1300636426793824
2025-03-10 16:35:10,818 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9220444420220093
2025-03-10 16:35:10,828 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6413719671411344
2025-03-10 16:35:10,838 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6920782114740551
2025-03-10 16:35:10,847 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.819484335388885
2025-03-10 16:35:10,858 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.169986738263089
2025-03-10 16:35:10,867 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.719132962690383
2025-03-10 16:35:10,877 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9018186378589959
2025-03-10 16:35:10,887 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1590839340054333
2025-03-10 16:35:10,897 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.994316005567939
2025-03-10 16:35:10,906 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7922766852674556
2025-03-10 16:35:10,916 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9612441938068836
2025-03-10 16:35:10,925 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8034582523159042
2025-03-10 16:35:10,935 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9019388055292665
2025-03-10 16:35:10,946 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2607507012660943
2025-03-10 16:35:10,955 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9317437234381265
2025-03-10 16:35:10,965 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1777971039110686
2025-03-10 16:35:10,975 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.588508082875055
2025-03-10 16:35:10,985 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0533648198319594
2025-03-10 16:35:10,996 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2111367372010173
2025-03-10 16:35:11,006 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1851208523220227
2025-03-10 16:35:11,016 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7515604133598803
2025-03-10 16:35:11,026 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.837403196595544
2025-03-10 16:35:11,035 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6273657945381732
2025-03-10 16:35:11,045 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.117350623040924
2025-03-10 16:35:11,054 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.625994480373911
2025-03-10 16:35:11,064 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6939567343438597
2025-03-10 16:35:11,073 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6625776062050108
2025-03-10 16:35:11,083 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7933420578472863
2025-03-10 16:35:11,093 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.158672487885599
2025-03-10 16:35:11,102 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0898724534038444
2025-03-10 16:35:11,112 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9147042334285822
2025-03-10 16:35:11,122 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.901547302865772
2025-03-10 16:35:11,131 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1051338204822407
2025-03-10 16:35:11,141 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2659154477681516
2025-03-10 16:35:11,150 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.591410987235384
2025-03-10 16:35:11,160 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.336273741593593
2025-03-10 16:35:11,170 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.913993995303675
2025-03-10 16:35:11,179 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8327586660597424
2025-03-10 16:35:11,188 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8457164197023344
2025-03-10 16:35:11,198 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9931045515097858
2025-03-10 16:35:11,208 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7924459719486145
2025-03-10 16:35:11,217 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.833410765303569
2025-03-10 16:35:11,228 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1592727729320877
2025-03-10 16:35:11,239 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2441231898379397
2025-03-10 16:35:11,249 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.274784759778402
2025-03-10 16:35:11,259 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6660917248564504
2025-03-10 16:35:11,268 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1287736626271085
2025-03-10 16:35:11,278 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0054059525161176
2025-03-10 16:35:11,287 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.896534060230386
2025-03-10 16:35:11,297 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:11,310 - INFO - FONN3 Epoch 800:
2025-03-10 16:35:11,310 - INFO - Train MSE: 0.6816, Test MSE: 1.0891
2025-03-10 16:35:11,311 - INFO - Train R²: 0.3184, Test R²: -0.2902
2025-03-10 16:35:11,311 - INFO - Train MAE: 0.6235, Test MAE: 0.7830
2025-03-10 16:35:11,311 - INFO - Overfit ratio (train R² / test R²): -1.0974
Epoch 0, Loss: 2.1063875975990975
2025-03-10 16:35:11,321 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6237106449371779
2025-03-10 16:35:11,330 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.415964688259708
2025-03-10 16:35:11,340 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9403491768767178
2025-03-10 16:35:11,350 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7527833375708854
2025-03-10 16:35:11,360 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7845076278620693
2025-03-10 16:35:11,370 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.766945213101154
2025-03-10 16:35:11,379 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9736503668749092
2025-03-10 16:35:11,389 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8324259050849756
2025-03-10 16:35:11,398 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0550619255175273
2025-03-10 16:35:11,408 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.72367810393879
2025-03-10 16:35:11,417 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7758691856817703
2025-03-10 16:35:11,427 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7057712523182655
2025-03-10 16:35:11,437 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.676030584151643
2025-03-10 16:35:11,447 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.249380326175658
2025-03-10 16:35:11,456 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8586716886581245
2025-03-10 16:35:11,465 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9104249214368207
2025-03-10 16:35:11,475 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.970889407865357
2025-03-10 16:35:11,485 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.329932791143064
2025-03-10 16:35:11,494 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.953807962133045
2025-03-10 16:35:11,504 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.775184779538968
2025-03-10 16:35:11,513 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6930608432285112
2025-03-10 16:35:11,523 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7876510814729503
2025-03-10 16:35:11,532 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.998379500035824
2025-03-10 16:35:11,542 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9742427400191251
2025-03-10 16:35:11,552 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.790957868847585
2025-03-10 16:35:11,562 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5214122130445378
2025-03-10 16:35:11,572 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.029669317581628
2025-03-10 16:35:11,581 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9786200624093189
2025-03-10 16:35:11,591 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.825831605801949
2025-03-10 16:35:11,600 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7873712337592664
2025-03-10 16:35:11,610 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8763178752809535
2025-03-10 16:35:11,620 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.152287640366361
2025-03-10 16:35:11,629 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.542965951303595
2025-03-10 16:35:11,639 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1385901725624756
2025-03-10 16:35:11,649 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0789114249586556
2025-03-10 16:35:11,659 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6959747229901903
2025-03-10 16:35:11,668 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.140518489557358
2025-03-10 16:35:11,678 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7923767317519748
2025-03-10 16:35:11,688 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.785093433030463
2025-03-10 16:35:11,697 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9280534680268389
2025-03-10 16:35:11,707 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0127283812161862
2025-03-10 16:35:11,716 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9015939220833953
2025-03-10 16:35:11,726 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.939512042611581
2025-03-10 16:35:11,736 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.028317598862508
2025-03-10 16:35:11,746 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6729758707839661
2025-03-10 16:35:11,755 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7957481709193805
2025-03-10 16:35:11,765 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9970032064557934
2025-03-10 16:35:11,775 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7772962912551251
2025-03-10 16:35:11,785 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6640567087808023
2025-03-10 16:35:11,794 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8674863670341184
2025-03-10 16:35:11,804 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9670743936810562
2025-03-10 16:35:11,813 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.745678794727251
2025-03-10 16:35:11,823 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9738948399624112
2025-03-10 16:35:11,832 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.939539121550106
2025-03-10 16:35:11,841 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9096953809024397
2025-03-10 16:35:11,851 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.4137000291988144
2025-03-10 16:35:11,860 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.187060158124694
2025-03-10 16:35:11,869 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9091107056022902
2025-03-10 16:35:11,879 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.132518746320194
2025-03-10 16:35:11,888 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.963767969278985
2025-03-10 16:35:11,898 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.108387379908067
2025-03-10 16:35:11,908 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5268763016414053
2025-03-10 16:35:11,919 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8116717516114138
2025-03-10 16:35:11,928 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.120123299454945
2025-03-10 16:35:11,939 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2491294049462995
2025-03-10 16:35:11,949 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0541796251427242
2025-03-10 16:35:11,959 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8091482377351147
2025-03-10 16:35:11,969 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9719272431326273
2025-03-10 16:35:11,979 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5305601926983443
2025-03-10 16:35:11,989 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9704002750730318
2025-03-10 16:35:12,000 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.703737897378879
2025-03-10 16:35:12,010 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9486028542173706
2025-03-10 16:35:12,020 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.042377805514919
2025-03-10 16:35:12,031 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1259704162512536
2025-03-10 16:35:12,041 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.053998985836417
2025-03-10 16:35:12,052 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9565109034698458
2025-03-10 16:35:12,062 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8715407014055483
2025-03-10 16:35:12,072 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.123797566775214
2025-03-10 16:35:12,082 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9627705418087125
2025-03-10 16:35:12,091 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.943268488843732
2025-03-10 16:35:12,101 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.028600654121244
2025-03-10 16:35:12,111 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9887524185652135
2025-03-10 16:35:12,120 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.259366115225074
2025-03-10 16:35:12,130 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9091032878268939
2025-03-10 16:35:12,139 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0101104732756347
2025-03-10 16:35:12,149 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8919176981352681
2025-03-10 16:35:12,158 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6325445099288554
2025-03-10 16:35:12,168 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9175874056111477
2025-03-10 16:35:12,178 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8592283597272665
2025-03-10 16:35:12,188 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8004291606034863
2025-03-10 16:35:12,197 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1173376612211188
2025-03-10 16:35:12,207 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0095212213261213
2025-03-10 16:35:12,217 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8193034111132123
2025-03-10 16:35:12,226 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8780984620081498
2025-03-10 16:35:12,236 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2397868070750415
2025-03-10 16:35:12,246 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8789329988959311
2025-03-10 16:35:12,256 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.871540558424504
2025-03-10 16:35:12,265 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0407088023066975
2025-03-10 16:35:12,275 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.899249619134036
2025-03-10 16:35:12,285 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:12,298 - INFO - FONN3 Epoch 900:
2025-03-10 16:35:12,298 - INFO - Train MSE: 0.6701, Test MSE: 1.0712
2025-03-10 16:35:12,298 - INFO - Train R²: 0.3299, Test R²: -0.2689
2025-03-10 16:35:12,299 - INFO - Train MAE: 0.6195, Test MAE: 0.7804
2025-03-10 16:35:12,299 - INFO - Overfit ratio (train R² / test R²): -1.2266
Epoch 0, Loss: 2.2280097151366918
2025-03-10 16:35:12,309 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9708166321983742
2025-03-10 16:35:12,318 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0306282494377044
2025-03-10 16:35:12,328 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9575031477958331
2025-03-10 16:35:12,338 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.183413619961153
2025-03-10 16:35:12,347 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9747191195158103
2025-03-10 16:35:12,357 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8431465754435956
2025-03-10 16:35:12,367 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1464766644641147
2025-03-10 16:35:12,376 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7081082826787672
2025-03-10 16:35:12,386 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7659379070674492
2025-03-10 16:35:12,396 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9288055969800388
2025-03-10 16:35:12,405 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.100210299970542
2025-03-10 16:35:12,415 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.819740422013348
2025-03-10 16:35:12,424 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8927829224964277
2025-03-10 16:35:12,434 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.34806203316484
2025-03-10 16:35:12,443 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9615621919798019
2025-03-10 16:35:12,453 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.110738324346555
2025-03-10 16:35:12,463 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0060683215711044
2025-03-10 16:35:12,473 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2518067672481443
2025-03-10 16:35:12,483 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.860114116869508
2025-03-10 16:35:12,493 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2948269936608647
2025-03-10 16:35:12,502 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.183862010584558
2025-03-10 16:35:12,512 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.5765336797066523
2025-03-10 16:35:12,522 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7841494562829516
2025-03-10 16:35:12,531 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.220903401455113
2025-03-10 16:35:12,542 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3497967697502187
2025-03-10 16:35:12,551 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7672785888783438
2025-03-10 16:35:12,561 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6630306399770634
2025-03-10 16:35:12,571 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.137804745140579
2025-03-10 16:35:12,581 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.024344483715888
2025-03-10 16:35:12,590 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.205367738187818
2025-03-10 16:35:12,600 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0415112654827263
2025-03-10 16:35:12,610 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.827659490459385
2025-03-10 16:35:12,620 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8486914574567628
2025-03-10 16:35:12,630 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8994183943825866
2025-03-10 16:35:12,641 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9818964291985357
2025-03-10 16:35:12,651 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.982480952817999
2025-03-10 16:35:12,661 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7964748479993913
2025-03-10 16:35:12,671 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7888658386138052
2025-03-10 16:35:12,681 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0564005612279095
2025-03-10 16:35:12,691 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.456923370960789
2025-03-10 16:35:12,701 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9412523464467526
2025-03-10 16:35:12,711 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.6884008543706084
2025-03-10 16:35:12,721 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7818150834788313
2025-03-10 16:35:12,731 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.227703609580289
2025-03-10 16:35:12,741 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.764965137855693
2025-03-10 16:35:12,752 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.970691383745758
2025-03-10 16:35:12,762 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.223168628682182
2025-03-10 16:35:12,772 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8972704128049103
2025-03-10 16:35:12,782 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8863847295993847
2025-03-10 16:35:12,792 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8096493520788353
2025-03-10 16:35:12,802 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.031441592898806
2025-03-10 16:35:12,812 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7572940494323712
2025-03-10 16:35:12,822 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.364666269390792
2025-03-10 16:35:12,832 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7398336294619927
2025-03-10 16:35:12,842 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.077967208608211
2025-03-10 16:35:12,853 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9976266860697705
2025-03-10 16:35:12,863 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9586137533579213
2025-03-10 16:35:12,873 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8488138213564895
2025-03-10 16:35:12,884 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3163549750371986
2025-03-10 16:35:12,894 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.037324851241892
2025-03-10 16:35:12,904 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5297570378649872
2025-03-10 16:35:12,913 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7716479936881409
2025-03-10 16:35:12,923 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.3722735232219816
2025-03-10 16:35:12,932 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8246241084092063
2025-03-10 16:35:12,942 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.084090479099858
2025-03-10 16:35:12,952 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8480786001596219
2025-03-10 16:35:12,962 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7632268999046992
2025-03-10 16:35:12,971 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.59654939025411
2025-03-10 16:35:12,981 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7408190591198847
2025-03-10 16:35:12,991 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9075454916378245
2025-03-10 16:35:13,001 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.944000727126038
2025-03-10 16:35:13,011 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.947580276532006
2025-03-10 16:35:13,020 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.34128196396588
2025-03-10 16:35:13,030 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.850072146508218
2025-03-10 16:35:13,040 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0790774513779606
2025-03-10 16:35:13,050 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1188530460167936
2025-03-10 16:35:13,059 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.9860889458482205
2025-03-10 16:35:13,069 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7943306252507154
2025-03-10 16:35:13,079 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8373851802064174
2025-03-10 16:35:13,089 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0607172385527233
2025-03-10 16:35:13,098 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.715942643853144
2025-03-10 16:35:13,108 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8521814252101234
2025-03-10 16:35:13,118 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0413618007212593
2025-03-10 16:35:13,128 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.985071658088325
2025-03-10 16:35:13,138 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.2304043794017687
2025-03-10 16:35:13,147 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1875399812426797
2025-03-10 16:35:13,157 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7993758578147734
2025-03-10 16:35:13,167 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.1199990920220824
2025-03-10 16:35:13,176 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.059499178170711
2025-03-10 16:35:13,186 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.027862894876691
2025-03-10 16:35:13,195 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8337033062543862
2025-03-10 16:35:13,205 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.109465220222837
2025-03-10 16:35:13,215 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8006924707511562
2025-03-10 16:35:13,225 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.5438399803660185
2025-03-10 16:35:13,234 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 2.0264723621789225
2025-03-10 16:35:13,244 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.799166803447634
2025-03-10 16:35:13,254 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.7565162507118273
2025-03-10 16:35:13,264 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
Epoch 0, Loss: 1.8406180078749759
2025-03-10 16:35:13,273 - INFO - Skipping tree regularization for FONN3 - feature_importances_ is read-only
2025-03-10 16:35:13,287 - INFO - FONN3 Epoch 999:
2025-03-10 16:35:13,287 - INFO - Train MSE: 0.6692, Test MSE: 1.0660
2025-03-10 16:35:13,287 - INFO - Train R²: 0.3308, Test R²: -0.2628
2025-03-10 16:35:13,287 - INFO - Train MAE: 0.6203, Test MAE: 0.7836
2025-03-10 16:35:13,287 - INFO - Overfit ratio (train R² / test R²): -1.2588
2025-03-10 16:35:13,300 - INFO -
FONN3 Final Metrics:
2025-03-10 16:35:13,301 - INFO - R² Score: -0.2628
2025-03-10 16:35:13,301 - INFO - MAE: 0.7836
2025-03-10 16:35:13,301 - INFO - MSE: 1.0660
2025-03-10 16:35:13,301 - INFO - Train R²: 0.3308
2025-03-10 16:35:13,301 - INFO - Overfit Ratio: inf
2025-03-10 16:35:13,301 - INFO - FONN3 evaluation successful!
2025-03-10 16:35:13,301 - INFO -
Evaluating baseline MLP...
2025-03-10 16:35:13,302 - INFO - Starting PureMLP training...
2025-03-10 16:35:13,302 - INFO - PureMLP with L2 regularization (alpha=0.001)
2025-03-10 16:35:13,302 - INFO - Applying dropout with rate 0.2 to MLP input
2025-03-10 16:35:13,311 - INFO - Fitting PureMLP...
Iteration 1, loss = 0.32628115
Iteration 2, loss = 0.17459205
Iteration 3, loss = 0.14105450
Iteration 4, loss = 0.11509161
Iteration 5, loss = 0.10095852
Iteration 6, loss = 0.09259336
Iteration 7, loss = 0.08393790
Iteration 8, loss = 0.08562850
Iteration 9, loss = 0.07532574
Iteration 10, loss = 0.07238272
Iteration 11, loss = 0.06720108
Iteration 12, loss = 0.06219678
Iteration 13, loss = 0.06429212
Iteration 14, loss = 0.05808003
Iteration 15, loss = 0.05747014
Iteration 16, loss = 0.05128305
Iteration 17, loss = 0.04659037
Iteration 18, loss = 0.04751348
Iteration 19, loss = 0.04554541
Iteration 20, loss = 0.05030078
Iteration 21, loss = 0.04997406
Iteration 22, loss = 0.04523821
Iteration 23, loss = 0.03996921
Iteration 24, loss = 0.03739838
Iteration 25, loss = 0.03530335
Iteration 26, loss = 0.03230694
Iteration 27, loss = 0.03298552
Iteration 28, loss = 0.03091271
Iteration 29, loss = 0.03377391
Iteration 30, loss = 0.03367424
Iteration 31, loss = 0.03623895
Iteration 32, loss = 0.03361138
Iteration 33, loss = 0.03597569
Iteration 34, loss = 0.02634180
Iteration 35, loss = 0.03101585
Iteration 36, loss = 0.02674136
Iteration 37, loss = 0.02888593
Iteration 38, loss = 0.03123893
Iteration 39, loss = 0.02920983
Iteration 40, loss = 0.03020446
Iteration 41, loss = 0.02294307
Iteration 42, loss = 0.02304185
Iteration 43, loss = 0.02486036
Iteration 44, loss = 0.02352720
Iteration 45, loss = 0.02330041
Iteration 46, loss = 0.02207039
Iteration 47, loss = 0.02273880
Iteration 48, loss = 0.02408255
Iteration 49, loss = 0.02654332
Iteration 50, loss = 0.02587694
Iteration 51, loss = 0.03151464
Iteration 52, loss = 0.03605663
Iteration 53, loss = 0.03385556
Iteration 54, loss = 0.02971717
Iteration 55, loss = 0.02238888
Iteration 56, loss = 0.02007446
Iteration 57, loss = 0.01714662
Iteration 58, loss = 0.02093383
Iteration 59, loss = 0.01830665
Iteration 60, loss = 0.01466906
Iteration 61, loss = 0.01376663
Iteration 62, loss = 0.01561126
Iteration 63, loss = 0.01679084
Iteration 64, loss = 0.01536133
Iteration 65, loss = 0.01987123
Iteration 66, loss = 0.02066173
Iteration 67, loss = 0.02038300
Iteration 68, loss = 0.01876503
Iteration 69, loss = 0.01874803
Iteration 70, loss = 0.01679769
Iteration 71, loss = 0.01758534
Iteration 72, loss = 0.01452660
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
2025-03-10 16:35:14,099 - INFO - PureMLP Training R² Score: 0.8534
2025-03-10 16:35:14,099 - INFO - PureMLP Test R² Score: 0.7387
2025-03-10 16:35:14,099 - INFO - PureMLP Overfit Ratio: 1.1552
2025-03-10 16:35:14,102 - INFO -
Results summary:
     Model  R² Score       MAE       MSE   Time (s)  Epochs  Final LR  Train R²  Overfit Ratio
0  TREENN1  0.658402  0.361097  0.288358   5.275275    1000     0.010  0.814453       1.237014
1  TREENN2  0.752561  0.297482  0.208874   5.976077    1000     0.010  0.828585       1.101020
2  TREENN3  0.710897  0.318014  0.244045   4.908105    1000     0.010  0.849051       1.194338
3    FONN1  0.802291  0.291644  0.166895  10.371667    1000     0.010  0.859623       1.071460
4    FONN2  0.787853  0.275775  0.179083   9.705579    1000     0.010  0.838580       1.064386
5    FONN3 -0.262760  0.783566  1.065953  10.219636    1000     0.001  0.330756            inf
6  PureMLP  0.738707  0.275439  0.220569   0.797914    1000     0.010  0.853382       1.155238
