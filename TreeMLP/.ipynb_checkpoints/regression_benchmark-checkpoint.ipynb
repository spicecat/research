{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsf3KDMkBnJJ"
      },
      "source": [
        "# OpenML-CTR23 Regression Benchmark\n",
        "\n",
        "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9ZbqI_CAHx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm1ejpmI6RFJ"
      },
      "outputs": [],
      "source": [
        "# %pip install -Uq pip black blackcellmagic scikit-learn openml optuna pandas jupyter ipywidgets nbformat setuptools\n",
        "# %load_ext blackcellmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GT0rGO7CByh"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIDiz21W9Hgm"
      },
      "outputs": [],
      "source": [
        "# Control Models\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "models = {\n",
        "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
        "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
        "    \"LR\": LinearRegression(),\n",
        "    \"MLP\": MLPRegressor(solver=\"sgd\", random_state=SEED),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-5NQvgi9HqO"
      },
      "outputs": [],
      "source": [
        "# Test Models\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class ForestMLPRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_trees=5,\n",
        "        trees_max_depth=3,\n",
        "        final_estimator=MLPRegressor(),\n",
        "        final_estimator__hidden_layer_sizes=100,\n",
        "        random_state=0,\n",
        "    ):\n",
        "        self.n_trees = n_trees\n",
        "        self.trees_max_depth = trees_max_depth\n",
        "        self.final_estimator = final_estimator\n",
        "        self.final_estimator__hidden_layer_sizes = final_estimator__hidden_layer_sizes\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _make_stacking(self):\n",
        "        return StackingRegressor(\n",
        "            estimators=[\n",
        "                (\n",
        "                    f\"tree_{i}\",\n",
        "                    DecisionTreeRegressor(\n",
        "                        max_depth=self.trees_max_depth,\n",
        "                        random_state=self.random_state + i,\n",
        "                    ),\n",
        "                )\n",
        "                for i in range(self.n_trees)\n",
        "            ],\n",
        "            final_estimator=clone(self.final_estimator).set_params(\n",
        "                hidden_layer_sizes=self.final_estimator__hidden_layer_sizes,\n",
        "            ),\n",
        "            passthrough=True,\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_ = self._make_stacking()\n",
        "        self.model_.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "\n",
        "test_models = {\n",
        "    \"TreeMLP\": StackingRegressor(\n",
        "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
        "        final_estimator=models[\"MLP\"],\n",
        "        passthrough=True,\n",
        "    ),\n",
        "    \"ForestMLP\": ForestMLPRegressor(final_estimator=models[\"MLP\"], random_state=SEED),\n",
        "}\n",
        "\n",
        "models.update(test_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9grQGt7BCJOg"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsmnhtRu9Hzp"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import numpy as np\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    [\n",
        "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"numeric_scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\n",
        "            \"categorical_encoder\",\n",
        "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "preprocessor = make_column_transformer(\n",
        "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
        "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
        "    sparse_threshold=0.0,\n",
        ")\n",
        "\n",
        "models = {\n",
        "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
        "    for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjW8qkdTCKTB"
      },
      "source": [
        "### Hyperparameter Optimization Configuration and Space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve1gazIt9H9A"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Space\n",
        "hpo_spaces = {\n",
        "    \"Dummy\": {},\n",
        "    \"RF\": {\n",
        "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 20}),\n",
        "    },\n",
        "    \"LR\": {},\n",
        "    \"MLP\": {\n",
        "        \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"TreeMLP\": {\n",
        "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"ForestMLP\": {\n",
        "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 10}),\n",
        "        \"trees_max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "}\n",
        "\n",
        "models = {\n",
        "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvYcl3Fl9IEt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Configuration\n",
        "import optuna\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Study configuration\n",
        "hpo_config = {\n",
        "    \"n_trials\": 3,\n",
        "    \"timeout\": None,\n",
        "    \"show_progress_bar\": True,\n",
        "}\n",
        "\n",
        "# Cross-validation parameters for HPO objective function\n",
        "objective_cv_params = {\"cv\": 5, \"scoring\": \"neg_mean_squared_error\"}\n",
        "\n",
        "\n",
        "def create_objective(model, hpo_space, X, y):\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        param_type_map = {\n",
        "            \"int\": trial.suggest_int,\n",
        "            \"float\": trial.suggest_float,\n",
        "            \"categorical\": trial.suggest_categorical,\n",
        "        }\n",
        "        params = {\n",
        "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
        "            for p, (typ, kw) in hpo_space.items()\n",
        "        }\n",
        "        model.set_params(**params)\n",
        "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
        "\n",
        "    return objective\n",
        "\n",
        "\n",
        "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
        "    def __init__(self, model, hpo_space):\n",
        "        self.model = model\n",
        "        self.hpo_space = hpo_space\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        model = clone(self.model)\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "        study.optimize(\n",
        "            create_objective(model, self.hpo_space, X, y),\n",
        "            **hpo_config,\n",
        "        )\n",
        "        model.set_params(**study.best_params)\n",
        "        self.fitted_model_ = model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.fitted_model_.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ge2W26CNXp"
      },
      "source": [
        "## Define Benchmark Suite and Tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNEd-zKK9PUu"
      },
      "outputs": [],
      "source": [
        "# Define Benchmark Suite\n",
        "import openml\n",
        "from IPython.display import display\n",
        "\n",
        "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
        "suite = openml.study.get_suite(SUITE_ID)\n",
        "display(suite)\n",
        "print(suite.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyya8O9Q9Qld"
      },
      "outputs": [],
      "source": [
        "# Download tasks from the suite\n",
        "N_TASKS = 2\n",
        "tasks = openml.tasks.get_tasks(\n",
        "    (suite.tasks or [])[:N_TASKS], download_data=True, download_qualities=True\n",
        ")\n",
        "display(tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op3VR4BlCPkQ"
      },
      "source": [
        "### Benchmarking Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vepYJIxW9R8S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "cv_params = {\n",
        "    \"scoring\": [\"neg_mean_squared_error\", \"r2\"],\n",
        "    \"return_train_score\": True,\n",
        "}\n",
        "\n",
        "runs = {}\n",
        "\n",
        "for task in tasks:\n",
        "    model_results = {}\n",
        "    splits = task.download_split().split\n",
        "    X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"Running {model_name=} on {task.id=}...\")\n",
        "        run = cross_validate(\n",
        "            TemplateRegressor(*model),\n",
        "            X,\n",
        "            y,\n",
        "            cv=[s[0] for s in splits[0].values()],  # Using pre-defined OpenML splits\n",
        "            **cv_params,\n",
        "        )\n",
        "        model_results[model_name] = pd.DataFrame(run).mean(axis=0)\n",
        "    runs[task.id] = model_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAN_GWXWCRKY"
      },
      "source": [
        "### Aggregate Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eeK8Sc49TM1"
      },
      "outputs": [],
      "source": [
        "# Aggregate Results\n",
        "import pandas as pd\n",
        "\n",
        "runs_df = pd.DataFrame(runs)\n",
        "metrics = cv_params[\"scoring\"]\n",
        "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
        "for metric in metrics:\n",
        "    metrics_df[metric] = (\n",
        "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
        "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
        "    )\n",
        "\n",
        "    # Use first metric for ranking\n",
        "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
        "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
        "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
        "\n",
        "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
        "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
        "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
        "\n",
        "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
        "\n",
        "# Display all metrics and ranks\n",
        "for metric, (test, train) in metrics_df.items():\n",
        "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn2J6VVC85Ba"
      },
      "outputs": [],
      "source": [
        "# # Single model evaluation\n",
        "# from sklearn.model_selection import cross_validate\n",
        "\n",
        "# task = tasks[0]\n",
        "# splits = task.download_split().split\n",
        "# X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "# model = TemplateRegressor(*models[\"ForestMLP\"])\n",
        "# run = cross_validate(\n",
        "#     model,\n",
        "#     X,\n",
        "#     y,\n",
        "#     cv=[s[0] for s in splits[0].values()][:3],  # Using pre-defined OpenML splits\n",
        "#     **cv_params,\n",
        "# )\n",
        "# display(pd.DataFrame(run).mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
