{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036f6610",
   "metadata": {},
   "source": [
    "# OpenML Regression Benchmark 2025\n",
    "\n",
    "This notebook benchmarks a **custom Decision Trees → MLP architecture** against several standard scikit‑learn regressors on every dataset in the **`New_OpenML_Suite_2025_regression`**.\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook outline\n",
    "\n",
    "1. **Setup** – install/import libraries\n",
    "2. **Configuration** – constants & hyper‑parameters\n",
    "3. **Custom Model Definition** – placeholder implementation\n",
    "4. **Helper Functions** – preprocessing & evaluation utilities\n",
    "5. **Benchmark Loop** – iterate over datasets and models, log to Weights & Biases\n",
    "6. **Results Summary** – aggregate and visualise results\n",
    "\n",
    "> **Tip:** Sections flagged with `TODO` are hooks for deeper customisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc12b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mspicecat\u001b[0m (\u001b[33mspicecat-club\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# ---- Setup --------------------------------------------------------------\n",
    "%pip install openml wandb scikit-learn pandas nbformat numpy --quiet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.metrics import (make_scorer, r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Authenticate W&B (expects environment variable or local API key)\n",
    "wandb.login()\n",
    "import copy\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcb3284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alias",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "main_entity_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creator",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "22f48fb7-f2df-4736-8cfd-477837b0eedb",
       "rows": [
        [
         "14",
         "14",
         "OpenML100",
         "task",
         "Collaborative, reproducible benchmarking and analysis",
         "in_preparation",
         "2019-02-21 18:40:13",
         "1"
        ],
        [
         "99",
         "99",
         "OpenML-CC18",
         "task",
         "OpenML-CC18 Curated Classification benchmark",
         "active",
         "2019-02-21 18:47:13",
         "1"
        ],
        [
         "218",
         "218",
         "AutoML-Benchmark",
         "task",
         "AutoML Benchmark",
         "in_preparation",
         "2019-05-02 13:35:08",
         "869"
        ],
        [
         "219",
         "219",
         "FOREX",
         "task",
         "Forex",
         "in_preparation",
         "2019-06-04 00:45:17",
         "1"
        ],
        [
         "225",
         "225",
         "OpenML-friendly",
         "task",
         "OpenML100-friendly",
         "active",
         "2019-09-16 19:41:46",
         "1"
        ],
        [
         "236",
         "236",
         "a9ee1f0b2a4b48b6b6da1653fe92890e",
         "task",
         "Item Response Theory for Classification problems",
         "in_preparation",
         "2020-04-06 21:38:55",
         "64"
        ],
        [
         "239",
         "239",
         "c638a5d3d31241179f9b4853951fdb79",
         "task",
         "Item Response Theory for Regression problems",
         "in_preparation",
         "2020-04-19 22:15:30",
         "64"
        ],
        [
         "240",
         "240",
         "e5e7f56c8655433eb2418c240ec8b8c0",
         "task",
         "InvestigatingDL",
         "in_preparation",
         "2020-04-28 02:30:38",
         "2902"
        ],
        [
         "253",
         "253",
         "testecc18",
         "task",
         "TesteCC18",
         "in_preparation",
         "2020-09-01 00:57:54",
         "8598"
        ],
        [
         "258",
         "258",
         null,
         "task",
         "CC18NewBenchmark",
         "in_preparation",
         "2020-09-30 08:30:00",
         "8598"
        ],
        [
         "268",
         "268",
         null,
         "task",
         "New benchmark",
         "in_preparation",
         "2020-10-06 17:40:23",
         "8598"
        ],
        [
         "269",
         "269",
         "amlb-regression",
         "task",
         "AutoML Benchmark Regression",
         "in_preparation",
         "2020-11-19 18:28:48",
         "869"
        ],
        [
         "270",
         "270",
         "amlb-classification-more",
         "task",
         "AutoML Benchmark More Classification",
         "in_preparation",
         "2020-11-19 20:40:18",
         "869"
        ],
        [
         "271",
         "271",
         "amlb-classification-all",
         "task",
         "AutoML Benchmark All Classification",
         "in_preparation",
         "2020-11-19 20:52:19",
         "869"
        ],
        [
         "274",
         "274",
         null,
         "task",
         "MidSize Suite",
         "in_preparation",
         "2021-06-15 13:25:59",
         "25914"
        ],
        [
         "280",
         "280",
         "eb6cfe788cd3408688b9820c471ba45e",
         "task",
         "Test-Suite",
         "in_preparation",
         "2022-03-13 17:57:52",
         "29614"
        ],
        [
         "281",
         "281",
         "d51eeda67d0641e492b3884b28b9eda2",
         "task",
         "Test-Suite",
         "in_preparation",
         "2022-03-13 18:03:39",
         "29614"
        ],
        [
         "282",
         "282",
         "fa4a0c5bf0f948438b39fc2b990af06e",
         "task",
         "Test-Suite",
         "in_preparation",
         "2022-03-13 18:06:11",
         "29614"
        ],
        [
         "283",
         "283",
         null,
         "task",
         "MidSize Suite",
         "in_preparation",
         "2022-03-16 22:36:06",
         "29614"
        ],
        [
         "284",
         "284",
         null,
         "task",
         "MidSize Suite",
         "in_preparation",
         "2022-03-16 22:46:24",
         "29614"
        ],
        [
         "285",
         "285",
         null,
         "task",
         "Cardoso-50pc",
         "in_preparation",
         "2022-03-17 12:18:05",
         "29614"
        ],
        [
         "293",
         "293",
         "AutoML-Benchmark-Train",
         "task",
         "AutoML Benchmark Training Datasets",
         "in_preparation",
         "2022-04-21 17:24:13",
         "86"
        ],
        [
         "297",
         "297",
         null,
         "task",
         "Tabular benchmark numerical regression",
         "in_preparation",
         "2022-07-10 10:45:09",
         "26324"
        ],
        [
         "298",
         "298",
         null,
         "task",
         "Tabular benchmark numerical classification",
         "in_preparation",
         "2022-07-10 11:00:56",
         "26324"
        ],
        [
         "299",
         "299",
         null,
         "task",
         "Tabular benchmark categorical regression",
         "in_preparation",
         "2022-07-10 11:05:19",
         "26324"
        ],
        [
         "300",
         "300",
         null,
         "task",
         "Tabular benchmark categorical classification",
         "in_preparation",
         "2022-07-12 18:58:05",
         "26324"
        ],
        [
         "304",
         "304",
         null,
         "task",
         "Tabular benchmark categorical classification",
         "in_preparation",
         "2022-07-25 08:22:21",
         "26324"
        ],
        [
         "308",
         "308",
         "d58338ee137242ef8bd807b0295a2916",
         "task",
         "2",
         "in_preparation",
         "2022-11-19 06:56:39",
         "31244"
        ],
        [
         "309",
         "309",
         "8217f7baa2b84a93ba8b3e35c5ed77ff",
         "task",
         "2",
         "in_preparation",
         "2022-11-19 06:56:40",
         "31244"
        ],
        [
         "310",
         "310",
         "42ad071307e64d45ad4531c7a07b176d",
         "task",
         "2",
         "in_preparation",
         "2022-11-19 06:56:43",
         "31244"
        ],
        [
         "311",
         "311",
         "55e36879b4a5441183537822f0ccbce5",
         "task",
         "2",
         "in_preparation",
         "2022-11-19 06:56:43",
         "31244"
        ],
        [
         "315",
         "315",
         "Meta-Album_Micro_2022",
         "task",
         "Meta-Album Benchmark - Micro 2022",
         "in_preparation",
         "2022-12-07 23:54:59",
         "2"
        ],
        [
         "317",
         "317",
         "Meta-Album_Mini_2022",
         "task",
         "Meta-Album Benchmark - Mini 2022",
         "in_preparation",
         "2022-12-08 00:05:08",
         "2"
        ],
        [
         "318",
         "318",
         "Meta-Album_Extended_2022",
         "task",
         "Meta-Album Benchmark - Extended 2022",
         "in_preparation",
         "2022-12-08 00:08:50",
         "2"
        ],
        [
         "334",
         "334",
         null,
         "task",
         "Tabular benchmark categorical classification",
         "in_preparation",
         "2023-01-16 03:22:41",
         "26324"
        ],
        [
         "335",
         "335",
         null,
         "task",
         "Tabular benchmark categorical regression",
         "in_preparation",
         "2023-01-16 03:40:57",
         "26324"
        ],
        [
         "336",
         "336",
         null,
         "task",
         "Tabular benchmark numerical regression",
         "in_preparation",
         "2023-01-16 03:42:12",
         "26324"
        ],
        [
         "337",
         "337",
         null,
         "task",
         "Tabular benchmark numerical classification",
         "in_preparation",
         "2023-01-16 03:45:23",
         "26324"
        ],
        [
         "338",
         "338",
         "e5b9af3082f240b1be365cb62d1eb3cb",
         "task",
         "Test Collection",
         "in_preparation",
         "2023-01-17 06:11:26",
         "31892"
        ],
        [
         "339",
         "339",
         "31e7a27cf5ba4024836078a183293d1a",
         "task",
         "Test Collection",
         "in_preparation",
         "2023-01-17 06:11:31",
         "31892"
        ],
        [
         "340",
         "340",
         null,
         "task",
         "SSLC Benchmark Suite",
         "in_preparation",
         "2023-01-29 12:03:27",
         "31892"
        ],
        [
         "341",
         "341",
         "STCC",
         "task",
         "STCC Classificaton Benchmark",
         "in_preparation",
         "2023-02-01 09:55:43",
         "31892"
        ],
        [
         "342",
         "342",
         "d07f616196f44f7088e6ef4c2b05bdc6",
         "task",
         "TuningTreesClassification",
         "in_preparation",
         "2023-05-10 12:56:03",
         "35616"
        ],
        [
         "343",
         "343",
         "234d3c18df0d4f7ea1a873efa7bb40fc",
         "task",
         "Tuning Trees Classification",
         "in_preparation",
         "2023-05-10 12:56:11",
         "35616"
        ],
        [
         "344",
         "344",
         "cdfab46ebf7e4716aa21ac67e54a77cc",
         "task",
         "TuningTreesClassification",
         "in_preparation",
         "2023-05-10 12:59:50",
         "35616"
        ],
        [
         "345",
         "345",
         "0292c76c72b943c6914c61714a80c4af",
         "task",
         "TuningTreesClassification",
         "in_preparation",
         "2023-05-10 12:59:58",
         "35616"
        ],
        [
         "346",
         "346",
         "0cfed93e38be4b8e98c2438b07366572",
         "task",
         "A large-scale comparison of regression algorithms",
         "in_preparation",
         "2023-05-10 13:06:34",
         "35616"
        ],
        [
         "353",
         "353",
         "8f0ea660163b436bbd4abd49665c7b1d",
         "task",
         "OpenML-CTR23 - A curated tabular regression benchmarking suite",
         "active",
         "2023-05-31 16:39:49",
         "30127"
        ],
        [
         "366",
         "366",
         "657422f6af1747d4ae9eaf55229c7f06",
         "task",
         "digital_text",
         "in_preparation",
         "2023-06-05 08:49:21",
         "36095"
        ],
        [
         "367",
         "367",
         "5724ed506dcc4fb89f1ae8617c0c7a03",
         "task",
         "digital_text",
         "in_preparation",
         "2023-06-05 08:49:24",
         "36095"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 105
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alias</th>\n",
       "      <th>main_entity_type</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>OpenML100</td>\n",
       "      <td>task</td>\n",
       "      <td>Collaborative, reproducible benchmarking and a...</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-02-21 18:40:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>OpenML-CC18</td>\n",
       "      <td>task</td>\n",
       "      <td>OpenML-CC18 Curated Classification benchmark</td>\n",
       "      <td>active</td>\n",
       "      <td>2019-02-21 18:47:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>AutoML-Benchmark</td>\n",
       "      <td>task</td>\n",
       "      <td>AutoML Benchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-05-02 13:35:08</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>FOREX</td>\n",
       "      <td>task</td>\n",
       "      <td>Forex</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-06-04 00:45:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>OpenML-friendly</td>\n",
       "      <td>task</td>\n",
       "      <td>OpenML100-friendly</td>\n",
       "      <td>active</td>\n",
       "      <td>2019-09-16 19:41:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>f1f014076bfc49aaaa655f22efd10c18</td>\n",
       "      <td>task</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2025-03-12 07:47:56</td>\n",
       "      <td>48020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>db9adbe551614b1480abda01689ca6fd</td>\n",
       "      <td>task</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2025-03-12 07:47:57</td>\n",
       "      <td>48020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>ffbe01c051554f0ab15fede1dec6f63f</td>\n",
       "      <td>task</td>\n",
       "      <td>Meta AutoML Benchmark Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2025-03-14 19:30:38</td>\n",
       "      <td>38009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>classification_2025_March_1</td>\n",
       "      <td>task</td>\n",
       "      <td>New_OpenML_Suite_2025_classification</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2025-03-17 11:27:55</td>\n",
       "      <td>25914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>regression_2025_March_1</td>\n",
       "      <td>task</td>\n",
       "      <td>New_OpenML_Suite_2025_regression</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2025-03-17 11:33:22</td>\n",
       "      <td>25914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             alias main_entity_type  \\\n",
       "14    14                         OpenML100             task   \n",
       "99    99                       OpenML-CC18             task   \n",
       "218  218                  AutoML-Benchmark             task   \n",
       "219  219                             FOREX             task   \n",
       "225  225                   OpenML-friendly             task   \n",
       "..   ...                               ...              ...   \n",
       "451  451  f1f014076bfc49aaaa655f22efd10c18             task   \n",
       "452  452  db9adbe551614b1480abda01689ca6fd             task   \n",
       "453  453  ffbe01c051554f0ab15fede1dec6f63f             task   \n",
       "454  454       classification_2025_March_1             task   \n",
       "455  455           regression_2025_March_1             task   \n",
       "\n",
       "                                                  name          status  \\\n",
       "14   Collaborative, reproducible benchmarking and a...  in_preparation   \n",
       "99        OpenML-CC18 Curated Classification benchmark          active   \n",
       "218                                   AutoML Benchmark  in_preparation   \n",
       "219                                              Forex  in_preparation   \n",
       "225                                 OpenML100-friendly          active   \n",
       "..                                                 ...             ...   \n",
       "451                                          Benchmark  in_preparation   \n",
       "452                                          Benchmark  in_preparation   \n",
       "453                        Meta AutoML Benchmark Suite  in_preparation   \n",
       "454               New_OpenML_Suite_2025_classification  in_preparation   \n",
       "455                   New_OpenML_Suite_2025_regression  in_preparation   \n",
       "\n",
       "           creation_date  creator  \n",
       "14   2019-02-21 18:40:13        1  \n",
       "99   2019-02-21 18:47:13        1  \n",
       "218  2019-05-02 13:35:08      869  \n",
       "219  2019-06-04 00:45:17        1  \n",
       "225  2019-09-16 19:41:46        1  \n",
       "..                   ...      ...  \n",
       "451  2025-03-12 07:47:56    48020  \n",
       "452  2025-03-12 07:47:57    48020  \n",
       "453  2025-03-14 19:30:38    38009  \n",
       "454  2025-03-17 11:27:55    25914  \n",
       "455  2025-03-17 11:33:22    25914  \n",
       "\n",
       "[105 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suites = openml.study.list_suites(output_format=\"dataframe\", status=\"all\")\n",
    "display(suites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e53fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ------------------------------------------------------\n",
    "SUITE_NAME = (\n",
    "    \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
    ")\n",
    "WANDB_PROJECT = \"OpenML_Regression_Benchmark_2025\"\n",
    "CV_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Scoring dictionary (positive = higher is better)\n",
    "scoring = {\n",
    "    \"r2\": make_scorer(r2_score),\n",
    "    \"mae\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"rmse\": make_scorer(\n",
    "        lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        greater_is_better=False,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Baseline models\n",
    "baseline_models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    # \"Ridge\": Ridge(random_state=RANDOM_STATE),\n",
    "    # \"Lasso\": Lasso(random_state=RANDOM_STATE),\n",
    "    # \"SVR\": SVR(),\n",
    "    # \"RandomForestRegressor\": RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    # \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "    \"MLPRegressor\": MLPRegressor(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Placeholder for our custom architecture (defined next)\n",
    "from typing import Optional, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b694228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Custom DecisionTree→MLP Model -------------------------------------\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "class TreeMLPRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"A simple tree feature extractor followed by an MLP regressor.\n",
    "\n",
    "    Stage 1: Train `n_trees` individual `DecisionTreeRegressor`s (or a RandomForest).\n",
    "    Stage 2: For each sample, produce one‑hot encoded leaf indices per tree.\n",
    "    Stage 3: Concatenate original X with tree‑encoded features → feed to an MLP.\n",
    "\n",
    "    Note: This is a minimal, *illustrative* implementation. Optimizations such\n",
    "    as sparse handling, batching, or GPU acceleration are omitted for clarity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_trees: int = 10,\n",
    "        tree_max_depth: Optional[int] = None,\n",
    "        mlp_hidden_layer_sizes: Iterable[int] = (100,),\n",
    "        mlp_max_iter: int = 200,\n",
    "        random_state: Optional[int] = None,\n",
    "    ):\n",
    "        self.n_trees = n_trees\n",
    "        self.tree_max_depth = tree_max_depth\n",
    "        self.mlp_hidden_layer_sizes = tuple(mlp_hidden_layer_sizes)\n",
    "        self.mlp_max_iter = mlp_max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    # --------------------------- Fit ------------------------------------\n",
    "    def fit(self, X, y):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        # Stage 1 – train independent Decision Trees\n",
    "        self.trees_ = []\n",
    "        for i in range(self.n_trees):\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.tree_max_depth,\n",
    "                random_state=rng.randint(0, 1_000_000),\n",
    "            )\n",
    "            tree.fit(X, y)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        # Stage 2 – compute leaf indices for training data\n",
    "        leaf_indices = [tree.apply(X).reshape(-1, 1) for tree in self.trees_]\n",
    "        leaf_indices = np.hstack(leaf_indices)\n",
    "\n",
    "        # One‑hot encode leaf indices\n",
    "        self.ohe_ = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "        leaf_ohe = self.ohe_.fit_transform(leaf_indices)\n",
    "\n",
    "        # Combine original features with tree features\n",
    "        if sparse.issparse(leaf_ohe):\n",
    "            X_aug = sparse.hstack([sparse.csr_matrix(X), leaf_ohe]).tocsr()\n",
    "        else:\n",
    "            X_aug = np.hstack([X, leaf_ohe])\n",
    "\n",
    "        # Stage 3 – train the downstream MLP\n",
    "        self.mlp_ = MLPRegressor(\n",
    "            hidden_layer_sizes=self.mlp_hidden_layer_sizes,\n",
    "            max_iter=self.mlp_max_iter,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        self.mlp_.fit(X_aug, y)\n",
    "        return self\n",
    "\n",
    "    # ------------------------ Predict -----------------------------------\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, [\"trees_\", \"ohe_\", \"mlp_\"])\n",
    "        leaf_indices = np.hstack([tree.apply(X).reshape(-1, 1) for tree in self.trees_])\n",
    "        leaf_ohe = self.ohe_.transform(leaf_indices)\n",
    "\n",
    "        if sparse.issparse(leaf_ohe):\n",
    "            X_aug = sparse.hstack([sparse.csr_matrix(X), leaf_ohe]).tocsr()\n",
    "        else:\n",
    "            X_aug = np.hstack([X, leaf_ohe])\n",
    "\n",
    "        return self.mlp_.predict(X_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc071c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper Utilities ---------------------------------------------------\n",
    "\n",
    "\n",
    "def make_preprocessing_pipeline(X: pd.DataFrame):\n",
    "    \"\"\"Return a ColumnTransformer that imputes and scales/encodes appropriately.\"\"\"\n",
    "    numeric_features = X.select_dtypes(include=[\"int\", \"float\"]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=[\"int\", \"float\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def evaluate_model(model_name, model, X, y):\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \"\"\"Create pipeline, perform cross‑validation, return metric means.\"\"\"\n",
    "    pre = make_preprocessing_pipeline(X)\n",
    "    pipe = Pipeline(steps=[(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "    cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    cv_results = cross_validate(\n",
    "        pipe, X, y, cv=cv, scoring=scoring, return_train_score=False, n_jobs=-1\n",
    "    )\n",
    "    # Flip sign on MAE/RMSE (they were negated)\n",
    "    metrics = {\n",
    "        \"r2\": np.mean(cv_results[\"test_r2\"]),\n",
    "        \"mae\": -np.mean(cv_results[\"test_mae\"]),\n",
    "        \"rmse\": -np.mean(cv_results[\"test_rmse\"]),\n",
    "    }\n",
    "    \n",
    "    # Fit once on a train/test split for W&B visualizations\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    pipe_fit = Pipeline(steps=[('pre', pre), ('model', copy.deepcopy(model))])\n",
    "    pipe_fit.fit(X_train, y_train)\n",
    "    wandb.sklearn.plot_regressor(pipe_fit, X_train, X_test, y_train, y_test, model_name=model_name)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c513db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 35 tasks from suite '8f0ea660163b436bbd4abd49665c7b1d'\n",
      "\n",
      "Dataset: abalone (task_id=361234) | shape=(4177, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ahteh/Developer/research/TreeMLP/wandb/run-20250424_012837-h6urj58d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/h6urj58d' target=\"_blank\">abalone-LinearRegression</a></strong> to <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/h6urj58d' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/h6urj58d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Plotting LinearRegression.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X_test contains values that are not numbers. Please vectorize, label encode or one hot encode X_test and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged learning curve.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged outlier candidates.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged residuals.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>1.58555</td></tr><tr><td>r2</td><td>0.52571</td></tr><tr><td>rmse</td><td>2.21135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">abalone-LinearRegression</strong> at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/h6urj58d' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/h6urj58d</a><br> View project at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_012837-h6urj58d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ahteh/Developer/research/TreeMLP/wandb/run-20250424_012839-zsr3kh0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/zsr3kh0n' target=\"_blank\">abalone-MLPRegressor</a></strong> to <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/zsr3kh0n' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/zsr3kh0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Plotting MLPRegressor.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X_test contains values that are not numbers. Please vectorize, label encode or one hot encode X_test and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged learning curve.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged outlier candidates.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m X contains values that are not numbers. Please vectorize, label encode or one hot encode X and call the plotting function again.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged residuals.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>1.50507</td></tr><tr><td>r2</td><td>0.56262</td></tr><tr><td>rmse</td><td>2.12482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">abalone-MLPRegressor</strong> at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/zsr3kh0n' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/zsr3kh0n</a><br> View project at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_012839-zsr3kh0n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: airfoil_self_noise (task_id=361235) | shape=(1503, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ahteh/Developer/research/TreeMLP/wandb/run-20250424_012855-sfpxy32z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/sfpxy32z' target=\"_blank\">airfoil_self_noise-LinearRegression</a></strong> to <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/sfpxy32z' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/sfpxy32z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Plotting LinearRegression.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged learning curve.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart outlier_candidates\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged outlier candidates.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 100 datapoints to create chart residuals\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 100 datapoints to create chart residuals\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged residuals.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>3.7542</td></tr><tr><td>r2</td><td>0.50514</td></tr><tr><td>rmse</td><td>4.83142</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">airfoil_self_noise-LinearRegression</strong> at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/sfpxy32z' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/sfpxy32z</a><br> View project at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_012855-sfpxy32z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ahteh/Developer/research/TreeMLP/wandb/run-20250424_012858-6c6218gu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/6c6218gu' target=\"_blank\">airfoil_self_noise-MLPRegressor</a></strong> to <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/6c6218gu' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/6c6218gu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Plotting MLPRegressor.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged learning curve.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart outlier_candidates\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged outlier candidates.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 100 datapoints to create chart residuals\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 100 datapoints to create chart residuals\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged residuals.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mae</td><td>14.20294</td></tr><tr><td>r2</td><td>-6.01698</td></tr><tr><td>rmse</td><td>18.17611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">airfoil_self_noise-MLPRegressor</strong> at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/6c6218gu' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025/runs/6c6218gu</a><br> View project at: <a href='https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025' target=\"_blank\">https://wandb.ai/spicecat-club/OpenML_Regression_Benchmark_2025</a><br>Synced 5 W&B file(s), 4 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_012858-6c6218gu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Main Benchmark Loop -----------------------------------------------\n",
    "results = []\n",
    "\n",
    "suite = openml.study.get_suite(SUITE_NAME)\n",
    "print(f\"Evaluating {len(suite.tasks)} tasks from suite '{SUITE_NAME}'\")\n",
    "\n",
    "# Add custom model to list\n",
    "models = baseline_models.copy()\n",
    "# models[\"TreeMLPRegressor\"] = TreeMLPRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "for task_id in suite.tasks[:2]:\n",
    "    try:\n",
    "        task = openml.tasks.get_task(task_id)\n",
    "        dataset = task.get_dataset()\n",
    "        X, y, categorical_indicator, attr_names = dataset.get_data(\n",
    "            target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    "        )\n",
    "\n",
    "        print(f\"\\nDataset: {dataset.name} (task_id={task_id}) | shape={X.shape}\")\n",
    "\n",
    "        for name, model in models.items():\n",
    "            run = wandb.init(\n",
    "                project=WANDB_PROJECT,\n",
    "                name=f\"{dataset.name}-{name}\",\n",
    "                config={\n",
    "                    \"dataset_name\": dataset.name,\n",
    "                    \"task_id\": task_id,\n",
    "                    \"model\": name,\n",
    "                    \"cv_folds\": CV_FOLDS,\n",
    "                    \"random_state\": RANDOM_STATE,\n",
    "                    \"model_params\": (\n",
    "                        model.get_params() if hasattr(model, \"get_params\") else {}\n",
    "                    ),\n",
    "                },\n",
    "                reinit=\"finish_previous\",\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                metrics = evaluate_model(name, model, X, y)\n",
    "                wandb.log(metrics)\n",
    "                # Store for local summary\n",
    "                record = {\n",
    "                    \"dataset\": dataset.name,\n",
    "                    \"task_id\": task_id,\n",
    "                    \"model\": name,\n",
    "                    **metrics,\n",
    "                }\n",
    "                results.append(record)\n",
    "            except Exception as model_exc:\n",
    "                print(\n",
    "                    f\"⚠️  Error evaluating model '{name}' on '{dataset.name}': {model_exc}\"\n",
    "                )\n",
    "                wandb.log({\"error\": str(model_exc)})\n",
    "            finally:\n",
    "                run.finish()\n",
    "    except Exception as ds_exc:\n",
    "        print(f\"⚠️  Skipping task_id={task_id} due to error: {ds_exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6b9fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "38033ae0-9e3d-4b90-91d4-1c7ad5c4a7c8",
       "rows": [],
       "shape": {
        "columns": 0,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Results Summary ----------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# Log aggregated table to W&B\n",
    "if len(results_df):\n",
    "    table = wandb.Table(dataframe=results_df)\n",
    "    wandb.log({\"benchmark_results\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77975e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.3\n",
      "Platform: Linux-5.15.0-135-generic-x86_64-with-glibc2.35\n",
      "scikit-learn: 1.6.1\n",
      "OpenML: 0.15.1\n"
     ]
    }
   ],
   "source": [
    "# ---- Appendix -----------------------------------------------------------\n",
    "import sys, sklearn, platform, openml\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"OpenML:\", openml.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415cc1e4",
   "metadata": {},
   "source": [
    "## W&B Sweeps\n",
    "Set up hyper‑parameter sweeps with Weights & Biases to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Sweep helper --------------------------------------------------------\n",
    "def make_model_from_sweep(cfg):\n",
    "    if cfg.model == \"RandomForest\":\n",
    "        return RandomForestRegressor(\n",
    "            n_estimators=cfg.rf_n_estimators,\n",
    "            max_depth=cfg.rf_max_depth,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    if cfg.model == \"GradientBoosting\":\n",
    "        return GradientBoostingRegressor(\n",
    "            n_estimators=cfg.gb_n_estimators,\n",
    "            learning_rate=cfg.gb_lr,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    if cfg.model == \"MLP\":\n",
    "        return MLPRegressor(\n",
    "            hidden_layer_sizes=tuple(cfg.mlp_layers),\n",
    "            learning_rate_init=cfg.mlp_lr,\n",
    "            max_iter=cfg.mlp_max_iter,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    raise ValueError(cfg.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c31c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Define and run a W&B sweep ------------------------------------------\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"rmse\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"dataset_idx\": {\"values\": [0,1,2]},\n",
    "            \"model\": {\"values\": [\"RandomForest\", \"GradientBoosting\", \"MLP\"]},\n",
    "        \"rf_n_estimators\": {\"values\": [100, 200, 400]},\n",
    "        \"rf_max_depth\": {\"values\": [None, 10, 20]},\n",
    "        \"gb_n_estimators\": {\"values\": [100, 300]},\n",
    "        \"gb_lr\": {\"values\": [0.05, 0.1, 0.2]},\n",
    "        \"mlp_layers\": {\"values\": [(64,), (128, 64)]},\n",
    "        \"mlp_lr\": {\"values\": [0.001, 0.01]},\n",
    "        \"mlp_max_iter\": {\"values\": [200, 400]},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)\n",
    "\n",
    "# Example: run sweep on first dataset in the suite\n",
    "suite = openml.study.get_suite(SUITE_NAME)\n",
    "task_selected = openml.tasks.get_task(suite.tasks[cfg.dataset_idx])\n",
    "ds = task_selected.get_dataset()\n",
    "X_sweep, y_sweep, *_ = ds.get_data(\n",
    "    target=ds.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "def sweep_train():\n",
    "    with wandb.init() as run:\n",
    "        cfg = wandb.config\n",
    "        model = make_model_from_sweep(cfg)\n",
    "        metrics = evaluate_model(cfg.model, model, X_sweep, y_sweep)\n",
    "        wandb.log(metrics)\n",
    "\n",
    "# Launch trials (adjust count or run multiple agents)\n",
    "wandb.agent(sweep_id, function=sweep_train, count=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6847a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Reproducibility helpers ---------------------------------------------\n",
    "def log_dataset_artifact(run, dataset):\n",
    "    \"\"\"Log OpenML dataset as W&B artifact and attach to run.\"\"\"\n",
    "    art = wandb.Artifact(dataset.name.replace(\" \", \"_\"), type=\"dataset\")\n",
    "    if getattr(dataset, \"url\", None):\n",
    "        art.add_reference(dataset.url)\n",
    "    run.use_artifact(art)\n",
    "\n",
    "def save_model_artifact(run, pipe_fitted, dataset_name, model_name):\n",
    "    \"\"\"Save fitted model pipeline and log to W&B.\"\"\"\n",
    "    out_path = f\"/tmp/{dataset_name.replace(' ', '_')}_{model_name}_{uuid.uuid4().hex}.joblib\"\n",
    "    joblib.dump(pipe_fitted, out_path)\n",
    "    art = wandb.Artifact(f\"{dataset_name}-{model_name}\", type=\"model\")\n",
    "    art.add_file(out_path)\n",
    "    run.log_artifact(art)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee742e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Feature importance helper ------------------------------------------\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def log_permutation_importance(pipe_fitted, X_val, y_val, model_name):\n",
    "    \"\"\"Compute and log permutation importances for tree models.\"\"\"\n",
    "    try:\n",
    "        pre = pipe_fitted.named_steps.get(\"pre\")\n",
    "        X_val_enc = pre.transform(X_val) if pre else X_val\n",
    "        res = permutation_importance(pipe_fitted, X_val_enc, y_val, n_repeats=5, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        imp_table = {f\"perm_imp_{model_name}_{i}\": val for i, val in enumerate(res.importances_mean)}\n",
    "        wandb.log(imp_table)\n",
    "    except Exception as exc:\n",
    "        print(f\"[perm importance skipped] {exc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
