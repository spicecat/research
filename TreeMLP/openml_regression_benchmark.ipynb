{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0355f62c",
   "metadata": {},
   "source": [
    "# OpenML-CTR23 Regression Benchmark\n",
    "\n",
    "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c211b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q pip openml scikit-learn pandas nbformat setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Models\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Baseline models\n",
    "models = {\n",
    "    \"DummyRegressor\": DummyRegressor(strategy=\"mean\"),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    # \"LinearRegression\": LinearRegression(),\n",
    "    \"MLPRegressor\": MLPRegressor(solver=\"sgd\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2f9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "\n",
    "search_params = {\n",
    "    \"cv\": 5,\n",
    "    \"n_jobs\": -1,\n",
    "    \"n_trials\": 10,\n",
    "    \"return_train_score\": False,\n",
    "    \"scoring\": \"neg_mean_squared_error\",\n",
    "    \"timeout\": None,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "hpo_grid = {\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"n_estimators\": randint(5, 100),\n",
    "        \"max_depth\": [2, 5, 10],\n",
    "    },\n",
    "    \"MLPRegressor\": {\n",
    "        \"hidden_layer_sizes\": [(10,), (50,), (10, 10), (50, 50)],\n",
    "        \"alpha\": loguniform(1e-5, 1e-1),\n",
    "        \"learning_rate_init\": loguniform(1e-4, 1e-1),\n",
    "        \"max_iter\": [100, 400, 1000],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63771953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Benchmark Suite\n",
       "======================\n",
       "ID..............: 353\n",
       "Name............: OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
       "Status..........: active\n",
       "Main Entity Type: task\n",
       "Study URL.......: https://www.openml.org/s/353\n",
       "# of Data.......: 35\n",
       "# of Tasks......: 35\n",
       "Creator.........: https://www.openml.org/u/30127\n",
       "Upload Time.....: 2023-05-31 16:39:49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Benchmark Suite\n",
    "import openml\n",
    "from IPython.display import display\n",
    "\n",
    "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
    "suite = openml.study.get_suite(SUITE_ID)\n",
    "display(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6305108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def make_preprocessor(dataset: openml.OpenMLDataset) -> ColumnTransformer:\n",
    "    target = dataset.default_target_attribute\n",
    "    numeric_features = dataset.get_features_by_type(\"numeric\", exclude=[target])\n",
    "    nominal_features = dataset.get_features_by_type(\"nominal\", exclude=[target])\n",
    "\n",
    "    numeric_transformer = Pipeline(\n",
    "        [(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "    nominal_transformer = Pipeline(\n",
    "        [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]\n",
    "    )\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        [\n",
    "            (\"numeric_preprocessor\", numeric_transformer, numeric_features),\n",
    "            (\"nominal_preprocessor\", nominal_transformer, nominal_features),\n",
    "        ],\n",
    "        sparse_threshold=0.0,  # Ensure dense output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Models\n",
    "SEED = 42\n",
    "N_TASKS = 2\n",
    "task_runs = {}\n",
    "\n",
    "for task_id in suite.tasks[:N_TASKS]:\n",
    "    model_results = {}\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    dataset = task.get_dataset()\n",
    "    preprocessor = make_preprocessor(dataset)\n",
    "    for model_name in models.keys():\n",
    "        print(f\"Running {model_name=} on {dataset.name=}...\")\n",
    "        pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", models[model_name])])\n",
    "        model = (\n",
    "            RandomizedSearchCV(\n",
    "                pipe,\n",
    "                {f\"model__{k}\": v for k, v in hpo_grid[model_name].items()},\n",
    "                cv=KFold(n_splits=4, shuffle=True),\n",
    "            )\n",
    "            if model_name in hpo_grid\n",
    "            else pipe\n",
    "        )\n",
    "        # run = openml.runs.run_model_on_task(model, task, seed=SEED, n_jobs=-1)\n",
    "        # model_results[model_name] = run\n",
    "    task_runs[task_id] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd01b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Results\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "runs_df = pd.DataFrame(task_runs)\n",
    "mse_df = runs_df.map(lambda run: run.get_metric_fn(mean_squared_error).mean())\n",
    "r2_df = runs_df.map(lambda run: run.get_metric_fn(r2_score).mean())\n",
    "rank_df = mse_df.rank(axis=0, method=\"min\", ascending=True)\n",
    "average_rank = rank_df.mean(axis=1)\n",
    "display(mse_df, r2_df, rank_df, average_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation\n",
    "task_id = suite.tasks[4]\n",
    "task = openml.tasks.get_task(task_id)\n",
    "dataset = task.get_dataset()\n",
    "preprocessor = make_preprocessor(dataset)\n",
    "\n",
    "model_name = \"RandomForestRegressor\"\n",
    "pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", models[model_name])])\n",
    "model = pipe\n",
    "\n",
    "run = openml.runs.run_model_on_task(model, task, n_jobs=-1)\n",
    "display(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b7a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:openml.extensions.sklearn.extension:'Read more' not found in descriptions. Trying to trim till 'Parameters' if available in docstring.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found a second occurence of component sklearn.tree._classes.DecisionTreeRegressor when trying to serialize StackingRegressor(estimators=[('Tree 0', DecisionTreeRegressor(random_state=0)),\n                              ('Tree 1', DecisionTreeRegressor(random_state=1)),\n                              ('Tree 2', DecisionTreeRegressor(random_state=2)),\n                              ('Tree 3', DecisionTreeRegressor(random_state=3)),\n                              ('Tree 4',\n                               DecisionTreeRegressor(random_state=4))],\n                  final_estimator=MLPRegressor(hidden_layer_sizes=(10,)),\n                  passthrough=True).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m forest_mlp_pipe = Pipeline([(\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, preprocessor), (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, forest_mlp)])\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# mlp_run = openml.runs.run_model_on_task(mlp_pipe, task, n_jobs=-1)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# tree_mlp_run = openml.runs.run_model_on_task(tree_mlp_pipe, task, n_jobs=-1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m forest_mlp_run = \u001b[43mopenml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_model_on_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforest_mlp_pipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/runs/functions.py:141\u001b[39m, in \u001b[36mrun_model_on_task\u001b[39m\u001b[34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow, dataset_format, n_jobs)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# This should never happen and is only here to please mypy will be gone soon once the\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# whole function is removed\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(extension)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m flow = \u001b[43mextension\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_to_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_task_and_type_conversion\u001b[39m(_task: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mstr\u001b[39m | OpenMLTask) -> OpenMLTask:\n\u001b[32m    144\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieve an OpenMLTask object from either an integer or string ID,\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m    or directly from an OpenMLTask object.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m \u001b[33;03m        The OpenMLTask object.\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:502\u001b[39m, in \u001b[36mSklearnExtension.model_to_flow\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform a scikit-learn model to a flow for uploading it to OpenML.\u001b[39;00m\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    499\u001b[39m \u001b[33;03mOpenMLFlow\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# Necessary to make pypy not complain about all the different possible return types\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:510\u001b[39m, in \u001b[36mSklearnExtension._serialize_sklearn\u001b[39m\u001b[34m(self, o, parent_model)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# TODO: assert that only on first recursion lvl `parent_model` can be None\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_estimator(o):\n\u001b[32m    509\u001b[39m     \u001b[38;5;66;03m# is the main model or a submodel\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    512\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[32m    513\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(o) == \u001b[32m2\u001b[39m\n\u001b[32m    514\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m o[\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m SKLEARN_PIPELINE_STRING_COMPONENTS\n\u001b[32m    515\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parent_model, sklearn.pipeline._BaseComposition)\n\u001b[32m    516\u001b[39m ):\n\u001b[32m    517\u001b[39m     rval = o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:794\u001b[39m, in \u001b[36mSklearnExtension._serialize_model\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    774\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an OpenMLFlow.\u001b[39;00m\n\u001b[32m    775\u001b[39m \n\u001b[32m    776\u001b[39m \u001b[33;03mCalls `sklearn_to_flow` recursively to properly serialize the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m \n\u001b[32m    787\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[38;5;66;03m# Get all necessary information about the model objects itself\u001b[39;00m\n\u001b[32m    789\u001b[39m (\n\u001b[32m    790\u001b[39m     parameters,\n\u001b[32m    791\u001b[39m     parameters_meta_info,\n\u001b[32m    792\u001b[39m     subcomponents,\n\u001b[32m    793\u001b[39m     subcomponents_explicit,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_information_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# Check that a component does not occur multiple times in a flow as this\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[38;5;66;03m# is not supported by OpenML\u001b[39;00m\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m._check_multiple_occurence_of_component_in_flow(model, subcomponents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:950\u001b[39m, in \u001b[36mSklearnExtension._extract_information_from_model\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    948\u001b[39m model_parameters = model.get_params(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(model_parameters.items(), key=\u001b[38;5;28;01mlambda\u001b[39;00m t: t[\u001b[32m0\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflatten_all\u001b[39m(list_):\n\u001b[32m    953\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"Flattens arbitrary depth lists of lists (e.g. [[1,2],[3,[1]]] -> [1,2,3,1]).\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:520\u001b[39m, in \u001b[36mSklearnExtension._serialize_sklearn\u001b[39m\u001b[34m(self, o, parent_model)\u001b[39m\n\u001b[32m    517\u001b[39m     rval = o\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# TODO: explain what type of parameter is here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     rval = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m o]\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    522\u001b[39m         rval = \u001b[38;5;28mtuple\u001b[39m(rval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:520\u001b[39m, in \u001b[36mSklearnExtension._serialize_sklearn\u001b[39m\u001b[34m(self, o, parent_model)\u001b[39m\n\u001b[32m    517\u001b[39m     rval = o\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# TODO: explain what type of parameter is here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     rval = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m o]\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    522\u001b[39m         rval = \u001b[38;5;28mtuple\u001b[39m(rval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:510\u001b[39m, in \u001b[36mSklearnExtension._serialize_sklearn\u001b[39m\u001b[34m(self, o, parent_model)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# TODO: assert that only on first recursion lvl `parent_model` can be None\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_estimator(o):\n\u001b[32m    509\u001b[39m     \u001b[38;5;66;03m# is the main model or a submodel\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    512\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[32m    513\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(o) == \u001b[32m2\u001b[39m\n\u001b[32m    514\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m o[\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m SKLEARN_PIPELINE_STRING_COMPONENTS\n\u001b[32m    515\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parent_model, sklearn.pipeline._BaseComposition)\n\u001b[32m    516\u001b[39m ):\n\u001b[32m    517\u001b[39m     rval = o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:798\u001b[39m, in \u001b[36mSklearnExtension._serialize_model\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    789\u001b[39m (\n\u001b[32m    790\u001b[39m     parameters,\n\u001b[32m    791\u001b[39m     parameters_meta_info,\n\u001b[32m    792\u001b[39m     subcomponents,\n\u001b[32m    793\u001b[39m     subcomponents_explicit,\n\u001b[32m    794\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._extract_information_from_model(model)\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# Check that a component does not occur multiple times in a flow as this\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[38;5;66;03m# is not supported by OpenML\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_multiple_occurence_of_component_in_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubcomponents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Create a flow name, which contains all components in brackets, e.g.:\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# RandomizedSearchCV(Pipeline(StandardScaler,AdaBoostClassifier(DecisionTreeClassifier)),\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# StandardScaler,AdaBoostClassifier(DecisionTreeClassifier))\u001b[39;00m\n\u001b[32m    803\u001b[39m class_name = model.\u001b[34m__module__\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + model.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/openml/extensions/sklearn/extension.py:917\u001b[39m, in \u001b[36mSklearnExtension._check_multiple_occurence_of_component_in_flow\u001b[39m\u001b[34m(self, model, sub_components)\u001b[39m\n\u001b[32m    915\u001b[39m     known_sub_components.add(visitee)\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m visitee.name \u001b[38;5;129;01min\u001b[39;00m known_sub_components:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    918\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound a second occurence of component \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisitee.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrying to serialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    920\u001b[39m     )\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    922\u001b[39m     known_sub_components.add(visitee.name)\n",
      "\u001b[31mValueError\u001b[39m: Found a second occurence of component sklearn.tree._classes.DecisionTreeRegressor when trying to serialize StackingRegressor(estimators=[('Tree 0', DecisionTreeRegressor(random_state=0)),\n                              ('Tree 1', DecisionTreeRegressor(random_state=1)),\n                              ('Tree 2', DecisionTreeRegressor(random_state=2)),\n                              ('Tree 3', DecisionTreeRegressor(random_state=3)),\n                              ('Tree 4',\n                               DecisionTreeRegressor(random_state=4))],\n                  final_estimator=MLPRegressor(hidden_layer_sizes=(10,)),\n                  passthrough=True)."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "task_id = suite.tasks[0]\n",
    "task = openml.tasks.get_task(task_id)\n",
    "dataset = task.get_dataset()\n",
    "preprocessor = make_preprocessor(dataset)\n",
    "\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,),\n",
    "    max_iter=200,\n",
    ")\n",
    "tree_mlp = StackingRegressor(\n",
    "    estimators=[(\"Tree\", DecisionTreeRegressor())],\n",
    "    final_estimator=mlp,\n",
    "    passthrough=True,\n",
    ")\n",
    "forest_mlp = StackingRegressor(\n",
    "    estimators=[(f\"Tree {i}\", DecisionTreeRegressor(random_state=i)) for i in range(5)],\n",
    "    final_estimator=mlp,\n",
    "    passthrough=True,\n",
    ")\n",
    "\n",
    "mlp_pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", mlp)])\n",
    "tree_mlp_pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", tree_mlp)])\n",
    "forest_mlp_pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", forest_mlp)])\n",
    "\n",
    "# mlp_run = openml.runs.run_model_on_task(mlp_pipe, task, n_jobs=-1)\n",
    "# tree_mlp_run = openml.runs.run_model_on_task(tree_mlp_pipe, task, n_jobs=-1)\n",
    "forest_mlp_run = openml.runs.run_model_on_task(forest_mlp_pipe, task, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mlp_run, tree_mlp_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51548d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(data_id=44956)\n",
    "display(dataset)\n",
    "[openml.tasks.get_task(task).dataset_id for task in suite.tasks]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
