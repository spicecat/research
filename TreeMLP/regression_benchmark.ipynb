{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsf3KDMkBnJJ"
      },
      "source": [
        "# OpenML-CTR23 Regression Benchmark\n",
        "\n",
        "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9ZbqI_CAHx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lm1ejpmI6RFJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq pip black blackcellmagic scikit-learn openml optuna pandas joblib jupyter ipywidgets nbformat setuptools\n",
        "%load_ext blackcellmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GT0rGO7CByh"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qIDiz21W9Hgm"
      },
      "outputs": [],
      "source": [
        "# Control Models\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "models = {\n",
        "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
        "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
        "    \"LR\": LinearRegression(),\n",
        "    \"MLP\": MLPRegressor(solver=\"sgd\", random_state=SEED),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p-5NQvgi9HqO"
      },
      "outputs": [],
      "source": [
        "# Test Models\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class ForestMLPRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_trees=5,\n",
        "        trees_max_depth=3,\n",
        "        final_estimator=MLPRegressor(),\n",
        "        final_estimator__hidden_layer_sizes=100,\n",
        "        random_state=0,\n",
        "    ):\n",
        "        self.n_trees = n_trees\n",
        "        self.trees_max_depth = trees_max_depth\n",
        "        self.final_estimator = final_estimator\n",
        "        self.final_estimator__hidden_layer_sizes = final_estimator__hidden_layer_sizes\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _make_stacking(self):\n",
        "        return StackingRegressor(\n",
        "            estimators=[\n",
        "                (\n",
        "                    f\"tree_{i}\",\n",
        "                    DecisionTreeRegressor(\n",
        "                        max_depth=self.trees_max_depth,\n",
        "                        random_state=self.random_state + i,\n",
        "                    ),\n",
        "                )\n",
        "                for i in range(self.n_trees)\n",
        "            ],\n",
        "            final_estimator=clone(self.final_estimator).set_params(\n",
        "                hidden_layer_sizes=self.final_estimator__hidden_layer_sizes,\n",
        "            ),\n",
        "            passthrough=True,\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_ = self._make_stacking()\n",
        "        self.model_.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "\n",
        "test_models = {\n",
        "    \"TreeMLP\": StackingRegressor(\n",
        "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
        "        final_estimator=models[\"MLP\"],\n",
        "        passthrough=True,\n",
        "    ),\n",
        "    \"ForestMLP\": ForestMLPRegressor(final_estimator=models[\"MLP\"], random_state=SEED),\n",
        "}\n",
        "\n",
        "models.update(test_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9grQGt7BCJOg"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TsmnhtRu9Hzp"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import numpy as np\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    [\n",
        "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"numeric_scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\n",
        "            \"categorical_encoder\",\n",
        "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "preprocessor = make_column_transformer(\n",
        "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
        "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
        "    sparse_threshold=0.0,\n",
        ")\n",
        "\n",
        "models = {\n",
        "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
        "    for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjW8qkdTCKTB"
      },
      "source": [
        "### Hyperparameter Optimization Configuration and Space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ve1gazIt9H9A"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Space\n",
        "hpo_spaces = {\n",
        "    \"Dummy\": {},\n",
        "    \"RF\": {\n",
        "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 20}),\n",
        "    },\n",
        "    \"LR\": {},\n",
        "    \"MLP\": {\n",
        "        \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"TreeMLP\": {\n",
        "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"ForestMLP\": {\n",
        "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 10}),\n",
        "        \"trees_max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "}\n",
        "\n",
        "models = {\n",
        "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VvYcl3Fl9IEt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Configuration\n",
        "import optuna\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Study configuration\n",
        "hpo_config = {\n",
        "    \"n_trials\": 10,\n",
        "    \"timeout\": None,\n",
        "    \"show_progress_bar\": True,\n",
        "}\n",
        "\n",
        "# Cross-validation parameters for HPO objective function\n",
        "objective_cv_params = {\"cv\": 5, \"scoring\": \"neg_mean_squared_error\"}\n",
        "\n",
        "\n",
        "def create_objective(model, hpo_space, X, y):\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        param_type_map = {\n",
        "            \"int\": trial.suggest_int,\n",
        "            \"float\": trial.suggest_float,\n",
        "            \"categorical\": trial.suggest_categorical,\n",
        "        }\n",
        "        params = {\n",
        "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
        "            for p, (typ, kw) in hpo_space.items()\n",
        "        }\n",
        "        model.set_params(**params)\n",
        "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
        "\n",
        "    return objective\n",
        "\n",
        "\n",
        "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
        "    def __init__(self, model, hpo_space):\n",
        "        self.model = model\n",
        "        self.hpo_space = hpo_space\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        model = clone(self.model)\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "        study.optimize(\n",
        "            create_objective(model, self.hpo_space, X, y),\n",
        "            **hpo_config,\n",
        "        )\n",
        "        model.set_params(**study.best_params)\n",
        "        self.fitted_model_ = model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.fitted_model_.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ge2W26CNXp"
      },
      "source": [
        "## Define Benchmark Suite and Tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hNEd-zKK9PUu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenML Benchmark Suite\n",
              "======================\n",
              "ID..............: 353\n",
              "Name............: OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
              "Status..........: active\n",
              "Main Entity Type: task\n",
              "Study URL.......: https://www.openml.org/s/353\n",
              "# of Data.......: 35\n",
              "# of Tasks......: 35\n",
              "Creator.........: https://www.openml.org/u/30127\n",
              "Upload Time.....: 2023-05-31 16:39:49"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inclusion Criteria:  \n",
            "\n",
            "* There are between 500 and 100000 observations.\n",
            "* There are less than 5000 features after one-hot encoding all categorical features.\n",
            "* The dataset is not in a sparse format.\n",
            "* The observations are i.i.d., which means that we exclude datasets that have time dependencies or require grouped data splits.\n",
            "* The dataset comes with a source or reference that clearly describes it.\n",
            "* We did not consider the dataset to be artificial, but allowed simulated datasets.\n",
            "* The data is not a subset of a larger dataset.\n",
            "* There is a numeric target variable with at least 5 different values.\n",
            "* The dataset is not trivially solvable by a linear model, i.e. the training error of a linear model fitted to the whole data has an R2 of less than 1.\n",
            "* The dataset does not have ethical concerns.\n",
            "* The use of the dataset for benchmarking is not forbidden.\n",
            "\n",
            "In addition to the datasets, the OpenML tasks also contain resampling splits, which were determined according to the following rule: If there are less than 1000 observations we use 10 times repeated 10-fold CV. If there are more than 10000 observations we use a 33% holdout split, and for everything\n",
            "between, we use 10-fold CV.\n",
            "\n",
            "Please cite the following paper if you use the suite:\n",
            "\n",
            "@inproceedings{\n",
            "  fischer2023openmlctr,  \n",
            "  title={Open{ML}-{CTR}23 {\\textendash} A curated tabular regression benchmarking suite},  \n",
            "  author={Sebastian Felix Fischer and Liana Harutyunyan Matthias Feurer and Bernd Bischl},  \n",
            "  booktitle={AutoML Conference 2023 (Workshop)},  \n",
            "  year={2023},  \n",
            "  url={https://openreview.net/forum?id=HebAOoMm94}\n",
            "}\n",
            "\n",
            "If you notice a problem with one of the datasets, please add a comment here: https://github.com/slds-lmu/paper_2023_regression_suite/issues/1\n"
          ]
        }
      ],
      "source": [
        "# Define Benchmark Suite\n",
        "import openml\n",
        "from IPython.display import display\n",
        "\n",
        "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
        "suite = openml.study.get_suite(SUITE_ID)\n",
        "display(suite)\n",
        "print(suite.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyya8O9Q9Qld"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361234\n",
              " Task URL.............: https://www.openml.org/t/361234\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: rings]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download tasks from the suite\n",
        "# N_TASKS = 1\n",
        "N_TASKS = len(suite.tasks or [])\n",
        "tasks = openml.tasks.get_tasks(\n",
        "    (suite.tasks or [])[:N_TASKS], download_data=True, download_qualities=True\n",
        ")\n",
        "display(tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "cv_params = {\n",
        "    \"scoring\": [\"neg_mean_squared_error\", \"r2\"],\n",
        "    \"return_train_score\": True,\n",
        "}\n",
        "\n",
        "\n",
        "def run_model_on_task(model_name, model, X, y, cv):\n",
        "    print(f\"Running {model_name=}\")\n",
        "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "    run = cross_validate(\n",
        "        TemplateRegressor(*model),\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        **cv_params,\n",
        "    )\n",
        "    return model_name, pd.DataFrame(run).mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op3VR4BlCPkQ"
      },
      "source": [
        "### Benchmarking Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vepYJIxW9R8S"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "selected_models = models\n",
        "# selected_models = {m: models[m] for m in [\"Dummy\", \"RF\"]}\n",
        "\n",
        "runs = {}\n",
        "for task in tasks:\n",
        "    splits = task.download_split().split\n",
        "    X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "    cv = [s[0] for s in splits[0].values()]\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(run_model_on_task)(model_name, model, X, y, cv)\n",
        "        for model_name, model in selected_models.items()\n",
        "    )\n",
        "    runs[task.id] = dict(results)  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAN_GWXWCRKY"
      },
      "source": [
        "### Aggregate Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9eeK8Sc49TM1"
      },
      "outputs": [],
      "source": [
        "# %%capture output\n",
        "# Aggregate Results\n",
        "import pandas as pd\n",
        "\n",
        "runs_df = pd.DataFrame(runs)\n",
        "metrics = cv_params[\"scoring\"]\n",
        "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
        "for metric in metrics:\n",
        "    metrics_df[metric] = (\n",
        "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
        "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
        "    )\n",
        "\n",
        "# Use first metric for ranking\n",
        "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
        "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
        "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
        "\n",
        "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
        "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
        "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
        "\n",
        "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
        "\n",
        "# Display all metrics and ranks\n",
        "for metric, (test, train) in metrics_df.items():\n",
        "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'test_neg_mean_squared_error'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>-10.464317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>-5.614490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          361234\n",
              "Dummy -10.464317\n",
              "RF     -5.614490"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_neg_mean_squared_error'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>-10.384931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>-1.080574</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          361234\n",
              "Dummy -10.384931\n",
              "RF     -1.080574"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test_r2'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>-0.000932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.462583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         361234\n",
              "Dummy -0.000932\n",
              "RF     0.462583"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_r2'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.895948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         361234\n",
              "Dummy  0.000000\n",
              "RF     0.895948"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test_rank'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>avg_rank</th>\n",
              "      <th>std_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234  avg_rank  std_rank\n",
              "Dummy     2.0       2.0       0.0\n",
              "RF        1.0       1.0       0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_rank'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>avg_rank</th>\n",
              "      <th>std_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234  avg_rank  std_rank\n",
              "Dummy     2.0       2.0       0.0\n",
              "RF        1.0       1.0       0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# output.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pn2J6VVC85Ba"
      },
      "outputs": [],
      "source": [
        "# # Single model evaluation\n",
        "# from sklearn.model_selection import cross_validate\n",
        "\n",
        "# task = tasks[0]\n",
        "# splits = task.download_split().split\n",
        "# X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "# cv = [s[0] for s in splits[0].values()][:3]  # Using pre-defined OpenML splits\n",
        "# model = TemplateRegressor(*models[\"ForestMLP\"])\n",
        "# run = cross_validate(\n",
        "#     model,\n",
        "#     X,\n",
        "#     y,\n",
        "#     cv=cv\n",
        "#     **cv_params,\n",
        "# )\n",
        "# display(pd.DataFrame(run).mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
