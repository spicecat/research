{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsf3KDMkBnJJ"
      },
      "source": [
        "# OpenML-CTR23 Regression Benchmark\n",
        "\n",
        "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9ZbqI_CAHx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lm1ejpmI6RFJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq pip black blackcellmagic scikit-learn openml optuna pandas joblib jupyter ipywidgets nbformat setuptools papermill\n",
        "%load_ext blackcellmagic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "N_TRIALS = 1\n",
        "OBJECTIVE_CV = 2\n",
        "N_TASKS = 35\n",
        "CV = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GT0rGO7CByh"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qIDiz21W9Hgm"
      },
      "outputs": [],
      "source": [
        "# Control Models\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "models = {\n",
        "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
        "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
        "    \"LR\": LinearRegression(),\n",
        "    \"MLP\": MLPRegressor(solver=\"sgd\", random_state=SEED),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p-5NQvgi9HqO"
      },
      "outputs": [],
      "source": [
        "# Test Models\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class ForestMLPRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_trees=5,\n",
        "        trees_max_depth=3,\n",
        "        final_estimator=MLPRegressor(),\n",
        "        final_estimator__hidden_layer_sizes=100,\n",
        "        random_state=0,\n",
        "    ):\n",
        "        self.n_trees = n_trees\n",
        "        self.trees_max_depth = trees_max_depth\n",
        "        self.final_estimator = final_estimator\n",
        "        self.final_estimator__hidden_layer_sizes = final_estimator__hidden_layer_sizes\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _make_stacking(self):\n",
        "        return StackingRegressor(\n",
        "            estimators=[\n",
        "                (\n",
        "                    f\"tree_{i}\",\n",
        "                    DecisionTreeRegressor(\n",
        "                        max_depth=self.trees_max_depth,\n",
        "                        random_state=self.random_state + i,\n",
        "                    ),\n",
        "                )\n",
        "                for i in range(self.n_trees)\n",
        "            ],\n",
        "            final_estimator=clone(self.final_estimator).set_params(\n",
        "                hidden_layer_sizes=self.final_estimator__hidden_layer_sizes,\n",
        "            ),\n",
        "            passthrough=True,\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_ = self._make_stacking()\n",
        "        self.model_.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "\n",
        "test_models = {\n",
        "    \"TreeMLP\": StackingRegressor(\n",
        "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
        "        final_estimator=models[\"MLP\"],\n",
        "        passthrough=True,\n",
        "    ),\n",
        "    \"ForestMLP\": ForestMLPRegressor(final_estimator=models[\"MLP\"], random_state=SEED),\n",
        "}\n",
        "\n",
        "models.update(test_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9grQGt7BCJOg"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TsmnhtRu9Hzp"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import numpy as np\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    [\n",
        "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"numeric_scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\n",
        "            \"categorical_encoder\",\n",
        "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "preprocessor = make_column_transformer(\n",
        "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
        "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
        "    sparse_threshold=0.0,\n",
        ")\n",
        "\n",
        "models = {\n",
        "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
        "    for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjW8qkdTCKTB"
      },
      "source": [
        "### Hyperparameter Optimization Configuration and Space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ve1gazIt9H9A"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Space\n",
        "hpo_spaces = {\n",
        "    \"Dummy\": {},\n",
        "    \"RF\": {\n",
        "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 20}),\n",
        "    },\n",
        "    \"LR\": {},\n",
        "    \"MLP\": {\n",
        "        \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"TreeMLP\": {\n",
        "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "    \"ForestMLP\": {\n",
        "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 10}),\n",
        "        \"trees_max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
        "    },\n",
        "}\n",
        "\n",
        "models = {\n",
        "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VvYcl3Fl9IEt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Configuration\n",
        "import optuna\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Study configuration\n",
        "hpo_config = {\n",
        "    \"n_trials\": N_TRIALS,\n",
        "    \"timeout\": None,\n",
        "    \"show_progress_bar\": False,\n",
        "}\n",
        "\n",
        "# Cross-validation parameters for HPO objective function\n",
        "objective_cv_params = {\"cv\": OBJECTIVE_CV, \"scoring\": \"neg_mean_squared_error\"}\n",
        "\n",
        "\n",
        "def create_objective(model, hpo_space, X, y):\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        param_type_map = {\n",
        "            \"int\": trial.suggest_int,\n",
        "            \"float\": trial.suggest_float,\n",
        "            \"categorical\": trial.suggest_categorical,\n",
        "        }\n",
        "        params = {\n",
        "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
        "            for p, (typ, kw) in hpo_space.items()\n",
        "        }\n",
        "        model.set_params(**params)\n",
        "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
        "\n",
        "    return objective\n",
        "\n",
        "\n",
        "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
        "    def __init__(self, model, hpo_space):\n",
        "        self.model = model\n",
        "        self.hpo_space = hpo_space\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        model = clone(self.model)\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "        study.optimize(\n",
        "            create_objective(model, self.hpo_space, X, y),\n",
        "            **hpo_config,\n",
        "        )\n",
        "        model.set_params(**study.best_params)\n",
        "        self.fitted_model_ = model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.fitted_model_.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ge2W26CNXp"
      },
      "source": [
        "## Define Benchmark Suite and Tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hNEd-zKK9PUu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenML Benchmark Suite\n",
              "======================\n",
              "ID..............: 353\n",
              "Name............: OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
              "Status..........: active\n",
              "Main Entity Type: task\n",
              "Study URL.......: https://www.openml.org/s/353\n",
              "# of Data.......: 35\n",
              "# of Tasks......: 35\n",
              "Creator.........: https://www.openml.org/u/30127\n",
              "Upload Time.....: 2023-05-31 16:39:49"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inclusion Criteria:  \n",
            "\n",
            "* There are between 500 and 100000 observations.\n",
            "* There are less than 5000 features after one-hot encoding all categorical features.\n",
            "* The dataset is not in a sparse format.\n",
            "* The observations are i.i.d., which means that we exclude datasets that have time dependencies or require grouped data splits.\n",
            "* The dataset comes with a source or reference that clearly describes it.\n",
            "* We did not consider the dataset to be artificial, but allowed simulated datasets.\n",
            "* The data is not a subset of a larger dataset.\n",
            "* There is a numeric target variable with at least 5 different values.\n",
            "* The dataset is not trivially solvable by a linear model, i.e. the training error of a linear model fitted to the whole data has an R2 of less than 1.\n",
            "* The dataset does not have ethical concerns.\n",
            "* The use of the dataset for benchmarking is not forbidden.\n",
            "\n",
            "In addition to the datasets, the OpenML tasks also contain resampling splits, which were determined according to the following rule: If there are less than 1000 observations we use 10 times repeated 10-fold CV. If there are more than 10000 observations we use a 33% holdout split, and for everything\n",
            "between, we use 10-fold CV.\n",
            "\n",
            "Please cite the following paper if you use the suite:\n",
            "\n",
            "@inproceedings{\n",
            "  fischer2023openmlctr,  \n",
            "  title={Open{ML}-{CTR}23 {\\textendash} A curated tabular regression benchmarking suite},  \n",
            "  author={Sebastian Felix Fischer and Liana Harutyunyan Matthias Feurer and Bernd Bischl},  \n",
            "  booktitle={AutoML Conference 2023 (Workshop)},  \n",
            "  year={2023},  \n",
            "  url={https://openreview.net/forum?id=HebAOoMm94}\n",
            "}\n",
            "\n",
            "If you notice a problem with one of the datasets, please add a comment here: https://github.com/slds-lmu/paper_2023_regression_suite/issues/1\n"
          ]
        }
      ],
      "source": [
        "# Define Benchmark Suite\n",
        "import openml\n",
        "from IPython.display import display\n",
        "\n",
        "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
        "suite = openml.study.get_suite(SUITE_ID)\n",
        "display(suite)\n",
        "print(suite.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cyya8O9Q9Qld"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361234\n",
              " Task URL.............: https://www.openml.org/t/361234\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: rings,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361235\n",
              " Task URL.............: https://www.openml.org/t/361235\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: sound_pressure,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361236\n",
              " Task URL.............: https://www.openml.org/t/361236\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: verification.time,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361237\n",
              " Task URL.............: https://www.openml.org/t/361237\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: strength,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361241\n",
              " Task URL.............: https://www.openml.org/t/361241\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: RMSD,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361242\n",
              " Task URL.............: https://www.openml.org/t/361242\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: critical_temp,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361243\n",
              " Task URL.............: https://www.openml.org/t/361243\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: latitude,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361244\n",
              " Task URL.............: https://www.openml.org/t/361244\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: c_class_flares,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361247\n",
              " Task URL.............: https://www.openml.org/t/361247\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: gt_compressor_decay_state_coefficient,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361249\n",
              " Task URL.............: https://www.openml.org/t/361249\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: quality,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361250\n",
              " Task URL.............: https://www.openml.org/t/361250\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: quality,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361251\n",
              " Task URL.............: https://www.openml.org/t/361251\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: stab,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361252\n",
              " Task URL.............: https://www.openml.org/t/361252\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: utime,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361253\n",
              " Task URL.............: https://www.openml.org/t/361253\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: energy_total,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361254\n",
              " Task URL.............: https://www.openml.org/t/361254\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: V22,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361255\n",
              " Task URL.............: https://www.openml.org/t/361255\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: medianHouseValue,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361256\n",
              " Task URL.............: https://www.openml.org/t/361256\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: usr,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361257\n",
              " Task URL.............: https://www.openml.org/t/361257\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: price,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361258\n",
              " Task URL.............: https://www.openml.org/t/361258\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: y,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361259\n",
              " Task URL.............: https://www.openml.org/t/361259\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: thetadd6,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361260\n",
              " Task URL.............: https://www.openml.org/t/361260\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: SALE_PRC,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361261\n",
              " Task URL.............: https://www.openml.org/t/361261\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: wage,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361264\n",
              " Task URL.............: https://www.openml.org/t/361264\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: counts_for_sons_current_occupation,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361266\n",
              " Task URL.............: https://www.openml.org/t/361266\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: price,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361267\n",
              " Task URL.............: https://www.openml.org/t/361267\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: total,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361268\n",
              " Task URL.............: https://www.openml.org/t/361268\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: FPS,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361269\n",
              " Task URL.............: https://www.openml.org/t/361269\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: whrswk,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361272\n",
              " Task URL.............: https://www.openml.org/t/361272\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: wage_eur,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361616\n",
              " Task URL.............: https://www.openml.org/t/361616\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: RS,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361617\n",
              " Task URL.............: https://www.openml.org/t/361617\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: heating_load,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361618\n",
              " Task URL.............: https://www.openml.org/t/361618\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: area,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361619\n",
              " Task URL.............: https://www.openml.org/t/361619\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: G3,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361621\n",
              " Task URL.............: https://www.openml.org/t/361621\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: LC50,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361622\n",
              " Task URL.............: https://www.openml.org/t/361622\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: Price,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361623\n",
              " Task URL.............: https://www.openml.org/t/361623\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: ln_votes_pop]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download tasks from the suite\n",
        "tasks = openml.tasks.get_tasks(\n",
        "    (suite.tasks or [])[:N_TASKS], download_data=True, download_qualities=True\n",
        ")\n",
        "display(tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "cv_params = {\n",
        "    \"scoring\": [\"neg_mean_squared_error\", \"r2\"],\n",
        "    \"return_train_score\": True,\n",
        "}\n",
        "\n",
        "\n",
        "def run_model_on_task(model_name, model, X, y, cv):\n",
        "    # print(f\"Running {model_name=}\")\n",
        "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "    run = cross_validate(\n",
        "        TemplateRegressor(*model),\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        **cv_params,\n",
        "    )\n",
        "    return model_name, pd.DataFrame(run).mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op3VR4BlCPkQ"
      },
      "source": [
        "### Benchmarking Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vepYJIxW9R8S"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "[W 2025-05-21 16:13:17,421] Trial 0 failed with parameters: {'model__hidden_layer_sizes': 40} because of the following error: ValueError('\\nAll the 2 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n2 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\\n    return self._fit(X, y, incremental=False)\\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\\n    raise ValueError(\\n    ...<2 lines>...\\n    )\\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\\n').\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_1575843/1907628840.py\", line 29, in objective\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "        estimator=estimator,\n",
            "    ...<9 lines>...\n",
            "        error_score=error_score,\n",
            "    )\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n",
            "    _warn_or_raise_about_fit_failures(results, error_score)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 2 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
            "    raise ValueError(\n",
            "    ...<2 lines>...\n",
            "    )\n",
            "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "\n",
            "[W 2025-05-21 16:13:17,424] Trial 0 failed with value None.\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "[W 2025-05-21 16:13:18,348] Trial 0 failed with parameters: {'model__hidden_layer_sizes': 40} because of the following error: ValueError('\\nAll the 2 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n2 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\\n    return fit_method(estimator, *args, **kwargs)\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\\n    return self._fit(X, y, incremental=False)\\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\\n    raise ValueError(\\n    ...<2 lines>...\\n    )\\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\\n').\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_1575843/1907628840.py\", line 29, in objective\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "        estimator=estimator,\n",
            "    ...<9 lines>...\n",
            "        error_score=error_score,\n",
            "    )\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n",
            "    _warn_or_raise_about_fit_failures(results, error_score)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 2 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
            "    raise ValueError(\n",
            "    ...<2 lines>...\n",
            "    )\n",
            "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "\n",
            "[W 2025-05-21 16:13:18,349] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 43, in fit\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/study.py\", line 475, in optimize\n    _optimize(\n    ~~~~~~~~~^\n        study=self,\n        ^^^^^^^^^^^\n    ...<7 lines>...\n        show_progress_bar=show_progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n    _optimize_sequential(\n    ~~~~~~~~~~~~~~~~~~~~^\n        study,\n        ^^^^^^\n    ...<8 lines>...\n        progress_bar=progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n    frozen_trial = _run_trial(study, func, catch)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n    raise func_err\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 29, in objective\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n    cv_results = cross_validate(\n        estimator=estimator,\n    ...<9 lines>...\n        error_score=error_score,\n    )\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\n    return self._fit(X, y, incremental=False)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
            "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py\", line 606, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1575843/2474140910.py\", line 16, in run_model_on_task\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 43, in fit\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/study.py\", line 475, in optimize\n    _optimize(\n    ~~~~~~~~~^\n        study=self,\n        ^^^^^^^^^^^\n    ...<7 lines>...\n        show_progress_bar=show_progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n    _optimize_sequential(\n    ~~~~~~~~~~~~~~~~~~~~^\n        study,\n        ^^^^^^\n    ...<8 lines>...\n        progress_bar=progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n    frozen_trial = _run_trial(study, func, catch)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n    raise func_err\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 29, in objective\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n    cv_results = cross_validate(\n        estimator=estimator,\n    ...<9 lines>...\n        error_score=error_score,\n    )\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\n    return self._fit(X, y, incremental=False)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n\n\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m X, y = task.get_X_and_y(dataset_format=\u001b[33m\"\u001b[39m\u001b[33mdataframe\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     10\u001b[39m cv = [s[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m splits[\u001b[32m0\u001b[39m].values()][:CV]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_model_on_task\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mselected_models\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m runs[task.id] = \u001b[38;5;28mdict\u001b[39m(results)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:1783\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1777\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1778\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1783\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1784\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1786\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:1858\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1854\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1858\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:757\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    751\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    754\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/research/.venv/lib/python3.13/site-packages/joblib/parallel.py:772\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mValueError\u001b[39m: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 43, in fit\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/study.py\", line 475, in optimize\n    _optimize(\n    ~~~~~~~~~^\n        study=self,\n        ^^^^^^^^^^^\n    ...<7 lines>...\n        show_progress_bar=show_progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n    _optimize_sequential(\n    ~~~~~~~~~~~~~~~~~~~~^\n        study,\n        ^^^^^^\n    ...<8 lines>...\n        progress_bar=progress_bar,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n    frozen_trial = _run_trial(study, func, catch)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n    raise func_err\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_1575843/1907628840.py\", line 29, in objective\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n    cv_results = cross_validate(\n        estimator=estimator,\n    ...<9 lines>...\n        error_score=error_score,\n    )\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 754, in fit\n    return self._fit(X, y, incremental=False)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ahteh/Developer/research/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n\n"
          ]
        }
      ],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "# selected_models = models\n",
        "selected_models = {m: models[m] for m in [\"MLP\"]}\n",
        "\n",
        "runs = {}\n",
        "for task in tasks:\n",
        "    splits = task.download_split().split\n",
        "    X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "    cv = [s[0] for s in splits[0].values()][:CV]\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(run_model_on_task)(model_name, model, X, y, cv)\n",
        "        for model_name, model in selected_models.items()\n",
        "    )\n",
        "    runs[task.id] = dict(results)  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAN_GWXWCRKY"
      },
      "source": [
        "### Aggregate Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eeK8Sc49TM1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'test_neg_mean_squared_error'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>-5.189078</td>\n",
              "      <td>-15.938179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234     361235\n",
              "MLP -5.189078 -15.938179"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_neg_mean_squared_error'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>-4.219045</td>\n",
              "      <td>-16.880282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234     361235\n",
              "MLP -4.219045 -16.880282"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test_r2'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.503856</td>\n",
              "      <td>0.653468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234    361235\n",
              "MLP  0.503856  0.653468"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_r2'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.593732</td>\n",
              "      <td>0.645399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       361234    361235\n",
              "MLP  0.593732  0.645399"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test_rank'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "      <th>avg_rank</th>\n",
              "      <th>std_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     361234  361235  avg_rank  std_rank\n",
              "MLP     1.0     1.0       1.0       0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'train_rank'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>361234</th>\n",
              "      <th>361235</th>\n",
              "      <th>avg_rank</th>\n",
              "      <th>std_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     361234  361235  avg_rank  std_rank\n",
              "MLP     1.0     1.0       1.0       0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %%capture output\n",
        "# Aggregate Results\n",
        "import pandas as pd\n",
        "\n",
        "runs_df = pd.DataFrame(runs)\n",
        "metrics = cv_params[\"scoring\"]\n",
        "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
        "for metric in metrics:\n",
        "    metrics_df[metric] = (\n",
        "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
        "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
        "    )\n",
        "\n",
        "# Use first metric for ranking\n",
        "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
        "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
        "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
        "\n",
        "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
        "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
        "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
        "\n",
        "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
        "\n",
        "# Display all metrics and ranks\n",
        "for metric, (test, train) in metrics_df.items():\n",
        "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# output.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn2J6VVC85Ba"
      },
      "outputs": [],
      "source": [
        "# # Single model evaluation\n",
        "# from sklearn.model_selection import cross_validate\n",
        "\n",
        "# task = tasks[0]\n",
        "# splits = task.download_split().split\n",
        "# X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "# cv = [s[0] for s in splits[0].values()][:3]  # Using pre-defined OpenML splits\n",
        "# model = TemplateRegressor(*models[\"ForestMLP\"])\n",
        "# run = cross_validate(\n",
        "#     model,\n",
        "#     X,\n",
        "#     y,\n",
        "#     cv=cv\n",
        "#     **cv_params,\n",
        "# )\n",
        "# display(pd.DataFrame(run).mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
