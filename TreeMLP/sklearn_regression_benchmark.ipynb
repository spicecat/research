{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0355f62c",
   "metadata": {},
   "source": [
    "# OpenML-CTR23 Regression Benchmark\n",
    "\n",
    "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9d5da",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c211b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already present\n",
    "# %pip install -Uq pip scikit-learn openml optuna pandas jupyter ipywidgets nbformat setuptools\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Models\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "models = {\n",
    "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
    "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
    "    \"LR\": LinearRegression(),\n",
    "    \"MLP\": MLPRegressor(solver=\"sgd\", random_state=SEED),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda96a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Models\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "test_models = {\n",
    "    \"TreeMLP\": StackingRegressor(\n",
    "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
    "        final_estimator=models[\"MLP\"],\n",
    "        passthrough=True,\n",
    "    ),\n",
    "    \"ForestMLP\": StackingRegressor(\n",
    "        estimators=[\n",
    "            (f\"tree_{i}\", DecisionTreeRegressor(random_state=i)) for i in range(5)\n",
    "        ],\n",
    "        final_estimator=models[\"MLP\"],\n",
    "        passthrough=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "models.update(test_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6305108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "[\n",
    "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"numierc_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "[\n",
    "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"categorical_encoder\",\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "),\n",
    "    ]\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
    "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
    "    sparse_threshold=0.0,\n",
    ")\n",
    "\n",
    "models = {\n",
    "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    for model_name, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74c150",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization (HPO) Objective Functions\n",
    "\n",
    "The following Python cell defines functions that create 'objectives' for Optuna. Each objective function encapsulates the logic for:\n",
    "1. Defining the hyperparameter search space for a specific regression model.\n",
    "2. Evaluating a set of hyperparameters using cross-validation on the training data.\n",
    "\n",
    "These objective functions are then used by Optuna to find the best hyperparameter combination for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization Space\n",
    "hpo_spaces = {\n",
    "    \"Dummy\": {},\n",
    "    \"RF\": {\n",
    "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 20}),\n",
    "    },\n",
    "    \"LR\": {},\n",
    "    \"MLP\": {\n",
    "    \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "    \"TreeMLP\": {\n",
    "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
    "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "    \"ForestMLP\": {\n",
    "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 10}),\n",
    "        \"trees__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
    "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "}\n",
    "\n",
    "models = {\n",
    "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization Configuration\n",
    "import random\n",
    "import optuna\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Suppress Optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Study configuration\n",
    "hpo_config = {\n",
    "    \"n_trials\": 3,\n",
    "    \"timeout\": None,\n",
    "    \"show_progress_bar\": True,\n",
    "}\n",
    "\n",
    "# Cross-validation parameters for HPO objective function\n",
    "objective_cv_params = {\"cv\": 5, \"scoring\": \"neg_mean_squared_error\"}\n",
    "\n",
    "\n",
    "def create_objective(model, hpo_space, X, y):\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        param_type_map = {\n",
    "            \"int\": trial.suggest_int,\n",
    "            \"float\": trial.suggest_float,\n",
    "            \"categorical\": trial.suggest_categorical,\n",
    "        }\n",
    "        params = {\n",
    "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
    "            for p, (typ, kw) in hpo_space.items()\n",
    "        }\n",
    "        if (\n",
    "            \"model__n_trees\" in params and \"model__trees__max_depth\" in params\n",
    "        ):  # ForestMLP\n",
    "            n_trees = params.pop(\"model__n_trees\")\n",
    "            max_depth = params.pop(\"model__trees__max_depth\")\n",
    "            model[\"model\"].estimators = [\n",
    "                (\n",
    "                    f\"tree_{i}\",\n",
    "                    clone(model[\"model\"].estimators[0][1]).set_params(\n",
    "                        max_depth=max_depth, random_state=i\n",
    "                    ),\n",
    "                )\n",
    "                for i in range(n_trees)\n",
    "            ]\n",
    "        model.set_params(**params)\n",
    "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, model, hpo_space):\n",
    "        self.model = model\n",
    "        self.hpo_space = hpo_space\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        model = clone(self.model)\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "        study.optimize(\n",
    "            create_objective(model, self.hpo_space, X, y),\n",
    "            **hpo_config,\n",
    "        )\n",
    "        model.set_params(**study.best_params)\n",
    "        self.fitted_model_ = model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.fitted_model_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63771953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Benchmark Suite\n",
    "import openml\n",
    "from IPython.display import display\n",
    "\n",
    "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
    "suite = openml.study.get_suite(SUITE_ID)\n",
    "display(suite)\n",
    "print(suite.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tasks from the suite\n",
    "N_TASKS = 1\n",
    "tasks = openml.tasks.get_tasks(\n",
    "    (suite.tasks or [])[:N_TASKS], download_data=True, download_qualities=True\n",
    ")\n",
    "display(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_params = {\n",
    "    \"scoring\": [\"neg_mean_squared_error\", \"r2\"],\n",
    "    \"return_train_score\": True,\n",
    "}\n",
    "\n",
    "runs = {}\n",
    "\n",
    "# for task in tasks:\n",
    "#     model_results = {}\n",
    "#     splits = task.download_split().split\n",
    "#     X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
    "\n",
    "#     for model_name, model in models.items():\n",
    "#         print(f\"Running {model_name=} on {task.id=}...\")\n",
    "#         run = cross_validate(\n",
    "#             TemplateRegressor(*model),\n",
    "#             X,\n",
    "#             y,\n",
    "#             cv=[s[0] for s in splits[0].values()],  # Using pre-defined OpenML splits\n",
    "#             **cv_params,\n",
    "#         )\n",
    "#         model_results[model_name] = pd.DataFrame(run).mean(axis=0)\n",
    "#     runs[task.id] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd01b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Results\n",
    "import pandas as pd\n",
    "\n",
    "runs_df = pd.DataFrame(runs)\n",
    "metrics = cv_params[\"scoring\"]\n",
    "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
    "for metric in metrics:\n",
    "    metrics_df[metric] = (\n",
    "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
    "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
    "    )\n",
    "\n",
    "# Use first metric for ranking\n",
    "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
    "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
    "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
    "\n",
    "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
    "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
    "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
    "\n",
    "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
    "\n",
    "# Display all metrics and ranks\n",
    "for metric, (test, train) in metrics_df.items():\n",
    "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single model evaluation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "task = tasks[0]\n",
    "splits = task.download_split().split\n",
    "X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
    "model = TemplateRegressor(*models[\"ForestMLP\"])\n",
    "run = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=[s[0] for s in splits[0].values()][:3],  # Using pre-defined OpenML splits\n",
    "    **cv_params,\n",
    ")\n",
    "display(pd.DataFrame(run).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570228ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"ForestMLP\"][0][1].estimators[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
