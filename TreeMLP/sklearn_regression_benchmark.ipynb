{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0355f62c",
   "metadata": {},
   "source": [
    "# OpenML-CTR23 Regression Benchmark\n",
    "\n",
    "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9d5da",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c211b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq pip black blackcellmagic scikit-learn openml optuna pandas jupyter ipywidgets nbformat setuptools\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Models\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "models = {\n",
    "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
    "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
    "    \"LR\": LinearRegression(),\n",
    "    \"MLP\": MLPRegressor(solver=\"sgd\", random_state=SEED),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda96a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Models\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class ForestMLPRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_trees=5,\n",
    "        trees_max_depth=3,\n",
    "        final_estimator=MLPRegressor(),\n",
    "        final_estimator__hidden_layer_sizes=100,\n",
    "        random_state=0,\n",
    "    ):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees_max_depth = trees_max_depth\n",
    "        self.final_estimator = final_estimator\n",
    "        self.final_estimator__hidden_layer_sizes = final_estimator__hidden_layer_sizes\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _make_stacking(self):\n",
    "        return StackingRegressor(\n",
    "            estimators=[\n",
    "                (\n",
    "                    f\"tree_{i}\",\n",
    "                    DecisionTreeRegressor(\n",
    "                        max_depth=self.trees_max_depth,\n",
    "                        random_state=self.random_state + i,\n",
    "                    ),\n",
    "                )\n",
    "                for i in range(self.n_trees)\n",
    "            ],\n",
    "            final_estimator=clone(self.final_estimator).set_params(\n",
    "                hidden_layer_sizes=self.final_estimator__hidden_layer_sizes,\n",
    "            ),\n",
    "            passthrough=True,\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model_ = self._make_stacking()\n",
    "        self.model_.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "\n",
    "test_models = {\n",
    "    \"TreeMLP\": StackingRegressor(\n",
    "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
    "        final_estimator=models[\"MLP\"],\n",
    "        passthrough=True,\n",
    "    ),\n",
    "    \"ForestMLP\": ForestMLPRegressor(final_estimator=models[\"MLP\"], random_state=SEED),\n",
    "}\n",
    "\n",
    "models.update(test_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6305108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"numeric_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"categorical_encoder\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
    "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
    "    sparse_threshold=0.0,\n",
    ")\n",
    "\n",
    "models = {\n",
    "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    for model_name, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74c150",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization (HPO) Objective Functions\n",
    "\n",
    "The following Python cell defines functions that create 'objectives' for Optuna. Each objective function encapsulates the logic for:\n",
    "1. Defining the hyperparameter search space for a specific regression model.\n",
    "2. Evaluating a set of hyperparameters using cross-validation on the training data.\n",
    "\n",
    "These objective functions are then used by Optuna to find the best hyperparameter combination for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2f9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization Space\n",
    "hpo_spaces = {\n",
    "    \"Dummy\": {},\n",
    "    \"RF\": {\n",
    "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 20}),\n",
    "    },\n",
    "    \"LR\": {},\n",
    "    \"MLP\": {\n",
    "        \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "    \"TreeMLP\": {\n",
    "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
    "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "    \"ForestMLP\": {\n",
    "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 10}),\n",
    "        \"trees_max_depth\": (\"int\", {\"low\": 1, \"high\": 10}),\n",
    "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 100}),\n",
    "    },\n",
    "}\n",
    "\n",
    "models = {\n",
    "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0bdc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization Configuration\n",
    "import optuna\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Study configuration\n",
    "hpo_config = {\n",
    "    \"n_trials\": 3,\n",
    "    \"timeout\": None,\n",
    "    \"show_progress_bar\": True,\n",
    "}\n",
    "\n",
    "# Cross-validation parameters for HPO objective function\n",
    "objective_cv_params = {\"cv\": 5, \"scoring\": \"neg_mean_squared_error\"}\n",
    "\n",
    "\n",
    "def create_objective(model, hpo_space, X, y):\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        param_type_map = {\n",
    "            \"int\": trial.suggest_int,\n",
    "            \"float\": trial.suggest_float,\n",
    "            \"categorical\": trial.suggest_categorical,\n",
    "        }\n",
    "        params = {\n",
    "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
    "            for p, (typ, kw) in hpo_space.items()\n",
    "        }\n",
    "        model.set_params(**params)\n",
    "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, model, hpo_space):\n",
    "        self.model = model\n",
    "        self.hpo_space = hpo_space\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        model = clone(self.model)\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "        study.optimize(\n",
    "            create_objective(model, self.hpo_space, X, y),\n",
    "            **hpo_config,\n",
    "        )\n",
    "        model.set_params(**study.best_params)\n",
    "        self.fitted_model_ = model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.fitted_model_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63771953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Benchmark Suite\n",
       "======================\n",
       "ID..............: 353\n",
       "Name............: OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
       "Status..........: active\n",
       "Main Entity Type: task\n",
       "Study URL.......: https://www.openml.org/s/353\n",
       "# of Data.......: 35\n",
       "# of Tasks......: 35\n",
       "Creator.........: https://www.openml.org/u/30127\n",
       "Upload Time.....: 2023-05-31 16:39:49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inclusion Criteria:  \n",
      "\n",
      "* There are between 500 and 100000 observations.\n",
      "* There are less than 5000 features after one-hot encoding all categorical features.\n",
      "* The dataset is not in a sparse format.\n",
      "* The observations are i.i.d., which means that we exclude datasets that have time dependencies or require grouped data splits.\n",
      "* The dataset comes with a source or reference that clearly describes it.\n",
      "* We did not consider the dataset to be artificial, but allowed simulated datasets.\n",
      "* The data is not a subset of a larger dataset.\n",
      "* There is a numeric target variable with at least 5 different values.\n",
      "* The dataset is not trivially solvable by a linear model, i.e. the training error of a linear model fitted to the whole data has an R2 of less than 1.\n",
      "* The dataset does not have ethical concerns.\n",
      "* The use of the dataset for benchmarking is not forbidden.\n",
      "\n",
      "In addition to the datasets, the OpenML tasks also contain resampling splits, which were determined according to the following rule: If there are less than 1000 observations we use 10 times repeated 10-fold CV. If there are more than 10000 observations we use a 33% holdout split, and for everything\n",
      "between, we use 10-fold CV.\n",
      "\n",
      "Please cite the following paper if you use the suite:\n",
      "\n",
      "@inproceedings{\n",
      "  fischer2023openmlctr,  \n",
      "  title={Open{ML}-{CTR}23 {\\textendash} A curated tabular regression benchmarking suite},  \n",
      "  author={Sebastian Felix Fischer and Liana Harutyunyan Matthias Feurer and Bernd Bischl},  \n",
      "  booktitle={AutoML Conference 2023 (Workshop)},  \n",
      "  year={2023},  \n",
      "  url={https://openreview.net/forum?id=HebAOoMm94}\n",
      "}\n",
      "\n",
      "If you notice a problem with one of the datasets, please add a comment here: https://github.com/slds-lmu/paper_2023_regression_suite/issues/1\n"
     ]
    }
   ],
   "source": [
    "# Define Benchmark Suite\n",
    "import openml\n",
    "from IPython.display import display\n",
    "\n",
    "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
    "suite = openml.study.get_suite(SUITE_ID)\n",
    "display(suite)\n",
    "print(suite.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5d7958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OpenML Regression Task\n",
       " ======================\n",
       " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
       " Task ID..............: 361234\n",
       " Task URL.............: https://www.openml.org/t/361234\n",
       " Estimation Procedure.: crossvalidation\n",
       " Target Feature.......: rings]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download tasks from the suite\n",
    "N_TASKS = 1\n",
    "tasks = openml.tasks.get_tasks(\n",
    "    (suite.tasks or [])[:N_TASKS], download_data=True, download_qualities=True\n",
    ")\n",
    "display(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_params = {\n",
    "    \"scoring\": [\"neg_mean_squared_error\", \"r2\"],\n",
    "    \"return_train_score\": True,\n",
    "}\n",
    "\n",
    "runs = {}\n",
    "\n",
    "for task in tasks:\n",
    "    model_results = {}\n",
    "    splits = task.download_split().split\n",
    "    X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Running {model_name=} on {task.id=}...\")\n",
    "        run = cross_validate(\n",
    "            TemplateRegressor(*model),\n",
    "            X,\n",
    "            y,\n",
    "            cv=[s[0] for s in splits[0].values()],  # Using pre-defined OpenML splits\n",
    "            **cv_params,\n",
    "        )\n",
    "        model_results[model_name] = pd.DataFrame(run).mean(axis=0)\n",
    "    runs[task.id] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd01b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_neg_mean_squared_error'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train_neg_mean_squared_error'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test_r2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train_r2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test_rank'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>std_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [avg_rank, std_rank]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train_rank'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>std_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [avg_rank, std_rank]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate Results\n",
    "import pandas as pd\n",
    "\n",
    "runs_df = pd.DataFrame(runs)\n",
    "metrics = cv_params[\"scoring\"]\n",
    "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
    "for metric in metrics:\n",
    "    metrics_df[metric] = (\n",
    "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
    "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
    "    )\n",
    "\n",
    "    # Use first metric for ranking\n",
    "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
    "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
    "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
    "\n",
    "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
    "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
    "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
    "\n",
    "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
    "\n",
    "# Display all metrics and ranks\n",
    "for metric, (test, train) in metrics_df.items():\n",
    "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb73546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f2e0f78b774a50b7d5ea348dd266e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7ab24973c74b79bc9a6a7623bcf080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d518f80ee7f44c938c543bc6d056f997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time                        19.015890\n",
       "score_time                       0.009783\n",
       "test_neg_mean_squared_error     -5.436803\n",
       "train_neg_mean_squared_error    -3.664474\n",
       "test_r2                          0.479871\n",
       "train_r2                         0.647085\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Single model evaluation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "task = tasks[0]\n",
    "splits = task.download_split().split\n",
    "X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
    "model = TemplateRegressor(*models[\"ForestMLP\"])\n",
    "run = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=[s[0] for s in splits[0].values()][:3],  # Using pre-defined OpenML splits\n",
    "    **cv_params,\n",
    ")\n",
    "display(pd.DataFrame(run).mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
