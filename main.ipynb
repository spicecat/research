{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yNSyFZvf0Leo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression, SGDRegressor, PassiveAggressiveRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, StackingRegressor, VotingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from xgboost import XGBRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","from models import MLP, FONN1, FONN2, TREENN1, TREENN2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["((506, 12), (506,))"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load the Boston dataset\n","data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22,  # type: ignore\n","                     header=None)  # type: ignore\n","X = np.hstack([raw_df.values[::2, :-1], raw_df.values[1::2, :2]])\n","y = raw_df.values[1::2, 2]\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","X.shape, y.shape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["((404, 12), (102, 12), (404,), (102,))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to train and evaluate a model\n","def train_evaluate_model(model, X_train, X_test, y_train, y_test):\n","    start_time = time.time()\n","    model.fit(X_train, y_train)\n","    end_time = time.time()\n","    train_time = end_time - start_time\n","\n","    start_time = time.time()\n","    predictions = model.predict(X_test)\n","    end_time = time.time()\n","    comp_time = end_time - start_time\n","\n","    r2 = r2_score(y_test, predictions)\n","    mae = mean_absolute_error(y_test, predictions)\n","    mse = mean_squared_error(y_test, predictions)\n","\n","    return r2, mae, mse, train_time, comp_time\n","\n","\n","# Initialize models\n","models = {\n","    \"Linear Regression\": LinearRegression(),\n","    \"Ridge Regression\": Ridge(),\n","    \"Lasso Regression\": Lasso(),\n","    \"ElasticNet Regression\": ElasticNet(),\n","    \"Bayesian Ridge Regression\": BayesianRidge(),\n","    \"ARD Regression\": ARDRegression(),\n","    \"SGD Regressor\": SGDRegressor(),\n","    \"Passive Aggressive Regressor\": PassiveAggressiveRegressor(),\n","    \"Support Vector Regression\": SVR(),\n","    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n","    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n","    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n","    \"XGBoost Regressor\": XGBRegressor(random_state=42),\n","    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=42),\n","    \"Bagging Regressor\": BaggingRegressor(random_state=42),\n","    \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=42),\n","    \"HistGradientBoosting Regressor\": HistGradientBoostingRegressor(random_state=42),\n","    \"Stacking Regressor\": StackingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42))\n","    ], final_estimator=Ridge()),\n","    \"Voting Regressor\": VotingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42)),\n","        ('gb', GradientBoostingRegressor(random_state=42))\n","    ])\n","}\n","\n","# Train and evaluate models\n","results = {}\n","for name, model in models.items():\n","    r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","        model, X_train, X_test, y_train, y_test)\n","    results[name] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                     \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize MLP\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","learning_rate = 0.01\n","epochs = 1000\n","\n","mlp = MLP(input_dim, hidden_dim, output_dim,\n","          learning_rate=learning_rate, epochs=epochs)\n","r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","    mlp, X_train, X_test, y_train, y_test)\n","results[\"Custom MLP\"] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                         \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize FONN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","num_trees_input = 10\n","learning_rate = 0.001 # Reduced learning rate for FONN1\n","epochs = 4000 # Increase epochs for FONN1\n","\n","fonn1 = FONN1(input_dim, hidden_dim, output_dim, num_trees_input,\n","              learning_rate=learning_rate, epochs=epochs)\n","r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","    fonn1, X_train, X_test, y_train, y_test)\n","results[\"FONN1\"] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                    \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize FONN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","num_trees_hidden = 10\n","epochs = 1000\n","learning_rate = 0.01\n","\n","fonn2 = FONN2(input_dim, hidden_dim, output_dim, num_trees_hidden,\n","              learning_rate=learning_rate, epochs=epochs)\n","r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","    fonn2, X_train, X_test, y_train, y_test)\n","results[\"FONN2\"] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                    \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize TREENN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","learning_rate = 0.01\n","epochs = 1000\n","\n","treenn1 = TREENN1(input_dim, hidden_dim, output_dim, learning_rate=learning_rate, epochs=epochs)\n","r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","    treenn1, X_train, X_test, y_train, y_test)\n","results[\"TREENN1\"] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                      \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize TREENN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","learning_rate = 0.001\n","epochs = 4000 # Increase epochs\n","\n","treenn2 = TREENN1(input_dim, hidden_dim, output_dim,\n","                  learning_rate=learning_rate, epochs=epochs)\n","r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","    treenn2, X_train, X_test, y_train, y_test)\n","results[\"TREENN2\"] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                      \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Measure computational time and predict house prices using the decision trees in the hidden layer\n","# start_time = time.time()\n","# fonn2_tree_predictions = fonn2.tree_predict(X_test)\n","# end_time = time.time()\n","# fonn2_tree_comp_time = end_time - start_time\n","\n","# fonn2_tree_r2 = r2_score(y_test, fonn2_tree_predictions)\n","# fonn2_tree_mae = mean_absolute_error(y_test, fonn2_tree_predictions)\n","# fonn2_tree_mse = mean_squared_error(y_test, fonn2_tree_predictions)\n","\n","# results[\"Tree-based Predictions (FONN2)\"] = {\"R² Score\": fonn2_tree_r2, \"MAE\": fonn2_tree_mae,\n","#                                              \"MSE\": fonn2_tree_mse, \"Train Time (s)\": fonn2_train_time, \"Comp Time (s)\": fonn2_tree_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Combine 10 decision trees and evaluate the ensemble model\n","# start_time = time.time()\n","# trees = [DecisionTreeRegressor(max_depth=5, random_state=i).fit(\n","#     X_train, y_train) for i in range(10)]\n","# end_time = time.time()\n","# ensemble_train_time = end_time - start_time\n","\n","# start_time = time.time()\n","# ensemble_predictions = np.mean(\n","#     [tree.predict(X_test) for tree in trees], axis=0)\n","# end_time = time.time()\n","# ensemble_comp_time = end_time - start_time\n","\n","# ensemble_r2 = r2_score(y_test, ensemble_predictions)\n","# ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n","# ensemble_mse = mean_squared_error(y_test, ensemble_predictions)\n","\n","# results[\"Ensemble of 10 Trees\"] = {\"R² Score\": ensemble_r2, \"MAE\": ensemble_mae,\n","#                                    \"MSE\": ensemble_mse, \"Train Time (s)\": ensemble_train_time, \"Comp Time (s)\": ensemble_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Measure computational time and predict house prices using the decision tree in the hidden layer\n","# start_time = time.time()\n","# treenn2_tree_predictions = treenn2.tree_hidden.predict(X_test)\n","# end_time = time.time()\n","# treenn2_tree_comp_time = end_time - start_time\n","\n","# treenn2_tree_r2 = r2_score(y_test, treenn2_tree_predictions)\n","# treenn2_tree_mae = mean_absolute_error(y_test, treenn2_tree_predictions)\n","# treenn2_tree_mse = mean_squared_error(y_test, treenn2_tree_predictions)\n","\n","# results[\"Tree-based Predictions (TREENN2)\"] = {\"R² Score\": treenn2_tree_r2, \"MAE\": treenn2_tree_mae,\n","#                                                \"MSE\": treenn2_tree_mse, \"Train Time (s)\": treenn2_train_time, \"Comp Time (s)\": treenn2_tree_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert results to a DataFrame for better visualization\n","results_df = pd.DataFrame(results).T\n","print(results_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get and print tree importances\n","tree_importances = fonn2.get_tree_importances()"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
