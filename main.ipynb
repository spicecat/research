{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yNSyFZvf0Leo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression, SGDRegressor, PassiveAggressiveRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, StackingRegressor, VotingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from xgboost import XGBRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","from models import FONN1, FONN2, TREENN1, TREENN2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["((506, 12), (506,))"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load the Boston dataset\n","data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22,  # type: ignore\n","                     header=None)  # type: ignore\n","X = np.hstack([raw_df.values[::2, :-1], raw_df.values[1::2, :2]])\n","y = raw_df.values[1::2, 2]\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","X.shape, y.shape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["((404, 12), (102, 12), (404,), (102,))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to train and evaluate a model\n","def train_evaluate_model(model, X_train, X_test, y_train, y_test):\n","    start_time = time.time()\n","    model.fit(X_train, y_train)\n","    end_time = time.time()\n","    train_time = end_time - start_time\n","\n","    start_time = time.time()\n","    predictions = model.predict(X_test)\n","    end_time = time.time()\n","    comp_time = end_time - start_time\n","\n","    r2 = r2_score(y_test, predictions)\n","    mae = mean_absolute_error(y_test, predictions)\n","    mse = mean_squared_error(y_test, predictions)\n","\n","    return r2, mae, mse, train_time, comp_time\n","\n","\n","# Initialize models\n","models = {\n","    \"Linear Regression\": LinearRegression(),\n","    \"Ridge Regression\": Ridge(),\n","    \"Lasso Regression\": Lasso(),\n","    \"ElasticNet Regression\": ElasticNet(),\n","    \"Bayesian Ridge Regression\": BayesianRidge(),\n","    \"ARD Regression\": ARDRegression(),\n","    \"SGD Regressor\": SGDRegressor(),\n","    \"Passive Aggressive Regressor\": PassiveAggressiveRegressor(),\n","    \"Support Vector Regression\": SVR(),\n","    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n","    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n","    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n","    \"XGBoost Regressor\": XGBRegressor(random_state=42),\n","    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=42),\n","    \"Bagging Regressor\": BaggingRegressor(random_state=42),\n","    \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=42),\n","    \"HistGradientBoosting Regressor\": HistGradientBoostingRegressor(random_state=42),\n","    \"Stacking Regressor\": StackingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42))\n","    ], final_estimator=Ridge()),\n","    \"Voting Regressor\": VotingRegressor(estimators=[\n","        ('lr', LinearRegression()),\n","        ('rf', RandomForestRegressor(n_estimators=10, random_state=42)),\n","        ('gb', GradientBoostingRegressor(random_state=42))\n","    ])\n","}\n","\n","# Train and evaluate models\n","results = {}\n","for name, model in models.items():\n","    r2, mae, mse, fit_time, comp_time = train_evaluate_model(\n","        model, X_train, X_test, y_train, y_test)\n","    results[name] = {\"R² Score\": r2, \"MAE\": mae, \"MSE\": mse,\n","                     \"Train Time (s)\": fit_time, \"Comp Time (s)\": comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Initialize and train MLP\n","# input_dim = X_train.shape[1]\n","# hidden_dim = 10  # Increased hidden layer size\n","# output_dim = 1\n","# num_trees_input = 0\n","# epochs = 20000  # Increased number of epochs\n","# learning_rate = 0.0001  # Decreased learning rate\n","\n","# start_time = time.time()\n","# mlp = FONN1(input_dim, hidden_dim, output_dim, num_trees_input)\n","# mlp.train(X_train, y_train, epochs, learning_rate)\n","# end_time = time.time()\n","# mlp_train_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train FONN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10  # Increased hidden layer size\n","output_dim = 1\n","num_trees_input = 10\n","epochs = 20000  # Increased number of epochs\n","learning_rate = 0.0001  # Decreased learning rate\n","\n","start_time = time.time()\n","fonn1 = FONN1(input_dim, hidden_dim, output_dim, num_trees_input)\n","fonn1.train(X_train, y_train, epochs, learning_rate)\n","end_time = time.time()\n","fonn1_train_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train FONN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","num_trees_hidden = 10\n","epochs = 1000\n","learning_rate = 0.001\n","\n","start_time = time.time()\n","fonn2 = FONN2(input_dim, hidden_dim, output_dim, num_trees_hidden)\n","fonn2.train(X_train, y_train, epochs, learning_rate)\n","end_time = time.time()\n","fonn2_train_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train TREENN1\n","input_dim = X_train.shape[1]\n","hidden_dim = 10  # Hidden layer size\n","output_dim = 1\n","epochs = 20000  # Number of epochs\n","learning_rate = 0.0001  # Learning rate\n","\n","start_time = time.time()\n","treenn1 = TREENN1(input_dim, hidden_dim, output_dim)\n","treenn1.train(X_train, y_train, epochs, learning_rate)\n","end_time = time.time()\n","treenn1_train_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize and train TREENN2\n","input_dim = X_train.shape[1]\n","hidden_dim = 10\n","output_dim = 1\n","epochs = 1000\n","learning_rate = 0.001\n","\n","start_time = time.time()\n","treenn2 = TREENN2(input_dim, hidden_dim, output_dim)\n","treenn2.train(X_train, y_train, epochs, learning_rate)\n","end_time = time.time()\n","treenn2_train_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the FONN1 model\n","start_time = time.time()\n","fonn1_predictions = fonn1.forward(X_test)\n","end_time = time.time()\n","fonn1_comp_time = end_time - start_time\n","\n","fonn1_r2 = r2_score(y_test, fonn1_predictions)\n","fonn1_mae = mean_absolute_error(y_test, fonn1_predictions)\n","fonn1_mse = mean_squared_error(y_test, fonn1_predictions)\n","\n","results[\"FONN1\"] = {\"R² Score\": fonn1_r2, \"MAE\": fonn1_mae, \"MSE\": fonn1_mse,\n","                    \"Train Time (s)\": fonn1_train_time, \"Comp Time (s)\": fonn1_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the custom MLP model\n","start_time = time.time()\n","fonn2_predictions = fonn2.forward(X_test)\n","end_time = time.time()\n","fonn2_comp_time = end_time - start_time\n","\n","fonn2_r2 = r2_score(y_test, fonn2_predictions)\n","fonn2_mae = mean_absolute_error(y_test, fonn2_predictions)\n","fonn2_mse = mean_squared_error(y_test, fonn2_predictions)\n","\n","results[\"FONN2\"] = {\"R² Score\": fonn2_r2, \"MAE\": fonn2_mae, \"MSE\": fonn2_mse,\n","                    \"Train Time (s)\": fonn2_train_time, \"Comp Time (s)\": fonn2_comp_time}\n","\n","# Measure computational time and predict house prices using the decision trees in the hidden layer\n","start_time = time.time()\n","fonn2_tree_predictions = fonn2.tree_predict(X_test)\n","end_time = time.time()\n","fonn2_tree_comp_time = end_time - start_time\n","\n","fonn2_tree_r2 = r2_score(y_test, fonn2_tree_predictions)\n","fonn2_tree_mae = mean_absolute_error(y_test, fonn2_tree_predictions)\n","fonn2_tree_mse = mean_squared_error(y_test, fonn2_tree_predictions)\n","\n","results[\"Tree-based Predictions (FONN2)\"] = {\"R² Score\": fonn2_tree_r2, \"MAE\": fonn2_tree_mae,\n","                                             \"MSE\": fonn2_tree_mse, \"Train Time (s)\": fonn2_train_time, \"Comp Time (s)\": fonn2_tree_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Combine 10 decision trees and evaluate the ensemble model\n","start_time = time.time()\n","trees = [DecisionTreeRegressor(max_depth=5, random_state=i).fit(\n","    X_train, y_train) for i in range(10)]\n","end_time = time.time()\n","ensemble_train_time = end_time - start_time\n","\n","start_time = time.time()\n","ensemble_predictions = np.mean(\n","    [tree.predict(X_test) for tree in trees], axis=0)\n","end_time = time.time()\n","ensemble_comp_time = end_time - start_time\n","\n","ensemble_r2 = r2_score(y_test, ensemble_predictions)\n","ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n","ensemble_mse = mean_squared_error(y_test, ensemble_predictions)\n","\n","results[\"Ensemble of 10 Trees\"] = {\"R² Score\": ensemble_r2, \"MAE\": ensemble_mae,\n","                                   \"MSE\": ensemble_mse, \"Train Time (s)\": ensemble_train_time, \"Comp Time (s)\": ensemble_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the TREENN1 model\n","start_time = time.time()\n","treenn1_predictions = treenn1.forward(X_test)\n","end_time = time.time()\n","treenn1_comp_time = end_time - start_time\n","\n","treenn1_r2 = r2_score(y_test, treenn1_predictions)\n","treenn1_mae = mean_absolute_error(y_test, treenn1_predictions)\n","treenn1_mse = mean_squared_error(y_test, treenn1_predictions)\n","\n","results[\"TREENN1\"] = {\"R² Score\": treenn1_r2, \"MAE\": treenn1_mae, \"MSE\": treenn1_mse,\n","                      \"Train Time (s)\": treenn1_train_time, \"Comp Time (s)\": treenn1_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Measure computational time and evaluate the custom MLP model\n","start_time = time.time()\n","treenn2_predictions = treenn2.forward(X_test)\n","end_time = time.time()\n","treenn2_comp_time = end_time - start_time\n","\n","treenn2_r2 = r2_score(y_test, treenn2_predictions)\n","treenn2_mae = mean_absolute_error(y_test, treenn2_predictions)\n","treenn2_mse = mean_squared_error(y_test, treenn2_predictions)\n","\n","results[\"TREENN2\"] = {\"R² Score\": treenn2_r2, \"MAE\": treenn2_mae,\n","                      \"MSE\": treenn2_mse, \"Train Time (s)\": treenn2_train_time, \"Comp Time (s)\": treenn2_comp_time}\n","\n","# Measure computational time and predict house prices using the decision tree in the hidden layer\n","start_time = time.time()\n","treenn2_tree_predictions = treenn2.tree_hidden.predict(treenn2.a1)\n","end_time = time.time()\n","treenn2_tree_comp_time = end_time - start_time\n","\n","treenn2_tree_r2 = r2_score(y_test, treenn2_tree_predictions)\n","treenn2_tree_mae = mean_absolute_error(y_test, treenn2_tree_predictions)\n","treenn2_tree_mse = mean_squared_error(y_test, treenn2_tree_predictions)\n","\n","results[\"Tree-based Predictions (TREENN2)\"] = {\"R² Score\": treenn2_tree_r2, \"MAE\": treenn2_tree_mae,\n","                                               \"MSE\": treenn2_tree_mse, \"Train Time (s)\": treenn2_train_time, \"Comp Time (s)\": treenn2_tree_comp_time}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert results to a DataFrame for better visualization\n","results_df = pd.DataFrame(results).T\n","print(results_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get and print tree importances\n","tree_importances = fonn2.get_tree_importances()"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
