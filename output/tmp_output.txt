0 [indus < 9.655] score=160.699, samples=15, value=22.460
  1 [zn < 26.500] score=16.304, samples=7, value=27.857
    2 score=16.007, samples=3, value=24.233
    2 score=16.528, samples=4, value=30.575
  1 [crim < 4.873] score=99.461, samples=8, value=17.738
    2 [crim < 1.341] score=10.080, samples=6, value=18.233
      3 score=2.880, samples=2, value=13.100
      3 score=13.680, samples=4, value=20.800
    2 score=111.005, samples=2, value=16.250
Variables used:
indus zn crim
Number of terminal nodes: 5
Residual mean deviance: 39.662
Samples: 15
Sum of squared residuals: 396.620

n iterations (60000)
hidden layers (1)
nodes in hidden layers (2)
activation function (sigmoid)
batch size (64, n/100)
epochs
https://colab.research.google.com/drive/1d8dpSOooMQ9DL1l8sjl2Il1Z2dHs3mm4?usp=sharing#scrollTo=506gxrI4Qo_O
stephen ryan, guofu zhou
bootstrapping(data, B): B trees; Add B columns to dataset
random sampling with replacement
SHAP Value: how y1 and y2 impact y
batch normalization
https://www.datacamp.com/tutorial/neural-network-models-r
https://rviews.rstudio.com/2020/07/20/shallow-neural-net-from-scratch-using-r-part-1/
