{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spicecat/research/blob/main/regression_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsf3KDMkBnJJ"
      },
      "source": [
        "# OpenML-CTR23 Regression Benchmark\n",
        "\n",
        "This notebook benchmarks a variety of regression models on the `OpenML-CTR23 - A curated tabular regression benchmarking suite` benchmark suite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9ZbqI_CAHx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lm1ejpmI6RFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8482a5f2-5c9e-4c2b-91d9-6cc541aa2034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%pip install -q pip black blackcellmagic scikit-learn openml optuna optuna-dashboard joblib\n",
        "%load_ext blackcellmagic\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fJXFGBR5OV6-"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"\n",
        "N_TRIALS = 15\n",
        "OBJECTIVE_CV = 3\n",
        "N_TASKS = 10\n",
        "CV = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GT0rGO7CByh"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ],
      "metadata": {
        "id": "qwU17NS4u-g3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qIDiz21W9Hgm"
      },
      "outputs": [],
      "source": [
        "# Control Models\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "models = {\n",
        "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
        "    \"RF\": RandomForestRegressor(max_depth=2, random_state=SEED),\n",
        "    # \"LR\": LinearRegression(),\n",
        "    \"MLP\": MLPRegressor(solver=\"adam\", random_state=SEED),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p-5NQvgi9HqO"
      },
      "outputs": [],
      "source": [
        "# Test Models\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class ForestMLPRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_trees=5,\n",
        "        trees_max_depth=2,\n",
        "        final_estimator=MLPRegressor(),\n",
        "        final_estimator__hidden_layer_sizes=100,\n",
        "        random_state=0,\n",
        "    ):\n",
        "        self.n_trees = n_trees\n",
        "        self.trees_max_depth = trees_max_depth\n",
        "        self.final_estimator = final_estimator\n",
        "        self.final_estimator__hidden_layer_sizes = final_estimator__hidden_layer_sizes\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _make_stacking(self):\n",
        "        return StackingRegressor(\n",
        "            estimators=[\n",
        "                (\n",
        "                    f\"tree_{i}\",\n",
        "                    DecisionTreeRegressor(\n",
        "                        max_depth=self.trees_max_depth,\n",
        "                        random_state=self.random_state + i,\n",
        "                    ),\n",
        "                )\n",
        "                for i in range(self.n_trees)\n",
        "            ],\n",
        "            final_estimator=clone(self.final_estimator).set_params(\n",
        "                hidden_layer_sizes=self.final_estimator__hidden_layer_sizes,\n",
        "            ),\n",
        "            passthrough=True,\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_ = self._make_stacking()\n",
        "        self.model_.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "\n",
        "test_models = {\n",
        "    \"TreeMLP\": StackingRegressor(\n",
        "        estimators=[(\"tree\", DecisionTreeRegressor(random_state=SEED))],\n",
        "        final_estimator=models[\"MLP\"],\n",
        "        passthrough=True,\n",
        "    ),\n",
        "    # \"ForestMLP\": ForestMLPRegressor(final_estimator=models[\"MLP\"], random_state=SEED),\n",
        "}\n",
        "\n",
        "models.update(test_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9grQGt7BCJOg"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TsmnhtRu9Hzp"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import numpy as np\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    [\n",
        "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"numeric_scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"categorical_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\n",
        "            \"categorical_encoder\",\n",
        "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "preprocessor = make_column_transformer(\n",
        "    (numeric_transformer, make_column_selector(dtype_include=np.number)),  # type: ignore\n",
        "    (categorical_transformer, make_column_selector(dtype_include=[\"object\", \"category\"])),  # type: ignore\n",
        "    sparse_threshold=0.0,\n",
        ")\n",
        "\n",
        "models = {\n",
        "    model_name: Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
        "    for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjW8qkdTCKTB"
      },
      "source": [
        "### Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ve1gazIt9H9A"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Space\n",
        "hpo_spaces = {\n",
        "    \"Dummy\": {},\n",
        "    \"RF\": {\n",
        "        \"n_estimators\": (\"int\", {\"low\": 5, \"high\": 20}),\n",
        "        \"max_depth\": (\"int\", {\"low\": 1, \"high\": 3}),\n",
        "    },\n",
        "    \"LR\": {},\n",
        "    \"MLP\": {\n",
        "        \"hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 20}),\n",
        "    },\n",
        "    \"TreeMLP\": {\n",
        "        \"tree__max_depth\": (\"int\", {\"low\": 1, \"high\": 3}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 20}),\n",
        "    },\n",
        "    \"ForestMLP\": {\n",
        "        \"n_trees\": (\"int\", {\"low\": 2, \"high\": 3}),\n",
        "        \"trees_max_depth\": (\"int\", {\"low\": 1, \"high\": 3}),\n",
        "        \"final_estimator__hidden_layer_sizes\": (\"int\", {\"low\": 5, \"high\": 20}),\n",
        "    },\n",
        "}\n",
        "\n",
        "models = {\n",
        "    model_name: (model, hpo_spaces[model_name]) for model_name, model in models.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VvYcl3Fl9IEt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization Configuration\n",
        "import optuna\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Study configuration\n",
        "hpo_config = {\n",
        "    \"n_trials\": N_TRIALS,\n",
        "    \"timeout\": None,\n",
        "    \"show_progress_bar\": True,\n",
        "}\n",
        "\n",
        "# Cross-validation parameters for HPO objective function\n",
        "objective_cv_params = {\"cv\": OBJECTIVE_CV, \"scoring\": \"neg_mean_squared_error\"}\n",
        "\n",
        "\n",
        "def create_objective(model, hpo_space, X, y):\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        param_type_map = {\n",
        "            \"int\": trial.suggest_int,\n",
        "            \"float\": trial.suggest_float,\n",
        "            \"categorical\": trial.suggest_categorical,\n",
        "        }\n",
        "        params = {\n",
        "            f\"model__{p}\": param_type_map[typ](f\"model__{p}\", **kw)\n",
        "            for p, (typ, kw) in hpo_space.items()\n",
        "        }\n",
        "        model.set_params(**params)\n",
        "        return cross_val_score(model, X, y, **objective_cv_params).mean()\n",
        "\n",
        "    return objective"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storage = optuna.storages.JournalStorage(\n",
        "    optuna.storages.journal.JournalFileBackend(\"optuna_journal_storage.log\")  # type: ignore\n",
        ")\n",
        "\n",
        "\n",
        "class TemplateRegressor(RegressorMixin, BaseEstimator):\n",
        "    _split_counters = {}\n",
        "\n",
        "    def __init__(self, study_name, model, hpo_space):\n",
        "        self.model = model\n",
        "        self.hpo_space = hpo_space\n",
        "        self.study_name = study_name\n",
        "        if study_name not in TemplateRegressor._split_counters:\n",
        "            TemplateRegressor._split_counters[study_name] = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        model = clone(self.model)\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        sampler = optuna.samplers.TPESampler(seed=SEED)\n",
        "\n",
        "        study_name = f\"{self.study_name}_{TemplateRegressor._split_counters[self.study_name]}\"\n",
        "        TemplateRegressor._split_counters[self.study_name] += 1\n",
        "\n",
        "        study = optuna.create_study(\n",
        "            storage=storage,\n",
        "            sampler=sampler,\n",
        "            study_name=study_name,\n",
        "            direction=\"maximize\",\n",
        "            load_if_exists=True,\n",
        "        )\n",
        "        study.optimize(\n",
        "            create_objective(model, self.hpo_space, X, y),\n",
        "            **hpo_config,\n",
        "        )\n",
        "        model.set_params(**study.best_params)\n",
        "        self.fitted_model_ = model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.fitted_model_.predict(X)"
      ],
      "metadata": {
        "id": "4WfHLF88bz8Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ge2W26CNXp"
      },
      "source": [
        "## Benchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Benchmark Suite"
      ],
      "metadata": {
        "id": "56iCwO8Bvasx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hNEd-zKK9PUu",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "b1cd5619-776f-4092-f85a-18946405a919"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OpenML Benchmark Suite\n",
              "======================\n",
              "ID..............: 353\n",
              "Name............: OpenML-CTR23 - A curated tabular regression benchmarking suite\n",
              "Status..........: active\n",
              "Main Entity Type: task\n",
              "Study URL.......: https://www.openml.org/s/353\n",
              "# of Data.......: 35\n",
              "# of Tasks......: 35\n",
              "Creator.........: https://www.openml.org/u/30127\n",
              "Upload Time.....: 2023-05-31 16:39:49"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inclusion Criteria:  \n",
            "\n",
            "* There are between 500 and 100000 observations.\n",
            "* There are less than 5000 features after one-hot encoding all categorical features.\n",
            "* The dataset is not in a sparse format.\n",
            "* The observations are i.i.d., which means that we exclude datasets that have time dependencies or require grouped data splits.\n",
            "* The dataset comes with a source or reference that clearly describes it.\n",
            "* We did not consider the dataset to be artificial, but allowed simulated datasets.\n",
            "* The data is not a subset of a larger dataset.\n",
            "* There is a numeric target variable with at least 5 different values.\n",
            "* The dataset is not trivially solvable by a linear model, i.e. the training error of a linear model fitted to the whole data has an R2 of less than 1.\n",
            "* The dataset does not have ethical concerns.\n",
            "* The use of the dataset for benchmarking is not forbidden.\n",
            "\n",
            "In addition to the datasets, the OpenML tasks also contain resampling splits, which were determined according to the following rule: If there are less than 1000 observations we use 10 times repeated 10-fold CV. If there are more than 10000 observations we use a 33% holdout split, and for everything\n",
            "between, we use 10-fold CV.\n",
            "\n",
            "Please cite the following paper if you use the suite:\n",
            "\n",
            "@inproceedings{\n",
            "  fischer2023openmlctr,  \n",
            "  title={Open{ML}-{CTR}23 {\\textendash} A curated tabular regression benchmarking suite},  \n",
            "  author={Sebastian Felix Fischer and Liana Harutyunyan Matthias Feurer and Bernd Bischl},  \n",
            "  booktitle={AutoML Conference 2023 (Workshop)},  \n",
            "  year={2023},  \n",
            "  url={https://openreview.net/forum?id=HebAOoMm94}\n",
            "}\n",
            "\n",
            "If you notice a problem with one of the datasets, please add a comment here: https://github.com/slds-lmu/paper_2023_regression_suite/issues/1\n"
          ]
        }
      ],
      "source": [
        "# Define Benchmark Suite\n",
        "import openml\n",
        "from IPython.display import display\n",
        "\n",
        "# SUITE_ID = \"8f0ea660163b436bbd4abd49665c7b1d\"  # OpenML-CTR23\n",
        "suite = openml.study.get_suite(SUITE_ID)\n",
        "display(suite)\n",
        "print(suite.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cyya8O9Q9Qld",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d590c083-b9ef-4797-9c9a-419566ae31dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361618\n",
              " Task URL.............: https://www.openml.org/t/361618\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: area,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361619\n",
              " Task URL.............: https://www.openml.org/t/361619\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: G3,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361617\n",
              " Task URL.............: https://www.openml.org/t/361617\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: heating_load,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361622\n",
              " Task URL.............: https://www.openml.org/t/361622\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: Price,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361621\n",
              " Task URL.............: https://www.openml.org/t/361621\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: LC50,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361237\n",
              " Task URL.............: https://www.openml.org/t/361237\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: strength,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361243\n",
              " Task URL.............: https://www.openml.org/t/361243\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: latitude,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361244\n",
              " Task URL.............: https://www.openml.org/t/361244\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: c_class_flares,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361264\n",
              " Task URL.............: https://www.openml.org/t/361264\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: counts_for_sons_current_occupation,\n",
              " OpenML Regression Task\n",
              " ======================\n",
              " Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_REGRESSION\n",
              " Task ID..............: 361616\n",
              " Task URL.............: https://www.openml.org/t/361616\n",
              " Estimation Procedure.: crossvalidation\n",
              " Target Feature.......: RS]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download tasks from the suite\n",
        "# N_TASKS = 2\n",
        "tasks = openml.tasks.get_tasks(\n",
        "    (suite.tasks or []), download_data=True, download_qualities=True\n",
        ")\n",
        "tasks.sort(key=lambda t: t.get_dataset().qualities.get(\"NumberOfInstances\", 0))  # type: ignore\n",
        "tasks = tasks[:N_TASKS]\n",
        "display(tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op3VR4BlCPkQ"
      },
      "source": [
        "### Benchmark Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OgbkUwM2ujKc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "ec120c13-269e-4896-85bc-9f7d7295d212"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8787, \"/dashboard\", \"100%\", \"400\", false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bottle v0.13.3 server starting up (using WSGIRefServer())...\n",
            "Listening on http://localhost:8787/\n",
            "Hit Ctrl-C to quit.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Optuna Dashboard\n",
        "from google.colab import output\n",
        "from optuna_dashboard import run_server\n",
        "import threading\n",
        "\n",
        "dashboard_thread = threading.Thread(target=lambda: run_server(storage, port=8787))\n",
        "dashboard_thread.start()\n",
        "output.serve_kernel_port_as_iframe(8787, path=\"/dashboard\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YHdve0ZvzXT-"
      },
      "outputs": [],
      "source": [
        "# Run Model on Task\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "cv_params = {\n",
        "    \"scoring\": [\"r2\", \"neg_mean_squared_error\"],\n",
        "    \"return_train_score\": True,\n",
        "}\n",
        "\n",
        "def run_model_on_task(model_name, target_name, model, X, y, cv):\n",
        "    print(f\"Running {model_name=}\")\n",
        "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "    run = cross_validate(\n",
        "        TemplateRegressor(f\"{target_name}_{model_name}\", *model),\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        **cv_params,\n",
        "    )\n",
        "    run_df = pd.DataFrame(run).mean(axis=0)\n",
        "    return (target_name, model_name), run_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vepYJIxW9R8S",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b59c4a5-656b-41bd-e5eb-6edd651e6c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [02/Jun/2025 04:03:00] \"GET /dashboard HTTP/1.1\" 200 4145\n",
            "127.0.0.1 - - [02/Jun/2025 04:03:01] \"GET /static/bundle.js HTTP/1.1\" 200 4140872\n",
            "127.0.0.1 - - [02/Jun/2025 04:03:03] \"GET /api/studies HTTP/1.1\" 200 23\n",
            "127.0.0.1 - - [02/Jun/2025 04:08:07] \"GET /api/studies HTTP/1.1\" 200 7695\n",
            "127.0.0.1 - - [02/Jun/2025 04:39:08] \"GET /api/studies HTTP/1.1\" 200 38198\n"
          ]
        }
      ],
      "source": [
        "# Run Tasks\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "jobs = []\n",
        "for task in tasks:\n",
        "    target_name = task.target_name  # type: ignore\n",
        "    splits = task.download_split().split\n",
        "    X, y = task.get_X_and_y(dataset_format=\"dataframe\")  # type: ignore\n",
        "    cv = [s[0] for s in splits[0].values()][:CV]\n",
        "    for model_name, model in models.items():\n",
        "        jobs.append((model_name, target_name, model, X, y, cv))  # type: ignore\n",
        "\n",
        "n_jobs = -1\n",
        "results = Parallel(n_jobs)(delayed(run_model_on_task)(*job) for job in jobs)  # type: ignore\n",
        "\n",
        "runs = {task.target_name: {} for task in tasks}  # type: ignore\n",
        "for (target_name, model_name), run in results:\n",
        "    runs[target_name][model_name] = run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAN_GWXWCRKY"
      },
      "source": [
        "## Aggregate Results\n",
        "[https://optuna.github.io/optuna-dashboard/](https://optuna.github.io/optuna-dashboard/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eeK8Sc49TM1"
      },
      "outputs": [],
      "source": [
        "# Aggregate Results\n",
        "import pandas as pd\n",
        "\n",
        "runs_df = pd.DataFrame(runs)\n",
        "metrics = cv_params[\"scoring\"]\n",
        "metrics_df: dict[str, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
        "for metric in metrics:\n",
        "    metrics_df[metric] = (\n",
        "        runs_df.map(lambda r: r[f\"test_{metric}\"]),\n",
        "        runs_df.map(lambda r: r[f\"train_{metric}\"]),\n",
        "    )\n",
        "\n",
        "# Use first metric for ranking\n",
        "test_ranks_df = metrics_df[metrics[0]][0].rank(axis=0, ascending=False)\n",
        "test_ranks_df[\"avg_rank\"] = test_ranks_df.mean(axis=1)\n",
        "test_ranks_df[\"std_rank\"] = test_ranks_df.std(axis=1)\n",
        "\n",
        "train_ranks_df = metrics_df[metrics[0]][1].rank(axis=0, ascending=False)\n",
        "train_ranks_df[\"avg_rank\"] = train_ranks_df.mean(axis=1)\n",
        "train_ranks_df[\"std_rank\"] = train_ranks_df.std(axis=1)\n",
        "\n",
        "metrics_df[\"rank\"] = (test_ranks_df, train_ranks_df)\n",
        "\n",
        "# Display all metrics and ranks\n",
        "for metric, (test, train) in metrics_df.items():\n",
        "    display(f\"test_{metric}\", test, f\"train_{metric}\", train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb46996b"
      },
      "source": [
        "!cp optuna_journal_storage.log /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9grQGt7BCJOg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPu65sOB51qTT6rwA+N5QR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}