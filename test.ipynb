{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yNSyFZvf0Leo"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["((10, 2), (10,))"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the data\n","data = {\n","    \"Size (sq ft)\": [850, 900, 1200, 1400, 1600, 1700, 1800, 2000, 2200, 2500],\n","    \"Bedrooms\": [2, 3, 3, 3, 3, 4, 4, 4, 5, 5],\n","    \"Price ($)\": [300000, 340000, 400000, 500000, 520000, 580000, 600000, 620000, 720000, 790000]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","X = df[[\"Size (sq ft)\", \"Bedrooms\"]].values\n","y = df[\"Price ($)\"].values\n","\n","X.shape, y.shape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["(2, (10, 5), 1)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","X = X.astype(np.float64)\n","y = y.astype(np.float64)\n","\n","# scaler_X = StandardScaler()\n","# X = scaler_X.fit_transform(X)\n","# scaler_y = StandardScaler()\n","# y = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()  # type: ignore\n","input_dim = X.shape[1]\n","hidden_dim = (10, 5)\n","output_dim = 1\n","n_samples = X.shape[0]\n","\n","learning_rate = 0.1\n","\n","input_dim, hidden_dim, output_dim"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["([2, 10, 5, 1], 4, [(2, 10), (10, 5), (5, 1)], [(10,), (5,), (1,)])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["coefs_ = []\n","intercepts_ = []\n","\n","if not hasattr(hidden_dim, \"__iter__\"):\n","    hidden_dim = [hidden_dim]\n","hidden_dim = list(hidden_dim)\n","\n","layer_units = [input_dim, *hidden_dim, output_dim]\n","n_layers_ = len(layer_units)\n","\n","for i in range(n_layers_ - 1):\n","    coef_init = np.random.randn(layer_units[i], layer_units[i + 1])\n","    intercept_init = np.zeros(layer_units[i+1])\n","    coefs_.append(coef_init)\n","    intercepts_.append(intercept_init)\n","\n","layer_units, n_layers_, [c.shape for c in coefs_], [\n","    i.shape for i in intercepts_]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[ 0.36139561],\n","        [ 1.53803657],\n","        [-0.03582604],\n","        [ 1.56464366],\n","        [-2.6197451 ]]),\n"," array([0.]))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["coefs_[-1], intercepts_[-1]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["([(2, 10), (10, 5), (5, 1)], [(10,), (5,), (1,)])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["coef_grads = [\n","    np.empty((n_fan_in_, n_fan_out_))\n","    for n_fan_in_, n_fan_out_ in zip(layer_units[:-1], layer_units[1:])\n","]\n","intercept_grads = [\n","    np.empty(n_fan_out_) for n_fan_out_ in layer_units[1:]\n","]\n","\n","[c.shape for c in coef_grads], [i.shape for i in intercept_grads]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["([(10, 2), (10, 10), (10, 5), (10, 1)],\n"," array([[-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475],\n","        [-1.72428475]]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def _forward(X):\n","    activations = [X] * n_layers_\n","    # Compute hidden layer activations\n","    for i in range(n_layers_ - 1):\n","        activations[i+1] = np.dot(activations[i], coefs_[i])\n","        activations[i+1] += intercepts_[i]\n","        if i+1 != n_layers_-1:\n","            # Tanh activation for hidden layers\n","            activations[i+1] = np.tanh(activations[i+1])\n","\n","    return activations\n","\n","\n","activations = _forward(X)\n","[a.shape for a in activations], activations[-1]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3\n","2\n","1\n"]},{"data":{"text/plain":["([(2, 10), (10, 5), (5, 1)], [(10,), (5,), (1,)])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# loss = activations[-1] - y.reshape(-1, 1)\n","\n","# # Compute gradients for the output layer\n","# coef_grads[-1] = np.dot(activations[-2].T, loss) / y.shape[0]\n","# intercept_grads[-1] = np.mean(loss, axis=0)\n","\n","# # Compute the gradients for the hidden layers\n","# for i in range(n_layers_ - 2, 0, -1):\n","#     loss = np.dot(loss, coefs_[i].T) * (1 - np.tanh(activations[i])**2)\n","#     coef_grads[i-1] = np.dot(activations[i-1].T, loss)\n","#     intercept_grads[i-1] = np.mean(loss, axis=0)\n","\n","loss = activations[-1] - y.reshape(-1, 1)\n","\n","# Compute the gradients for the hidden layers\n","for i in range(n_layers_ - 1, 0, -1):\n","    print(i)\n","    if i != n_layers_ - 1:\n","        loss = np.dot(loss, coefs_[i].T) * (1 - np.tanh(activations[i])**2)\n","    coef_grads[i - 1] = np.dot(\n","        activations[i-1].T, loss) / y.shape[0]\n","    intercept_grads[i-1] = np.mean(loss, axis=0)\n","\n","[c.shape for c in coefs_], [i.shape for i in intercepts_]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Gradient clipping to prevent exploding gradients\n","max_grad_norm = 1.0\n","for i in range(n_layers_-1):\n","    coef_grads[i] = np.clip(\n","        coef_grads[i], -max_grad_norm, max_grad_norm)\n","    intercept_grads[i] = np.clip(\n","        intercept_grads[i], -max_grad_norm, max_grad_norm)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Update weights and biases using gradient descent\n","for i in range(n_layers_-1):\n","    coefs_[i] -= learning_rate * coef_grads[i]\n","    intercepts_[i] -= learning_rate * intercept_grads[i]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"research","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
